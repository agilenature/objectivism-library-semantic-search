---
phase: 11-display-name-import
plan: 02
type: execute
wave: 2
depends_on: ["11-01"]
files_modified:
  - spike/phase11_spike/TRIGGER-STRATEGY.md
  - spike/phase11_spike/GATE-EVIDENCE.md
autonomous: true
user_setup: []

must_haves:
  truths:
    - "PROCESSING-to-INDEXED trigger strategy is committed with data justification from measured lag"
    - "Polling parameters are validated or adjusted based on P50/P95/P99 data"
    - "Phase 11 gate evidence is documented with pass/fail for all 3 success criteria"
    - "Strategy accounts for the measured eventual consistency window"
  artifacts:
    - path: "spike/phase11_spike/TRIGGER-STRATEGY.md"
      provides: "Committed trigger strategy decision with data-backed rationale"
      contains: "Non-blocking polling"
    - path: "spike/phase11_spike/GATE-EVIDENCE.md"
      provides: "Phase 11 gate assessment with SC1/SC2/SC3 pass/fail"
      contains: "SC1"
  key_links:
    - from: "spike/phase11_spike/TRIGGER-STRATEGY.md"
      to: "spike/phase11_spike/RESULTS.md"
      via: "Data references to measured P50/P95/P99 values"
      pattern: "P50|P95|P99"
    - from: "spike/phase11_spike/GATE-EVIDENCE.md"
      to: "spike/phase11_spike/RESULTS.md"
      via: "References SDK evidence and round-trip data for SC1"
      pattern: "SC1.*display_name"
    - from: "spike/phase11_spike/GATE-EVIDENCE.md"
      to: "spike/phase11_spike/TRIGGER-STRATEGY.md"
      via: "References strategy document for SC3"
      pattern: "SC3.*trigger strategy"
---

<objective>
PROCESSING-to-INDEXED trigger strategy decision and Phase 11 gate documentation

Purpose: Analyze the empirical data from Plan 11-01 (lag measurements, display_name round-trip results) and (1) commit the PROCESSING-to-INDEXED trigger strategy with data justification, and (2) produce the Phase 11 gate evidence document proving all 3 success criteria are met (BLOCKING gate for Phase 12).

Output: TRIGGER-STRATEGY.md (committed strategy) and GATE-EVIDENCE.md (gate assessment).
</objective>

<execution_context>
@/Users/david/.claude/get-shit-done/workflows/execute-plan.md
@/Users/david/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/11-display-name-import/11-CONTEXT.md
@.planning/phases/11-display-name-import/11-RESEARCH.md
@.planning/phases/11-display-name-import/CLARIFICATIONS-ANSWERED.md
@spike/phase11_spike/RESULTS.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write TRIGGER-STRATEGY.md with data-justified polling parameters</name>
  <files>spike/phase11_spike/TRIGGER-STRATEGY.md</files>
  <action>
Read spike/phase11_spike/RESULTS.md to get the empirical data from Plan 11-01. Then write spike/phase11_spike/TRIGGER-STRATEGY.md with the following sections:

**1. Strategy Decision**
State the committed strategy: Non-blocking polling with no new FSM states (per locked Decision 3).
- Import returns immediately, FSM enters PROCESSING.
- Background task polls until document is visible, then transitions to INDEXED.
- PROCESSING is a legitimate long-running state (duration bounded by timeout).

**2. Measured Lag Data (from RESULTS.md)**
Reproduce the key numbers:
- Overall P50, P95, P99 import-to-visible latency.
- By-size-bucket breakdown if meaningful correlation exists.
- Whether documents.get() or list_store_documents() was faster for visibility detection.
- Sample size and any caveats (e.g., "P99 from 12 samples is effectively the max").

**3. Polling Parameters (Validated or Adjusted)**
Start with the locked parameters (0.5s start, 1.5x factor, 10s max, 300s timeout) and validate against data:
- If measured P99 < 60s: confirm parameters are appropriate. The 300s timeout provides 5x safety margin.
- If measured P99 is 60-120s: confirm 300s timeout is still adequate. Note the tighter margin.
- If measured P99 > 120s: recommend increasing timeout OR document the risk for Phase 12.
- If documents.get() was consistently faster than list: recommend documents.get() as the primary visibility check for Phase 12 production code (O(1) vs O(N)).

**4. Visibility Check Method**
Based on RESULTS.md data, recommend which API call to use for production polling:
- If documents.get(name=document_name) worked reliably: recommend it (O(1), resource name from ImportFileOperation.response).
- If documents.get() failed or was unreliable: recommend list_store_documents() with scan.
- Document any eventual consistency gap between operation.done and visibility.

**5. Error Handling**
Confirm the two PROCESSING-to-FAILED trigger conditions (per locked Decision 4):
- API error state: if documents.get() returns a document with state != STATE_ACTIVE and != STATE_PENDING after the timeout, transition to FAILED.
- Timeout: if document never appears within 300 seconds, transition to FAILED.
- Both failures feed into existing RecoveryCrawler from Phase 10.

**6. Implications for Phase 12**
- What Phase 12 production code must implement (background polling task, visibility check, INDEXED transition).
- Any risks identified by the data (e.g., high variance in lag, size-dependent lag).
- Whether the 14-file sample is representative of the 1,748-file production workload.

**Format:** Markdown document with clear section headers. Use tables for data. Reference RESULTS.md by name for source data. The document must be self-contained enough that Phase 12 can implement from it without re-reading RESULTS.md.
  </action>
  <verify>
    test -f spike/phase11_spike/TRIGGER-STRATEGY.md && echo "TRIGGER-STRATEGY.md exists"
    grep -c "Non-blocking polling" spike/phase11_spike/TRIGGER-STRATEGY.md
    grep -c "P50" spike/phase11_spike/TRIGGER-STRATEGY.md
    grep -c "PROCESSING" spike/phase11_spike/TRIGGER-STRATEGY.md
    grep -c "Phase 12" spike/phase11_spike/TRIGGER-STRATEGY.md
  </verify>
  <done>
    TRIGGER-STRATEGY.md commits the non-blocking polling strategy with data-justified polling parameters. The document references measured P50/P95/P99 values, validates or adjusts the locked polling parameters, recommends the visibility check method, and documents implications for Phase 12.
  </done>
</task>

<task type="auto">
  <name>Task 2: Write GATE-EVIDENCE.md with Phase 11 gate assessment</name>
  <files>spike/phase11_spike/GATE-EVIDENCE.md</files>
  <action>
Write spike/phase11_spike/GATE-EVIDENCE.md as the Phase 11 BLOCKING gate assessment document. This is the formal evidence that Phase 11's success criteria are met (or not), directly paralleling the gate evidence produced in Phases 9 and 10.

**Structure:**

**Header:**
- Phase: 11 -- display_name Stability and Import Reliability
- Gate type: BLOCKING for Phase 12
- Distrust level: HOSTILE
- Assessment date: (current date)
- Verdict: PASS or FAIL (determined by evidence below)

**SC1: display_name is confirmed caller-controlled**
- SDK evidence: cite the exact file paths and line numbers from RESULTS.md showing display_name serialization path (files.py, types.py, _common.py).
- Round-trip evidence: cite the round-trip test results from RESULTS.md -- how many files tested, how many exact matches, any normalization detected.
- Conclusion: "display_name IS/IS NOT caller-controlled" with the specific evidence.
- If normalization was detected: document the rule and note that Phase 12 must pre-apply it.
- Verdict: PASS or FAIL.

**SC2: Import-to-visible lag measured with P50/P95/P99**
- Sample size: how many files produced successful measurements.
- Latency data: P50, P95, P99 overall (from RESULTS.md).
- By-size breakdown: if available and meaningful.
- Note on statistical significance: with N=10-14, P99 is approximately the max value.
- Verdict: PASS (characterization complete) or FAIL (insufficient data).

**SC3: PROCESSING-to-INDEXED trigger strategy decided and documented**
- Reference: TRIGGER-STRATEGY.md.
- Strategy summary: non-blocking polling, no new FSM states.
- Data justification: how the measured lag data supports the chosen parameters.
- Verdict: PASS (strategy committed with data justification) or FAIL.

**Overall Gate Verdict:**
- PASS if all three SC pass.
- FAIL if any SC fails, with specific remediation needed.

**Gate Table:**
| Success Criterion | Status | Key Evidence |
|-------------------|--------|--------------|
| SC1: display_name caller-controlled | PASS/FAIL | [summary] |
| SC2: P50/P95/P99 measured | PASS/FAIL | [summary] |
| SC3: Trigger strategy committed | PASS/FAIL | [summary] |
| **Overall** | **PASS/FAIL** | |

**Phase 12 Readiness:**
- List what Phase 12 can now rely on from Phase 11 findings.
- List any caveats or risks that Phase 12 must handle.
  </action>
  <verify>
    test -f spike/phase11_spike/GATE-EVIDENCE.md && echo "GATE-EVIDENCE.md exists"
    grep -c "SC1" spike/phase11_spike/GATE-EVIDENCE.md
    grep -c "SC2" spike/phase11_spike/GATE-EVIDENCE.md
    grep -c "SC3" spike/phase11_spike/GATE-EVIDENCE.md
    grep -c "PASS\|FAIL" spike/phase11_spike/GATE-EVIDENCE.md
    grep -c "Phase 12" spike/phase11_spike/GATE-EVIDENCE.md
  </verify>
  <done>
    GATE-EVIDENCE.md contains a formal gate assessment with per-criterion PASS/FAIL verdicts for SC1 (display_name), SC2 (latency data), and SC3 (trigger strategy). The overall gate verdict is stated. Phase 12 readiness is documented. All evidence references are traceable to RESULTS.md and TRIGGER-STRATEGY.md.
  </done>
</task>

</tasks>

<verification>
Phase 11 Plan 02 verification:
1. TRIGGER-STRATEGY.md exists with committed strategy, measured data, validated parameters
2. GATE-EVIDENCE.md exists with SC1/SC2/SC3 assessments and overall verdict
3. All data references trace back to RESULTS.md from Plan 11-01
4. Polling parameters are either confirmed or adjusted with justification
5. Phase 12 implications are documented
6. Gate verdict is explicitly stated (PASS or FAIL)
</verification>

<success_criteria>
- TRIGGER-STRATEGY.md commits non-blocking polling strategy with data-justified parameters
- GATE-EVIDENCE.md formally assesses all 3 Phase 11 success criteria
- If gate PASSES: Phase 12 is unblocked with documented evidence
- If gate FAILS: specific remediation is identified (which SC failed and why)
- All documents are self-contained and traceable to empirical data
</success_criteria>

<output>
After completion, create `.planning/phases/11-display-name-import/11-02-SUMMARY.md`
</output>
