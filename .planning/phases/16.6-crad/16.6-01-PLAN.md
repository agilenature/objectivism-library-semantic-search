# Plan 16.6-01: CRAD Pilot — 3-Pass Algorithm Implementation and Pilot Validation

**Phase:** 16.6 — Corpus-Relative Aspect Differentiation (CRAD)
**Status:** NOT STARTED
**Autonomous:** Yes

---

## Goal

Implement the 3-pass CRAD algorithm as `scripts/crad_algorithm.py`, create the DB schema for
storing genus profiles and discrimination phrases, run the algorithm on 3 known-failing pilot
files, and validate that the generated phrases match or exceed the known S4a rank for all 3.
This plan is the gate: if any pilot phrase achieves rank > 5 after 3 retry attempts, stop and
revise the algorithm before proceeding to Plan 16.6-02.

---

## Background: The Genus Method Applied

The CRAD algorithm applies Binswanger's Genus Method in 3 passes:

**Pass 1 (Genus Identification):** Read all files in a series from the DB. Compute an
aspect-frequency map: for each aspect, count how many files in the series mention it. Aspects
appearing in ≥80% of series files are "genus" (shared DNA). Aspects appearing in ≤2 files are
"rare" (differentiating). Output: GENUS_PROFILE per series.

**Pass 2 (Differential Identification):** For a single file, compare its aspects against the
GENUS_PROFILE. Subtract genus aspects. Rank remaining aspects by series rarity (fewest files
first). Output: FILE_DIFFERENTIA with top-3 rarest aspects.

**Pass 3 (Essentialization):** Concatenate the top-N rarest aspects into a ≤7-word phrase.
Strip markdown. Ensure it reads naturally. Output: discrimination_phrase.

**Pilot ground truth (from Phase 16.5 ROOT-CAUSE.md):**
- `ITOE AT - Class 14-01 - OH.txt`: known S4a = `"Zeno's arrow paradox"` → rank 1
- `OL - Class 14-02 - Open OH.txt` (or equivalent failing OL file): known S4c = `"Aristotle's solution to change Heraclitus paradox"` → rank 2
- `ITOE AT - Class 13-02 - OH.txt`: known S4a = `"measurements omitted in concept formation generic vs. brand sense of philosophy fundamentality of philosophy"` → rank 4

---

## Tasks

### Task 1: Create DB schema

Add two tables to the library.db schema (new migration V12 or standalone script):

```sql
CREATE TABLE IF NOT EXISTS series_genus (
  series_name TEXT PRIMARY KEY,
  genus_profile_json TEXT NOT NULL,
  file_count INTEGER NOT NULL,
  last_updated TEXT NOT NULL
);

CREATE TABLE IF NOT EXISTS file_discrimination_phrases (
  filename TEXT PRIMARY KEY,
  series_name TEXT NOT NULL,
  phrase TEXT NOT NULL,
  word_count INTEGER NOT NULL,
  aspects_used TEXT NOT NULL,     -- JSON array
  validation_rank INTEGER,        -- NULL until validated
  validation_status TEXT NOT NULL DEFAULT 'candidate',
  last_validated TEXT
);
```

Use `conn.execute("CREATE TABLE IF NOT EXISTS ...")` in the script (standalone, no migration
needed for pilot). Add to `src/objlib/database.py` migration for production.

### Task 2: Implement Pass 1 — Genus Identification

```python
def build_genus_profile(conn, series_name: str) -> dict:
    """
    Query all files in a series, compute aspect frequency map.
    Returns GENUS_PROFILE dict.
    """
    rows = conn.execute("""
        SELECT filename,
               json_extract(metadata_json, '$.topic_aspects') as aspects_json
        FROM file_metadata_ai
        WHERE is_current = 1
          AND filename LIKE ?
    """, (f"%{series_name}%",)).fetchall()

    freq = {}
    file_count = len(rows)
    for _, aspects_json in rows:
        aspects = json.loads(aspects_json or "[]")
        for a in aspects:
            freq[a] = freq.get(a, 0) + 1

    threshold_80pct = max(1, int(file_count * 0.8))
    shared = [a for a, c in freq.items() if c >= threshold_80pct]
    rarity_threshold = 2  # aspects in ≤2 files are differentiating

    return {
        "series_name": series_name,
        "file_count": file_count,
        "shared_aspects": shared,
        "aspect_frequency_map": freq,
        "rarity_threshold": rarity_threshold,
    }
```

**Validation:** Print GENUS_PROFILE for ITOE AT OH series (should show "epistemology",
"concept formation", etc. in shared_aspects with frequencies 22–26 out of 28).

### Task 3: Implement Pass 2 — Differential Identification (Claude-driven)

Pass 2 uses Claude (Anthropic API) as the discriminating agent. Pure frequency sorting collapses
for series like ITOE AT OH where ~240 of ~280 unique aspects all have series frequency = 1.
Claude sees the full series territory simultaneously and applies philosophical judgment to select
the aspects that make THIS file distinct from ALL its siblings. The frequency map from Pass 1 is
provided as a hint (signal about what is shared genus), but Claude reasons from philosophical
content, not just count.

**Why Claude, not a secondary sort key:** The research confirmed that "order of being vs. order
of knowing" (corpus freq=1, series freq=1) fails as a query while "Zeno's arrow paradox" (also
corpus freq=1, series freq=1) succeeds at rank 1. The difference is philosophical specificity,
not any computable frequency signal. The Genus Method requires reasoning, not sorting.

**Model choice: claude-haiku-4-5-20251001** (Haiku 4.5)

Rationale: The task is well-defined discrimination, not open-ended reasoning. Input context is
~300-600 tokens of series data per call. 3 pilot calls, 63 full-run calls. Haiku 4.5 is
significantly faster and cheaper at this task scale, and the structured JSON output format
(not free-form generation) reduces the quality gap with Sonnet for this specific use case.

**Function signature:**

```python
import anthropic
import json

CLAUDE_MODEL = "claude-haiku-4-5-20251001"

def get_claude_discrimination_phrase(
    target_filename: str,
    target_aspects: list[str],
    series_name: str,
    series_aspects_by_file: dict[str, list[str]],   # {filename: [aspect, ...]} for ALL siblings
    series_freq_map: dict[str, int],                 # from Pass 1: {aspect: count}
    corpus_freq_map: dict[str, int],                 # global corpus frequencies
    max_retries: int = 2,
) -> dict:
    """
    Call Claude to select the philosophically discriminating aspects for target_filename.

    Returns dict with keys:
        discrimination_phrase: str   -- the 1-7 word discrimination phrase
        aspects_used: list[str]      -- the 1-3 aspects Claude selected
        reasoning: str               -- Claude's explanation (for audit log)
        model: str                   -- model used
    Raises ValueError if Claude fails to return valid JSON after max_retries attempts.
    """
    client = anthropic.Anthropic()   # reads ANTHROPIC_API_KEY from env

    system_prompt = _build_pass2_system_prompt()
    user_message = _build_pass2_user_message(
        target_filename=target_filename,
        target_aspects=target_aspects,
        series_name=series_name,
        series_aspects_by_file=series_aspects_by_file,
        series_freq_map=series_freq_map,
        corpus_freq_map=corpus_freq_map,
    )

    last_error = None
    for attempt in range(max_retries + 1):
        try:
            response = client.messages.create(
                model=CLAUDE_MODEL,
                max_tokens=512,
                system=system_prompt,
                messages=[{"role": "user", "content": user_message}],
            )
            text = response.content[0].text.strip()
            # Strip markdown code fences if present
            if text.startswith("```"):
                text = text.split("```")[1]
                if text.startswith("json"):
                    text = text[4:]
                text = text.strip()
            parsed = json.loads(text)
            if "discrimination_phrase" not in parsed or "aspects_used" not in parsed:
                raise ValueError(f"Missing required keys in response: {list(parsed.keys())}")
            return {
                "discrimination_phrase": parsed["discrimination_phrase"],
                "aspects_used": parsed["aspects_used"],
                "reasoning": parsed.get("reasoning", ""),
                "model": CLAUDE_MODEL,
            }
        except (json.JSONDecodeError, ValueError, KeyError) as e:
            last_error = e
            if attempt < max_retries:
                import time
                time.sleep(1)
            continue
        except anthropic.APIError as e:
            raise RuntimeError(f"Anthropic API error: {e}") from e

    raise ValueError(
        f"Claude failed to return valid JSON after {max_retries + 1} attempts. "
        f"Last error: {last_error}"
    )
```

**System prompt:**

```python
def _build_pass2_system_prompt() -> str:
    return """You are a philosophical librarian applying the Genus Method to build a
discrimination index for an Objectivism lecture library.

Your task: given a target lecture file and all sibling files in the same series,
identify the 1-3 aspects that make the TARGET file philosophically distinct from ALL
its siblings. Output ONLY valid JSON — no prose before or after.

Rules:
1. Prefer aspects that are philosophically SPECIFIC over philosophically generic.
   "Zeno's arrow paradox" is specific. "epistemology" is generic.
   "measurement omission in concept formation" is specific. "methodology" is generic.
2. Prefer aspects that appear in FEW or NO sibling files (use the frequency hint).
   But when many aspects tie at the same frequency, judge by philosophical specificity.
3. Select 1-3 aspects whose concatenation totals ≤7 words.
4. Do NOT include aspects that appear in ≥80% of sibling files — those are genus, not differentia.
5. Do NOT use markdown, bullet points, or explanation outside the JSON object.

Output format (ONLY this JSON, nothing else):
{
  "discrimination_phrase": "the concatenated phrase, ≤7 words, no markdown",
  "aspects_used": ["aspect1", "aspect2"],
  "reasoning": "one sentence explaining why these aspects are the most specific differentia"
}"""
```

**User message builder:**

```python
def _build_pass2_user_message(
    target_filename: str,
    target_aspects: list[str],
    series_name: str,
    series_aspects_by_file: dict[str, list[str]],
    series_freq_map: dict[str, int],
    corpus_freq_map: dict[str, int],
) -> str:
    # Build sibling table: only the siblings (exclude target)
    sibling_lines = []
    for fname, aspects in sorted(series_aspects_by_file.items()):
        if fname == target_filename:
            continue
        sibling_lines.append(f"  {fname}: {', '.join(aspects[:8])}")  # cap at 8 per sibling

    # Frequency hint: target's aspects with their series and corpus frequencies
    freq_lines = []
    for aspect in target_aspects:
        s_freq = series_freq_map.get(aspect, 0)
        c_freq = corpus_freq_map.get(aspect, 0)
        freq_lines.append(f"  [{s_freq} in series, {c_freq} in corpus] {aspect}")

    return f"""Series: {series_name}
Series size: {len(series_aspects_by_file)} files

TARGET FILE: {target_filename}
Target aspects: {', '.join(target_aspects)}

SIBLING FILES (all other files in series):
{chr(10).join(sibling_lines)}

FREQUENCY HINT for target's aspects (series_count, corpus_count):
{chr(10).join(freq_lines)}

Select the 1-3 aspects that make {target_filename} philosophically DISTINCT from all siblings.
Output ONLY the JSON object."""
```

**Pilot simulation — what Claude receives and expected output:**

*Pilot 1: ITOE AT - Class 14-01 - OH.txt*
- Target aspects include: "Zeno's arrow paradox", "law of identity applied to motion",
  "order of being vs. order of knowing", "measurement omission", "concept formation"
- Series freq for all: ~1 (28-file series, most aspects unique)
- Expected Claude output: selects "Zeno's arrow paradox" because it names a specific
  historical problem (philosophically concrete), not an abstract method or general topic.
  The arrow paradox is the distinctive content of this specific session.
- Expected phrase: `"Zeno's arrow paradox"` (3 words, rank 1 confirmed)

*Pilot 2: ITOE AT - Class 13-02 - OH.txt*
- Target aspects include topics around measurement omission, generic vs brand concepts,
  sense of philosophy, fundamentality
- Expected Claude output: selects the cluster "measurements omitted concept formation
  generic brand" (4 concepts combined)
- Expected phrase: `"measurements omitted concept formation generic brand"` (≤7 words, rank 4)

*Pilot 3: OL - Class 14-02 - Open OH.txt*
- Target aspects include: "Aristotle's solution to change", "Heraclitus paradox",
  "principle of non-contradiction applied to motion"
- Expected Claude output: selects "Aristotle's solution to change Heraclitus paradox"
  (specific historical figures + specific philosophical problems = maximum specificity)
- Expected phrase: `"Aristotle's solution to change Heraclitus paradox"` (≤7 words, rank 2)

**Validation gate for Task 3:**
Claude must select aspects that (a) produce phrases matching the known S4a working queries
for all 3 pilots and (b) achieve rank ≤ 5 in Gemini. The frequency-only sort in the research
(secondary tie-breaking by corpus freq) was documented but found insufficient — Claude is the
correct solution for the philosophical discrimination step.

### Task 4: Implement Pass 3 — Essentialization

```python
import re

def build_discrimination_phrase(differentia: dict) -> dict:
    """
    Concatenate top-N rarest aspects into ≤7-word phrase. Strip markdown.
    """
    MAX_WORDS = 7

    def clean(aspect: str) -> str:
        return re.sub(r'[*_`]', '', aspect).strip()

    words_used = []
    aspects_used = []
    for aspect in differentia["top_3_rarest"]:
        cleaned = clean(aspect)
        words = cleaned.split()
        if len(words_used) + len(words) <= MAX_WORDS:
            words_used.extend(words)
            aspects_used.append(aspect)
        else:
            break  # word budget exhausted

    phrase = " ".join(words_used)
    return {
        "filename": differentia["filename"],
        "series_name": differentia["series_name"],
        "phrase": phrase,
        "word_count": len(words_used),
        "aspects_used": aspects_used,
        "validation_status": "candidate",
    }
```

### Task 5: Implement validation against Gemini

```python
def validate_phrase(phrase: str, target_filename: str, gemini_client, store_name: str,
                    top_k: int = 20) -> int | None:
    """
    Query Gemini File Search with the discrimination phrase.
    Return the rank (1-indexed) of the target file, or None if not found in top_k.
    """
    result = gemini_client.query(store_name, phrase, top_k=top_k)
    for i, citation in enumerate(result.citations, start=1):
        if target_filename in citation.filename:
            return i
    return None
```

### Task 6: Run pilot on 3 files

Script: `scripts/crad_pilot.py`

For each of the 3 pilot files:
1. Build genus profile for its series (Pass 1)
2. Build differentia (Pass 2)
3. Build discrimination phrase (Pass 3)
4. Validate against Gemini (3 consecutive queries; record ranks)
5. Compare to known S4a rank

**Acceptance criteria for each pilot file:**
- validation_rank ≤ 5 on all 3 consecutive queries (zero stochastic variance)
- phrase ≤ 7 words
- phrase is markdown-clean

**If any pilot fails (rank > 5):** Stop. Document which file failed and why. Adjust algorithm
(likely: increase top_3 to top_5, or add series_name as fallback). Do NOT proceed to Plan 16.6-02.

### Task 7: Store pilot results in DB

For each successful pilot file:
- Insert row into `series_genus` (genus profile)
- Insert row into `file_discrimination_phrases` (phrase + validation_rank)

### Task 8: Document results

Create `16.6-01-RESULTS.md` with:
- Genus profiles for each pilot series
- Differentia output for each pilot file
- Generated phrases (with word count)
- Validation ranks (3 runs each)
- Comparison to known S4a ranks
- Pass/Fail verdict for each pilot
- Overall gate: PASS (all 3 ≤ rank 5) or FAIL (any > rank 5, reason documented)

---

## Validation Gates

- [ ] DB tables created: `series_genus`, `file_discrimination_phrases`
- [ ] Pass 1 output: ITOE AT OH genus profile shows "epistemology" in shared_aspects with frequency ≥ 22/28
- [ ] Pass 2 output: Claude selects "Zeno's arrow paradox" for ITOE AT - Class 14-01 - OH (not just any freq=1 aspect)
- [ ] Pass 2 output: Claude selects aspects matching rank-4 known query for ITOE AT - Class 13-02 - OH
- [ ] Pass 2 output: Claude selects "Aristotle's solution to change Heraclitus paradox" for OL - Class 14-02 - Open OH
- [ ] Pass 3 output: All 3 pilot phrases ≤ 7 words, markdown-clean
- [ ] Validation: All 3 pilot phrases achieve rank ≤ 5 in Gemini, stable across 3 runs
- [ ] Results file committed: `16.6-01-RESULTS.md`
- [ ] Gate decision: PASS or FAIL with evidence

---

## Files Created/Modified

- `scripts/crad_algorithm.py` — 3-pass CRAD algorithm (Pass 1 computation + Pass 2 Claude call + Pass 3 computation)
- `scripts/crad_pilot.py` — pilot runner for 3 files
- `.planning/phases/16.6-crad/16.6-01-RESULTS.md` — pilot results and gate verdict
- `data/library.db` — two new tables (series_genus, file_discrimination_phrases)

## Dependencies

- `anthropic` SDK (v0.57.1, confirmed installed)
- `ANTHROPIC_API_KEY` environment variable must be set before running pilot
- Pass 2 makes 1 Claude API call per file (3 calls for pilot, 63 calls for full run)
- No batch API needed — 63 sequential sync calls are well within rate limits and take ~2-3 min total
