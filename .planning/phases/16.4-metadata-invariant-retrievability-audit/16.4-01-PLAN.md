---
phase: 16.4-metadata-invariant-retrievability-audit
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/objlib/constants.py
  - src/objlib/extraction/batch_orchestrator.py
autonomous: true

must_haves:
  truths:
    - "BOOK_SIZE_BYTES = 830_000 named constant exists in src/objlib/constants.py"
    - "batch_orchestrator.py imports BOOK_SIZE_BYTES and uses it for routing decisions"
    - "40 failed_validation Episode files are reset to ai_metadata_status='pending'"
    - "1 skipped Book file (Philosophy - Who Needs It, 552KB < 830KB) is reclassified to pending"
    - "60 needs_review OH files are approved (they already have file_primary_topics)"
    - "No code path allows a non-book file to reach approved without file_primary_topics"
  artifacts:
    - path: "src/objlib/constants.py"
      provides: "BOOK_SIZE_BYTES named constant"
      contains: "BOOK_SIZE_BYTES = 830_000"
    - path: "src/objlib/extraction/batch_orchestrator.py"
      provides: "Routing that uses BOOK_SIZE_BYTES for skip decisions"
      contains: "BOOK_SIZE_BYTES"
  key_links:
    - from: "src/objlib/extraction/batch_orchestrator.py"
      to: "src/objlib/constants.py"
      via: "import BOOK_SIZE_BYTES"
      pattern: "from objlib\\.constants import BOOK_SIZE_BYTES"
    - from: "src/objlib/upload/state.py"
      to: "file_primary_topics table"
      via: "EXISTS subquery in get_fsm_pending_files"
      pattern: "EXISTS.*file_primary_topics"
---

<objective>
Audit and fix the metadata routing invariant: define the book-size threshold constant, enumerate all routing divergence points, reset the 40 failed_validation Episode files and 1 skipped Book file to pending for re-extraction, approve the 60 needs_review OH files, and verify no code path allows a non-book file to bypass extraction.

Purpose: Establish the structural invariant that every non-book .txt/.md file must complete batch-extract before upload. This is the precondition for the quality audit (Plan 16.4-02) and retrievability audit (Plan 16.4-03).

Output: `src/objlib/constants.py` with BOOK_SIZE_BYTES, updated `batch_orchestrator.py` routing, DB state with 0 failed_validation and 0 needs_review indexed files, grep audit confirming no ad-hoc routing paths remain.
</objective>

<execution_context>
@/Users/david/.claude/get-shit-done/workflows/execute-plan.md
@/Users/david/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/16.4-metadata-invariant-retrievability-audit/16.4-CONTEXT.md
@.planning/phases/16.4-metadata-invariant-retrievability-audit/16.4-RESEARCH.md
@src/objlib/extraction/batch_orchestrator.py
@src/objlib/upload/state.py
@src/objlib/upload/header_builder.py
@src/objlib/database.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Diagnostic DB queries + define BOOK_SIZE_BYTES constant</name>
  <files>src/objlib/constants.py</files>
  <action>
  STEP 1 -- Run diagnostic DB queries BEFORE any code changes (per locked decision #1).
  These queries establish the exact baseline. Record all outputs in the SUMMARY.

  ```sql
  -- Q1: Corpus count verification
  SELECT COUNT(*) FROM files WHERE gemini_state='indexed';
  -- Expected: 1749

  -- Q2: Failed validation files (the 40 Episodes)
  SELECT COUNT(*), GROUP_CONCAT(filename, ', ') FROM files
  WHERE gemini_state='indexed' AND ai_metadata_status='failed_validation';
  -- Expected: 40

  -- Q3: Skipped .txt files below BOOK_SIZE_BYTES threshold
  SELECT filename, file_size FROM files
  WHERE ai_metadata_status='skipped' AND (file_path LIKE '%.txt' OR file_path LIKE '%.md')
  ORDER BY file_size;
  -- Expected: 1 file (Philosophy - Who Needs It, ~552KB)

  -- Q4: Needs-review indexed files
  SELECT COUNT(*) FROM files WHERE gemini_state='indexed' AND ai_metadata_status='needs_review';
  -- Expected: 60 (ITOE OH files)

  -- Q5: Approved files without file_primary_topics
  SELECT COUNT(*) FROM files f
  WHERE f.ai_metadata_status = 'approved'
  AND NOT EXISTS (SELECT 1 FROM file_primary_topics pt WHERE pt.file_path = f.file_path);
  -- Expected: 0

  -- Q6: All skipped .txt files with sizes (verify threshold derivation)
  SELECT filename, file_size FROM files
  WHERE ai_metadata_status='skipped' AND file_path LIKE '%.txt'
  ORDER BY file_size;
  ```

  STEP 2 -- Create `src/objlib/constants.py` with:
  ```python
  """Project-wide named constants.

  Constants defined here replace inline magic numbers across the codebase.
  Each constant has an empirical derivation documented in its docstring.
  """

  # Empirical derivation (2026-02-25):
  # - Largest successfully extracted .txt: 3,475,970 bytes (La rebelion de Atlas)
  # - Single skipped .txt boundary case: 552,798 bytes (Philosophy - Who Needs It)
  # - 1.5x the boundary file = 829,197 bytes, rounded to 830,000
  # - Files >= BOOK_SIZE_BYTES are books (ai_metadata_status='skipped', no extraction)
  # - Files < BOOK_SIZE_BYTES are non-books (must complete batch-extract)
  BOOK_SIZE_BYTES: int = 830_000
  ```

  Per locked decision #3: value is 830,000 (1.5x the 552KB boundary file), defined in src/objlib/constants.py.
  </action>
  <verify>
  - `python -c "from objlib.constants import BOOK_SIZE_BYTES; assert BOOK_SIZE_BYTES == 830_000; print('OK')"` prints OK
  - All 6 diagnostic queries return expected values (record in SUMMARY)
  </verify>
  <done>BOOK_SIZE_BYTES = 830_000 exists in src/objlib/constants.py and is importable. Diagnostic DB baseline recorded.</done>
</task>

<task type="auto">
  <name>Task 2: Fix routing code + reset DB state + grep audit</name>
  <files>src/objlib/extraction/batch_orchestrator.py</files>
  <action>
  This task has 4 sub-steps: code fix, DB resets, layer verification, grep audit.

  SUB-STEP A -- Update batch_orchestrator.py routing:

  1. Add import at top: `from objlib.constants import BOOK_SIZE_BYTES`
  2. Add a new helper method `_mark_book()` alongside the existing `_mark_oversized()`:
     ```python
     def _mark_book(self, file_path: str, file_size: int) -> None:
         """Mark file as a book (>= BOOK_SIZE_BYTES). Skips extraction entirely."""
         self._db.conn.execute(
             """
             UPDATE files
             SET ai_metadata_status = 'skipped',
                 error_message = ?,
                 updated_at = strftime('%Y-%m-%dT%H:%M:%f', 'now')
             WHERE file_path = ?
             """,
             (f"Book file ({file_size:,} bytes >= {BOOK_SIZE_BYTES:,} BOOK_SIZE_BYTES). "
              "Skipped extraction; uploaded to Gemini File Search without enrichment.",
              file_path),
         )
         self._db.conn.commit()
     ```
  3. In the batch request building loop (currently lines ~140-179), insert the byte-size check as the FIRST thing after `file_path = file_record["file_path"]` -- BEFORE the `content = Path(file_path).read_text(...)` line. This is critical: the file content must NEVER be read for book-sized files.

     Insert immediately after line 143 (`custom_id = str(idx)`), BEFORE line 146 (`content = Path(file_path).read_text(...)`):
     ```python
     # Book routing: files >= BOOK_SIZE_BYTES are books, skip extraction entirely.
     # This check runs BEFORE read_text to avoid loading large files into memory.
     file_size = Path(file_path).stat().st_size
     if file_size >= BOOK_SIZE_BYTES:
         logger.info(
             "Skipping book file %s (%d bytes >= %d BOOK_SIZE_BYTES)",
             Path(file_path).name, file_size, BOOK_SIZE_BYTES,
         )
         oversized_files.append(file_path)
         self._mark_book(file_path, file_size)
         continue
     ```

     IMPORTANT placement rules:
     - The byte check MUST be BEFORE `content = Path(file_path).read_text(encoding="utf-8")` (currently line 147)
     - The file is NEVER read if it meets the byte threshold
     - The existing token-based MAX_DOCUMENT_TOKENS check (lines 152-164) remains AFTER the read_text, unchanged
     - Two checks serve different purposes: BOOK_SIZE_BYTES = structural routing ("this is a book"), MAX_DOCUMENT_TOKENS = Mistral context window limit (technical constraint)

  SUB-STEP B -- Reset DB state for the 41 files that need re-extraction:

  Run via `sqlite3 data/library.db`:

  ```sql
  -- B1: Reset 40 failed_validation Episode files to pending
  UPDATE files SET ai_metadata_status = 'pending', error_message = NULL
  WHERE ai_metadata_status = 'failed_validation'
    AND gemini_state = 'indexed'
    AND (file_path LIKE '%.txt' OR file_path LIKE '%.md');
  -- Verify: SELECT changes();  -- Expected: 40

  -- B2: Reclassify the 1 skipped .txt Book below BOOK_SIZE_BYTES to pending
  -- (Philosophy - Who Needs It at 552KB < 830KB threshold)
  UPDATE files SET ai_metadata_status = 'pending', error_message = NULL
  WHERE ai_metadata_status = 'skipped'
    AND file_size < 830000
    AND (file_path LIKE '%.txt' OR file_path LIKE '%.md');
  -- Verify: SELECT changes();  -- Expected: 1

  -- B3: Approve 60 needs_review OH files (they already have file_primary_topics)
  -- Verification first:
  SELECT COUNT(*) FROM files f
  WHERE f.ai_metadata_status = 'needs_review'
    AND NOT EXISTS (SELECT 1 FROM file_primary_topics pt WHERE pt.file_path = f.file_path);
  -- Must be 0 (all needs_review files have topics)
  -- Then approve:
  UPDATE files SET ai_metadata_status = 'approved'
  WHERE ai_metadata_status = 'needs_review';
  -- Verify: SELECT changes();  -- Expected: 60
  ```

  SUB-STEP C -- Verify Layer 2 (upload gate):

  Read `src/objlib/upload/state.py` lines 694-722 and confirm `get_fsm_pending_files()` already has:
  - `ai_metadata_status = 'approved'` check
  - `EXISTS (SELECT 1 FROM file_primary_topics pt WHERE pt.file_path = files.file_path)` check
  Per locked decision #5 and research: this gate is already correct. No code change needed in state.py.
  Document this verification explicitly in the SUMMARY: "Layer 2 verified at state.py:714-717, no change needed."

  SUB-STEP D -- Grep audit of all files touching ai_metadata_status:

  Run grep for `ai_metadata_status` across all src/ files. For each occurrence, verify:
  1. No hardcoded category labels (e.g., "Episode", "MOTM") gate extraction routing
  2. No inline byte/token thresholds duplicate BOOK_SIZE_BYTES
  3. All paths that set ai_metadata_status='approved' require file_primary_topics

  Files to audit (from grep):
  - src/objlib/cli.py
  - src/objlib/database.py
  - src/objlib/extraction/batch_orchestrator.py
  - src/objlib/extraction/orchestrator.py
  - src/objlib/upload/state.py
  - src/objlib/extraction/review.py

  Record findings per file in SUMMARY. If ANY violation is found:
  - Fix the violation inline in the offending file
  - Add the fixed file to the `<files>` list in the SUMMARY's "Files Changed" section
  - Document what was found and what was changed, with before/after snippets
  - Re-run verification to confirm the fix does not break imports or tests
  </action>
  <verify>
  Post-reset DB verification queries (run all, record outputs):
  ```sql
  SELECT ai_metadata_status, COUNT(*) FROM files WHERE gemini_state='indexed' GROUP BY ai_metadata_status;
  -- Expected: approved=1708, pending=41, skipped=0 (for indexed .txt/.md)
  -- Note: skipped count changes because the 1 book is now pending

  SELECT COUNT(*) FROM files WHERE ai_metadata_status='failed_validation';
  -- Expected: 0

  SELECT COUNT(*) FROM files WHERE ai_metadata_status='needs_review';
  -- Expected: 0

  SELECT COUNT(*) FROM files WHERE ai_metadata_status='pending' AND gemini_state='indexed';
  -- Expected: 41 (40 Episodes + 1 reclassified Book)
  ```

  Code verification:
  - `grep -n "BOOK_SIZE_BYTES" src/objlib/extraction/batch_orchestrator.py` shows import and usage
  - `grep -n "_mark_book" src/objlib/extraction/batch_orchestrator.py` shows new helper method and its call in the loop
  - Confirm the byte check appears BEFORE the `read_text` call in the loop (line numbers must show byte check at a lower line number than read_text)
  - `grep -rn "ai_metadata_status" src/objlib/ | wc -l` returns same count as pre-change (no new unaudited references, excluding the new _mark_book method)
  - `python -c "from objlib.extraction.batch_orchestrator import BatchExtractionOrchestrator; print('imports OK')"` succeeds
  </verify>
  <done>
  - BOOK_SIZE_BYTES imported and used in batch_orchestrator.py for book routing
  - _mark_book() helper created for book-specific skip logic (no file content read)
  - Byte check placed BEFORE read_text in loop -- book files never loaded into memory
  - Existing token check (MAX_DOCUMENT_TOKENS) remains after read_text, unchanged
  - 40 failed_validation files reset to pending
  - 1 skipped Book reclassified to pending (below 830KB threshold)
  - 60 needs_review OH files approved
  - Layer 2 (get_fsm_pending_files) verified correct, no change needed
  - Grep audit of all ai_metadata_status references complete with per-file findings documented
  - Any violations found were fixed inline, documented in SUMMARY with before/after
  - 0 files with ai_metadata_status='failed_validation', 0 with 'needs_review'
  - 41 indexed files now pending re-extraction
  </done>
</task>

</tasks>

<verification>
Phase 16.4-01 routing invariant is enforced when:
1. `python -c "from objlib.constants import BOOK_SIZE_BYTES; print(BOOK_SIZE_BYTES)"` prints 830000
2. `grep -c "BOOK_SIZE_BYTES" src/objlib/extraction/batch_orchestrator.py` returns >= 2 (import + usage)
3. `grep -c "_mark_book" src/objlib/extraction/batch_orchestrator.py` returns >= 2 (definition + call)
4. `sqlite3 data/library.db "SELECT COUNT(*) FROM files WHERE ai_metadata_status='failed_validation'"` returns 0
5. `sqlite3 data/library.db "SELECT COUNT(*) FROM files WHERE ai_metadata_status='needs_review'"` returns 0
6. `sqlite3 data/library.db "SELECT COUNT(*) FROM files WHERE ai_metadata_status='pending' AND gemini_state='indexed'"` returns 41
7. Grep audit documents every ai_metadata_status reference across 6 source files
</verification>

<success_criteria>
- Named BOOK_SIZE_BYTES constant exists and is used for routing
- Byte check placed BEFORE read_text -- book files never loaded into memory
- Zero files with failed_validation or needs_review status
- 41 files pending re-extraction (40 Episodes + 1 Book)
- Layer 2 upload gate verified sound (no code change needed)
- Full grep audit of ai_metadata_status with per-file findings documented
- Any grep audit violations fixed inline and documented
</success_criteria>

<output>
After completion, create `.planning/phases/16.4-metadata-invariant-retrievability-audit/16.4-01-SUMMARY.md`
</output>
