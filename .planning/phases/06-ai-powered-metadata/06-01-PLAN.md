---
phase: 06-ai-powered-metadata
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - pyproject.toml
  - src/objlib/extraction/__init__.py
  - src/objlib/extraction/schemas.py
  - src/objlib/extraction/client.py
  - src/objlib/extraction/parser.py
  - src/objlib/database.py
  - src/objlib/config.py
  - src/objlib/cli.py
autonomous: true
# Scope note: 8 files across 3 subsystems (~55% context). Assessed for split into
# 01a (schema+DB) / 01b (client+parser+config) but deferred: tasks already cleanly
# separated, splitting would cascade into renumbering 06-02 through 06-05 depends_on
# references. Each task touches 4 files independently, staying within context budget.

must_haves:
  truths:
    - "Database schema v3 exists with ai_metadata_status, ai_confidence_score columns on files table"
    - "file_metadata_ai and file_primary_topics tables exist for versioned metadata storage"
    - "wave1_results table exists for competitive strategy comparison"
    - "Pydantic ExtractedMetadata model validates 4-tier hybrid metadata (category enum, primary_topics from controlled vocab, freeform aspects, semantic_description)"
    - "MistralClient can make async API calls to magistral-medium-latest with JSON mode, configurable temperature, and parse thinking+text array responses"
    - "Mistral API key is stored in and retrieved from system keyring (service: objlib-mistral)"
  artifacts:
    - path: "src/objlib/extraction/__init__.py"
      provides: "Extraction module package"
    - path: "src/objlib/extraction/schemas.py"
      provides: "Pydantic models for 4-tier metadata, controlled vocabulary, Category/Difficulty enums"
      contains: "class ExtractedMetadata"
    - path: "src/objlib/extraction/client.py"
      provides: "MistralClient wrapper with async API calls, JSON mode, configurable temperature, thinking block filtering"
      contains: "class MistralClient"
    - path: "src/objlib/extraction/parser.py"
      provides: "Two-phase response parser (structured array + regex fallback)"
      contains: "def parse_magistral_response"
    - path: "src/objlib/database.py"
      provides: "Schema v3 migration with new tables and columns"
      contains: "MIGRATION_V3_SQL"
  key_links:
    - from: "src/objlib/extraction/client.py"
      to: "mistralai SDK"
      via: "from mistralai import Mistral"
      pattern: "Mistral\\(api_key="
    - from: "src/objlib/extraction/client.py"
      to: "src/objlib/extraction/parser.py"
      via: "parse_magistral_response call"
      pattern: "parse_magistral_response"
    - from: "src/objlib/extraction/schemas.py"
      to: "pydantic"
      via: "BaseModel, Field, field_validator"
      pattern: "class ExtractedMetadata\\(BaseModel\\)"
---

<objective>
Build the foundation for Phase 6 AI-powered metadata extraction: database schema migration, Pydantic validation models with controlled vocabulary, Mistral API client with response parsing, and API key management.

Purpose: All subsequent Wave 1 and Wave 2 plans depend on these core building blocks -- schema, models, client, parser.
Output: New `src/objlib/extraction/` module with schemas, client, and parser; database migrated to v3; Mistral keyring entry supported.
</objective>

<execution_context>
@/Users/david/.claude/get-shit-done/workflows/execute-plan.md
@/Users/david/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-ai-powered-metadata/06-CONTEXT.md
@.planning/phases/06-ai-powered-metadata/06-RESEARCH.md
@.planning/phases/06-ai-powered-metadata/DECISION-HYBRID-TAXONOMY.md
@.planning/phases/06-ai-powered-metadata/CLARIFICATIONS-ANSWERED.md

@src/objlib/database.py
@src/objlib/models.py
@src/objlib/config.py
@src/objlib/cli.py
@pyproject.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Schema migration v3, Pydantic models, and controlled vocabulary</name>
  <files>
    src/objlib/extraction/__init__.py
    src/objlib/extraction/schemas.py
    src/objlib/database.py
    pyproject.toml
  </files>
  <action>
**1. Create `src/objlib/extraction/__init__.py`** -- empty package init.

**2. Create `src/objlib/extraction/schemas.py`** with:

- `Category` str enum with 7 values: `course_transcript`, `book_excerpt`, `qa_session`, `article`, `philosophy_comparison`, `concept_exploration`, `cultural_commentary`
- `Difficulty` str enum with 3 values: `intro`, `intermediate`, `advanced`
- `CONTROLLED_VOCABULARY` frozenset with exactly 40 Objectivist philosophy concept tags. Start with the ones listed in DECISION-HYBRID-TAXONOMY.md (epistemology, metaphysics, ethics, politics, aesthetics, reason, volition, rational_egoism, individual_rights, capitalism, objective_reality, consciousness, existence, identity, altruism, mysticism, collectivism, pragmatism, intrinsicism, subjectivism, determinism, concept_formation, free_will, emotions, rights_theory, art_theory, virtue_ethics). Fill remaining ~13 tags with important Objectivist concepts: `productiveness`, `honesty`, `independence`, `integrity`, `justice`, `benevolence`, `causality`, `logic`, `induction`, `values`, `happiness`, `self_interest`, `government`. Total: 40 tags.
- `SemanticDescription` Pydantic BaseModel with fields: `summary` (str, min_length=50), `key_arguments` (list[str], min_length=1), `philosophical_positions` (list[str], default_factory=list)
- `ExtractedMetadata` Pydantic BaseModel with: `category` (Category), `difficulty` (Difficulty), `primary_topics` (list[str], min_length=3, max_length=8), `topic_aspects` (list[str], min_length=3, max_length=10), `semantic_description` (SemanticDescription), `confidence_score` (float, ge=0.0, le=1.0). Use `model_config = ConfigDict(extra='ignore')`. Add `@field_validator('primary_topics')` that silently filters out tags not in CONTROLLED_VOCABULARY (per W2.A2 decision -- post-processing cleanup).
- `MetadataStatus` str enum: `pending`, `extracted`, `partial`, `needs_review`, `failed_json`, `failed_validation`, `retry_scheduled`, `approved`

**3. Add database migration v3 to `src/objlib/database.py`:**

Note: The existing `files` table uses `file_path TEXT PRIMARY KEY` (not integer IDs). All new tables use `file_path TEXT` as FK referencing `files(file_path)` to stay consistent with the existing schema. There is no separate `transcript` table -- all file records live in `files`.

Add `MIGRATION_V3_SQL` constant with:
- `ALTER TABLE files ADD COLUMN ai_metadata_status TEXT DEFAULT 'pending'` -- with CHECK constraint matching MetadataStatus values
- `ALTER TABLE files ADD COLUMN ai_confidence_score REAL`
- `CREATE TABLE IF NOT EXISTS file_metadata_ai` -- columns: metadata_id (PK AUTOINCREMENT), file_path TEXT NOT NULL (FK to files.file_path), metadata_json (TEXT NOT NULL), model (TEXT NOT NULL), model_version (TEXT), prompt_version (TEXT NOT NULL), extraction_config_hash (TEXT), is_current (BOOLEAN DEFAULT 1), created_at (TEXT DEFAULT strftime). Index on (file_path, is_current).
- `CREATE TABLE IF NOT EXISTS file_primary_topics` -- columns: file_path TEXT NOT NULL (FK to files.file_path), topic_tag (TEXT NOT NULL), PRIMARY KEY (file_path, topic_tag). Index on topic_tag.
- `CREATE TABLE IF NOT EXISTS wave1_results` -- columns: result_id (PK AUTOINCREMENT), file_path TEXT NOT NULL (FK to files.file_path), strategy (TEXT NOT NULL), metadata_json (TEXT NOT NULL), raw_response (TEXT), token_count (INTEGER), latency_ms (INTEGER), confidence_score (REAL), human_edit_distance (REAL), created_at (TEXT DEFAULT strftime).

Modify `_setup_schema` to:
1. Check `PRAGMA user_version` -- if already >=3, skip migration
2. If version == 2, run MIGRATION_V3_SQL
3. Set `PRAGMA user_version = 3`

Important: Use separate `ALTER TABLE` statements wrapped in try/except (SQLite ALTER TABLE ADD COLUMN fails if column already exists -- catch and ignore). For new tables, use `CREATE TABLE IF NOT EXISTS`.

**4. Add dependencies to `pyproject.toml`:**
- Add `"mistralai>=1.0"` to dependencies
- Add `"pydantic>=2.0"` to dependencies
- Add `"aiolimiter>=1.1"` to dependencies
  </action>
  <verify>
```bash
# Verify imports work and controlled vocabulary exact set
python -c "
from objlib.extraction.schemas import ExtractedMetadata, Category, Difficulty, CONTROLLED_VOCABULARY, MetadataStatus
print(f'Vocab size: {len(CONTROLLED_VOCABULARY)}')
assert len(CONTROLLED_VOCABULARY) == 40, f'Expected 40 tags, got {len(CONTROLLED_VOCABULARY)}'

# Verify the exact set of controlled vocabulary tags
EXPECTED_VOCAB = {
    'epistemology', 'metaphysics', 'ethics', 'politics', 'aesthetics',
    'reason', 'volition', 'rational_egoism', 'individual_rights', 'capitalism',
    'objective_reality', 'consciousness', 'existence', 'identity',
    'altruism', 'mysticism', 'collectivism', 'pragmatism', 'intrinsicism',
    'subjectivism', 'determinism', 'concept_formation', 'free_will',
    'emotions', 'rights_theory', 'art_theory', 'virtue_ethics',
    'productiveness', 'honesty', 'independence', 'integrity', 'justice',
    'benevolence', 'causality', 'logic', 'induction', 'values',
    'happiness', 'self_interest', 'government',
}
assert CONTROLLED_VOCABULARY == EXPECTED_VOCAB, f'Vocabulary mismatch. Missing: {EXPECTED_VOCAB - CONTROLLED_VOCABULARY}, Extra: {CONTROLLED_VOCABULARY - EXPECTED_VOCAB}'
print('Controlled vocabulary exact set verified')
"

# Verify schema validates correctly
python -c "
from objlib.extraction.schemas import ExtractedMetadata
m = ExtractedMetadata(
    category='course_transcript',
    difficulty='intermediate',
    primary_topics=['epistemology', 'concept_formation', 'reason'],
    topic_aspects=['measurement omission principle', 'unit-economy', 'hierarchical concepts'],
    semantic_description={'summary': 'A lecture on concept formation discussing measurement omission and unit-economy in epistemology.', 'key_arguments': ['Concepts formed by measuring similarities'], 'philosophical_positions': []},
    confidence_score=0.85
)
print(f'Valid: {m.category}, {m.difficulty}')
# Test invalid primary_topic gets filtered
m2 = ExtractedMetadata(
    category='qa_session',
    difficulty='intro',
    primary_topics=['epistemology', 'fake_topic', 'reason', 'ethics'],
    topic_aspects=['test aspect 1', 'test aspect 2', 'test aspect 3'],
    semantic_description={'summary': 'A Q&A session covering epistemology and ethics in the context of Objectivist philosophy.', 'key_arguments': ['Reason is primary'], 'philosophical_positions': []},
    confidence_score=0.7
)
print(f'Filtered topics: {m2.primary_topics}')
assert 'fake_topic' not in m2.primary_topics
"

# Verify database migration works
python -c "
from objlib.database import Database
import tempfile, os
db = Database(os.path.join(tempfile.mkdtemp(), 'test.db'))
# Check user_version is 3
ver = db.conn.execute('PRAGMA user_version').fetchone()[0]
assert ver == 3, f'Expected version 3, got {ver}'
# Check new columns exist
row = db.conn.execute('SELECT ai_metadata_status, ai_confidence_score FROM files LIMIT 0').fetchone()
# Check new tables exist
db.conn.execute('SELECT * FROM file_metadata_ai LIMIT 0')
db.conn.execute('SELECT * FROM file_primary_topics LIMIT 0')
db.conn.execute('SELECT * FROM wave1_results LIMIT 0')
print('Schema v3 migration OK')
db.close()
"

# Verify dependencies in pyproject.toml
grep -q "mistralai" pyproject.toml && grep -q "pydantic" pyproject.toml && grep -q "aiolimiter" pyproject.toml && echo "Dependencies OK"
```
  </verify>
  <done>
Pydantic ExtractedMetadata model validates all 4 tiers with controlled vocabulary filtering. Database schema v3 has ai_metadata_status, ai_confidence_score columns on files table, plus file_metadata_ai, file_primary_topics, and wave1_results tables. Dependencies added to pyproject.toml.
  </done>
</task>

<task type="auto">
  <name>Task 2: Mistral client wrapper, response parser, and API key management</name>
  <files>
    src/objlib/extraction/client.py
    src/objlib/extraction/parser.py
    src/objlib/config.py
    src/objlib/cli.py
  </files>
  <action>
**1. Create `src/objlib/extraction/parser.py`** with:

- `parse_magistral_response(response) -> dict` function implementing two-phase parsing:
  - Phase 1: If `response.choices[0].message.content` is a list, extract `text` segments (filter where `type == 'text'`), concatenate, and `json.loads()`.
  - Phase 2: If content is a string, try `json.loads()` directly.
  - Phase 3: Regex fallback -- find last complete JSON object (`{...}`) in string representation using `re.search(r'\{(?:[^{}]|\{[^{}]*\})*\}', text, re.DOTALL)`.
  - Phase 4: Raise `ValueError("No valid JSON found in response")`.
- Handle nested JSON objects in regex (the pattern should handle at least one level of nesting for the semantic_description field).

**2. Create `src/objlib/extraction/client.py`** with:

Concrete Mistral SDK integration:

```python
# Import paths (verified from mistralai>=1.0 SDK)
from mistralai import Mistral
from mistralai.models import SDKError  # HTTP error class with .status_code

# Import the parser
from objlib.extraction.parser import parse_magistral_response
```

- `class MistralClient`:
  - `__init__(self, api_key: str, model: str = "magistral-medium-latest")`:
    ```python
    self._client = Mistral(api_key=api_key)
    self._model = model
    ```
  - `async def extract_metadata(self, transcript_text: str, system_prompt: str, max_tokens: int = 8000, temperature: float = 1.0) -> tuple[dict, int]`:
    ```python
    try:
        response = await self._client.chat.complete_async(
            model=self._model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": transcript_text},
            ],
            temperature=temperature,
            max_tokens=max_tokens,
            response_format={"type": "json_object"},
        )
        parsed = parse_magistral_response(response)
        return (parsed, response.usage.total_tokens)
    except SDKError as e:
        if e.status_code == 402:
            raise CreditExhaustedException(f"Mistral credits exhausted: {e}") from e
        elif e.status_code == 429:
            raise RateLimitException(f"Mistral rate limit hit: {e}") from e
        raise
    ```
    - The `temperature` parameter defaults to 1.0 (required for magistral production use). Wave 1 strategies override this per-lane (0.1, 0.3, 0.5) as experiments.
    - Response JSON parsing is handled by `parse_magistral_response()` which extracts JSON from the magistral thinking+text content array.
    - Returns `(parsed_dict, total_tokens)` for tracking cost and usage.
  - Define custom exceptions in this module:
    ```python
    class CreditExhaustedException(Exception):
        """Raised when Mistral API returns HTTP 402 (Payment Required)."""
        pass

    class RateLimitException(Exception):
        """Raised when Mistral API returns HTTP 429 (Too Many Requests)."""
        pass
    ```

Note: Regression testing with a gold set of expected outputs is deferred to a future task. This plan establishes the core extraction infrastructure; Wave 1 execution (Plan 03) will produce the first real outputs for validation.

Note: Per research, magistral models REQUIRE temperature=1.0. Do NOT set any other temperature in production. Wave 1 strategy lanes A and B intentionally use lower temperatures as experiments -- those may produce degraded results and that's expected.

**3. Extend `src/objlib/config.py`:**

Add functions parallel to existing Gemini key management:
- `def get_mistral_api_key() -> str` -- reads from keyring service `objlib-mistral`, key `api_key`. Raises `RuntimeError` if not found with helpful message: "Mistral API key not found. Set it with: objlib config set-mistral-key YOUR_KEY"
- `def get_mistral_api_key_from_keyring() -> str` -- same as above (mirror the naming pattern of `get_api_key_from_keyring`).

**4. Extend `src/objlib/cli.py`:**

Add to the `config_app` Typer group:
- `@config_app.command("set-mistral-key")` -- stores key in keyring service `objlib-mistral`, key `api_key`. Same pattern as existing `set-api-key` command.
- `@config_app.command("get-mistral-key")` -- retrieves and displays masked Mistral API key. Same pattern as existing `get-api-key` command.
- `@config_app.command("remove-mistral-key")` -- deletes Mistral API key from keyring. Same pattern as existing `remove-api-key` command.
  </action>
  <verify>
```bash
# Verify parser works with simulated responses matching Mistral SDK structure
# Note: Mistral SDK ChatCompletionResponse.choices[0].message.content is either:
#   - A list of ContentChunk objects (each with .type and .text attrs) for magistral models
#   - A plain string for non-reasoning models
python -c "
from objlib.extraction.parser import parse_magistral_response
import json
from types import SimpleNamespace

# Build mock matching actual Mistral SDK ChatCompletionResponse structure:
# response.choices[0].message.content = [ContentChunk(type='thinking', text='...'), ContentChunk(type='text', text='{...}')]
def make_response(content):
    return SimpleNamespace(choices=[SimpleNamespace(message=SimpleNamespace(content=content))])

# Test 1: Array format with thinking + text ContentChunk objects (magistral models)
resp = make_response([
    SimpleNamespace(type='thinking', text='Let me analyze this philosophical text...'),
    SimpleNamespace(type='text', text=json.dumps({'category': 'course_transcript', 'difficulty': 'intro'}))
])
result = parse_magistral_response(resp)
assert result['category'] == 'course_transcript'
print('Array parse (thinking+text) OK')

# Test 2: Plain string content (non-reasoning mode or JSON mode)
resp2 = make_response(json.dumps({'category': 'qa_session'}))
result2 = parse_magistral_response(resp2)
assert result2['category'] == 'qa_session'
print('String parse OK')

# Test 3: Regex fallback for malformed responses
resp3 = make_response('Some preamble text {\"category\": \"article\"} trailing text')
result3 = parse_magistral_response(resp3)
assert result3['category'] == 'article'
print('Regex fallback OK')

print('Parser tests passed')
"

# Verify client module imports
python -c "from objlib.extraction.client import MistralClient, CreditExhaustedException, RateLimitException; print('Client imports OK')"

# Verify config functions exist
python -c "from objlib.config import get_mistral_api_key; print('Config OK')"

# Verify CLI commands registered
python -m objlib config --help 2>&1 | grep -q "set-mistral-key" && echo "CLI commands OK"
```
  </verify>
  <done>
MistralClient wraps magistral-medium-latest with async API calls, temperature=1.0, JSON mode, and thinking block filtering via two-phase parser. CreditExhaustedException and RateLimitException are defined. Mistral API key management added to config.py and CLI (set-mistral-key, get-mistral-key, remove-mistral-key).
  </done>
</task>

</tasks>

<verification>
```bash
# Full integration verification
python -c "
# 1. Schema imports
from objlib.extraction.schemas import ExtractedMetadata, Category, Difficulty, CONTROLLED_VOCABULARY, MetadataStatus, SemanticDescription
assert len(CONTROLLED_VOCABULARY) == 40
assert len(Category) == 7
assert len(Difficulty) == 3

# 2. Client imports
from objlib.extraction.client import MistralClient, CreditExhaustedException, RateLimitException

# 3. Parser imports
from objlib.extraction.parser import parse_magistral_response

# 4. Database migration
from objlib.database import Database
import tempfile, os
db = Database(os.path.join(tempfile.mkdtemp(), 'test.db'))
ver = db.conn.execute('PRAGMA user_version').fetchone()[0]
assert ver == 3
db.conn.execute('SELECT ai_metadata_status, ai_confidence_score FROM files LIMIT 0')
db.conn.execute('SELECT metadata_id, file_path, metadata_json, model, prompt_version, is_current FROM file_metadata_ai LIMIT 0')
db.conn.execute('SELECT file_path, topic_tag FROM file_primary_topics LIMIT 0')
db.conn.execute('SELECT result_id, file_path, strategy, metadata_json, human_edit_distance FROM wave1_results LIMIT 0')
db.close()

# 5. Config
from objlib.config import get_mistral_api_key

print('All Phase 6 Plan 01 verifications passed')
"
```
</verification>

<success_criteria>
- `src/objlib/extraction/` module exists with schemas.py, client.py, parser.py
- Pydantic ExtractedMetadata validates all 4 tiers, filters invalid primary_topics silently
- CONTROLLED_VOCABULARY has exactly 40 tags
- Database schema v3 applied with new columns and tables
- MistralClient wraps magistral-medium-latest with thinking+text response handling
- Two-phase parser handles array, string, and regex-fallback formats
- Mistral API key CLI commands (set/get/remove) work
- All verification commands pass
</success_criteria>

<output>
After completion, create `.planning/phases/06-ai-powered-metadata/06-01-SUMMARY.md`
</output>
