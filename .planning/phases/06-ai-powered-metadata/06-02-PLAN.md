---
phase: 06-ai-powered-metadata
plan: 02
type: execute
wave: 2
depends_on: ["06-01"]
files_modified:
  - src/objlib/extraction/prompts.py
  - src/objlib/extraction/strategies.py
  - src/objlib/extraction/checkpoint.py
  - src/objlib/extraction/orchestrator.py
  - src/objlib/extraction/sampler.py
autonomous: true

must_haves:
  truths:
    - "Three prompt strategies (Minimalist, Teacher, Reasoner) are defined with distinct structural archetypes"
    - "Test file selector can pick 20 files via stratified sampling by size, including podcast vs non-podcast distribution"
    - "Orchestrator can process files through 3 competitive lanes concurrently (within 3-thread/60-rpm limits)"
    - "Checkpoint manager saves state atomically per-file and handles credit exhaustion (HTTP 402) with clean pause"
    - "Resume from checkpoint skips already-completed files and continues from last position"
  artifacts:
    - path: "src/objlib/extraction/prompts.py"
      provides: "System prompts, user prompt template, and JSON schema injection for Mistral magistral model"
      contains: "def build_system_prompt"
    - path: "src/objlib/extraction/strategies.py"
      provides: "Wave 1 strategy lane definitions (Minimalist, Teacher, Reasoner)"
      contains: "class StrategyLane"
    - path: "src/objlib/extraction/checkpoint.py"
      provides: "Atomic checkpoint save/load with credit exhaustion handling"
      contains: "class CheckpointManager"
    - path: "src/objlib/extraction/orchestrator.py"
      provides: "Async batch orchestrator with semaphore, rate limiter, and per-lane tracking"
      contains: "class ExtractionOrchestrator"
    - path: "src/objlib/extraction/sampler.py"
      provides: "Stratified test file selection from database"
      contains: "def select_test_files"
  key_links:
    - from: "src/objlib/extraction/orchestrator.py"
      to: "src/objlib/extraction/client.py"
      via: "MistralClient.extract_metadata call in process loop"
      pattern: "self._client\\.extract_metadata"
    - from: "src/objlib/extraction/orchestrator.py"
      to: "src/objlib/extraction/checkpoint.py"
      via: "checkpoint.save on CreditExhaustedException"
      pattern: "CreditExhaustedException"
    - from: "src/objlib/extraction/strategies.py"
      to: "src/objlib/extraction/prompts.py"
      via: "Each strategy lane references a prompt builder"
      pattern: "build_system_prompt\\|build_user_prompt"
---

<objective>
Build the Wave 1 discovery infrastructure: prompt strategy definitions, test file selector, competitive lane orchestrator, and checkpoint/resume system.

Purpose: Enable running 3 competing prompt strategies (Minimalist, Teacher, Reasoner) against 20 stratified test files to discover the optimal extraction approach before committing to full-scale processing.
Output: Complete Wave 1 execution machinery ready to be triggered by CLI commands in Plan 03.
</objective>

<execution_context>
@/Users/david/.claude/get-shit-done/workflows/execute-plan.md
@/Users/david/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-ai-powered-metadata/06-CONTEXT.md
@.planning/phases/06-ai-powered-metadata/06-RESEARCH.md
@.planning/phases/06-ai-powered-metadata/CLARIFICATIONS-ANSWERED.md
@.planning/phases/06-ai-powered-metadata/DECISION-HYBRID-TAXONOMY.md
@.planning/phases/06-ai-powered-metadata/06-01-SUMMARY.md

@src/objlib/extraction/schemas.py
@src/objlib/extraction/client.py
@src/objlib/extraction/parser.py
@src/objlib/database.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Prompt templates, strategy lanes, and test file sampler</name>
  <files>
    src/objlib/extraction/prompts.py
    src/objlib/extraction/strategies.py
    src/objlib/extraction/sampler.py
  </files>
  <action>
**1. Create `src/objlib/extraction/prompts.py`** with:

- `PROMPT_VERSION = "1.0.0"` constant
- `def build_system_prompt(strategy: str) -> str` -- returns the system prompt tailored to a strategy:
  - All strategies share: "You are an Objectivist philosophy archivist. Return ONLY valid JSON matching the schema below."
  - Minimalist: Bare schema definition, no examples. Instruction: "Classify this philosophical text. Return JSON only."
  - Teacher: Includes 1 complete few-shot example (use the OPAR example from DECISION-HYBRID-TAXONOMY.md). Instruction: "Follow the example format exactly."
  - Reasoner: Adds chain-of-thought instruction: "First analyze the philosophical content: identify the main topic, determine if it's a lecture/Q&A/essay, assess difficulty. Then generate the JSON output."
- `def build_user_prompt(transcript_text: str, strategy: str) -> str` -- wraps transcript with appropriate framing. Minimalist: just the text. Teacher: "Here is the text to classify:" + text. Reasoner: "Analyze and classify:" + text.
- `def get_schema_for_prompt() -> str` -- returns a compact JSON schema string generated from `ExtractedMetadata.model_json_schema()`, plus the 40-tag controlled vocabulary list and 7 category options explicitly listed.
- Include the controlled vocabulary and category list in the schema prompt section, formatted as numbered lists for LLM clarity.

**2. Create `src/objlib/extraction/strategies.py`** with:

- `@dataclass class StrategyConfig`: name (str), system_prompt_strategy (str -- "minimalist"|"teacher"|"reasoner"), temperature (float), description (str)
- `WAVE1_STRATEGIES`: dict mapping strategy name to StrategyConfig:
  - `"minimalist"`: StrategyConfig(name="minimalist", system_prompt_strategy="minimalist", temperature=0.1, description="Zero-shot strict JSON schema, lowest cost")
  - `"teacher"`: StrategyConfig(name="teacher", system_prompt_strategy="teacher", temperature=0.3, description="One-shot with example, focus on structure")
  - `"reasoner"`: StrategyConfig(name="reasoner", system_prompt_strategy="reasoner", temperature=0.5, description="Chain-of-thought, focus on accuracy/nuance")

Note per research: magistral-medium-latest requires temperature=1.0 in production. Wave 1 intentionally uses lower temperatures as experiments. Lane A/B may produce degraded results -- that IS useful data. Document this in a comment.

- `@dataclass class StrategyLane`: config (StrategyConfig), completed_files (list[str]), failed_files (list[str]), total_tokens (int)
  - Method `progress_pct(self, total: int) -> float` returning completion percentage.

**3. Create `src/objlib/extraction/sampler.py`** with:

- `def select_test_files(db: Database, n: int = 20) -> list[dict]`:
  - Query the database for all TXT files with `category = 'unknown'` (using `json_extract(metadata_json, '$.category') = 'unknown'` AND `filename LIKE '%.txt'`)
  - Get file_path, filename, file_size, metadata_json for each
  - Parse metadata to check for `series == 'Peikoff Podcast'` (podcast vs non-podcast)
  - Stratify into buckets per research findings (adjusted boundaries since only 2 files <5KB):
    - Small (<10KB): 4 files
    - Medium (10-30KB): 6 files
    - Large (30-100KB): 6 files
    - Very large (>100KB): 4 files
  - Within each bucket, balance podcast vs non-podcast (at least 1 podcast per bucket where available)
  - Use `random.sample()` with seed for reproducibility: `random.seed(42)`
  - If a bucket has fewer files than requested, take all available and redistribute to other buckets
  - Return list of dicts with: file_path, filename, file_size, is_podcast (bool), bucket (str)
  - Print selection summary to console using Rich table
  </action>
  <verify>
```bash
# Verify prompt construction
python -c "
from objlib.extraction.prompts import build_system_prompt, build_user_prompt, get_schema_for_prompt, PROMPT_VERSION
print(f'Prompt version: {PROMPT_VERSION}')
for s in ['minimalist', 'teacher', 'reasoner']:
    sp = build_system_prompt(s)
    assert len(sp) > 100, f'{s} system prompt too short'
    print(f'{s} system prompt: {len(sp)} chars')
schema = get_schema_for_prompt()
assert 'epistemology' in schema  # Controlled vocab present
assert 'course_transcript' in schema  # Category enum present
print('Prompts OK')
"

# Verify strategy definitions
python -c "
from objlib.extraction.strategies import WAVE1_STRATEGIES, StrategyConfig, StrategyLane
assert len(WAVE1_STRATEGIES) == 3
for name, config in WAVE1_STRATEGIES.items():
    assert isinstance(config, StrategyConfig)
    print(f'{name}: temp={config.temperature}, desc={config.description[:40]}')
print('Strategies OK')
"

# Verify sampler function exists and handles empty DB
python -c "
from objlib.extraction.sampler import select_test_files
print('Sampler imports OK')
"
```
  </verify>
  <done>
Three strategy lanes defined (Minimalist/temp=0.1, Teacher/temp=0.3, Reasoner/temp=0.5) with distinct prompt archetypes. Prompt builder generates system prompts with schema injection and controlled vocabulary. Stratified sampler selects 20 test files balanced by size and podcast/non-podcast distribution.
  </done>
</task>

<task type="auto">
  <name>Task 2: Extraction orchestrator with checkpoint/resume and credit exhaustion handling</name>
  <files>
    src/objlib/extraction/checkpoint.py
    src/objlib/extraction/orchestrator.py
  </files>
  <action>
**1. Create `src/objlib/extraction/checkpoint.py`** with:

- `class CheckpointManager`:
  - `__init__(self, checkpoint_dir: Path = Path("data"))` -- sets checkpoint path to `data/wave1_checkpoint.json` (or parameterized)
  - `def save(self, state: dict) -> None` -- atomic write: write to `.tmp` file then rename. State dict includes: wave (str), lanes (dict of lane_name -> {completed: list[str], failed: list[str], tokens: int}), next_file_index (int), timestamp (ISO string), prompt_version (str).
  - `def load(self) -> dict | None` -- returns checkpoint dict or None if no file exists.
  - `def clear(self) -> None` -- deletes checkpoint file if exists.
  - `@property def exists(self) -> bool` -- checks if checkpoint file exists.

- `class CreditExhaustionHandler`:
  - `def display_pause_notification(self, lanes: dict, total_calls: int, estimated_cost: float) -> None` -- prints Rich Panel with red border showing: wave progress per lane, total API calls, estimated cost, instructions to fund and resume. Uses the format from 06-CONTEXT.md W1.6 decision.

**2. Create `src/objlib/extraction/orchestrator.py`** with:

- `class ExtractionOrchestrator`:
  - `__init__(self, client: MistralClient, db: Database, checkpoint: CheckpointManager, config: ExtractionConfig)`:
    - Stores references to client, db, checkpoint
    - Creates `asyncio.Semaphore(3)` for concurrency
    - Creates `AsyncLimiter(60, 60)` from aiolimiter for 60 req/min rate limiting
    - `config` is a simple dataclass with: max_concurrent (int=3), rate_limit_rpm (int=60), max_retries (int=2)
  - `@dataclass class ExtractionConfig`: max_concurrent (int=3), rate_limit_rpm (int=60), max_retries (int=2)

  - `async def run_wave1(self, test_files: list[dict], strategies: dict[str, StrategyConfig]) -> dict`:
    - For each file in test_files, for each strategy:
      - Read file content from disk (file_path)
      - Build system prompt and user prompt for the strategy
      - Call `self._process_one(file_path, transcript, strategy)` with semaphore + rate limiter (strategy's temperature passed through to `extract_metadata(temperature=strategy.temperature)`)
      - Save result to `wave1_results` table immediately (atomic per-file per-strategy)
      - Track timing (latency_ms) and token count
    - Handle `CreditExhaustedException`: save checkpoint, display pause notification, call `sys.exit(0)`
    - Handle `RateLimitException`: exponential backoff with jitter (2^retry + random 0-1), max 5 retries
    - If resuming from checkpoint: load checkpoint, skip already-completed (file, strategy) pairs
    - Return summary dict: {strategy_name: {completed: int, failed: int, total_tokens: int, avg_latency_ms: float}}

  - `async def _process_one(self, file_path: str, transcript: str, strategy: StrategyConfig) -> dict`:
    - Acquire semaphore and rate limiter
    - Build prompts using `build_system_prompt(strategy.system_prompt_strategy)` and `build_user_prompt(transcript, strategy.system_prompt_strategy)`
    - Time the API call
    - Call `self._client.extract_metadata(transcript_text=user_prompt, system_prompt=system_prompt, max_tokens=8000, temperature=strategy.temperature)`
    - Validate response against `ExtractedMetadata` Pydantic model (catch `ValidationError`)
    - Return result dict with: metadata (validated dict), tokens (int), latency_ms (int), confidence_score (float), validation_status (str)

  - `def _save_wave1_result(self, file_path: str, strategy: str, result: dict) -> None`:
    - INSERT into wave1_results table: file_path, strategy, metadata_json (json.dumps of result['metadata'])), token_count, latency_ms, confidence_score.
    - If raw_response storage is enabled (debug mode), include raw_response.

  - `async def run_production(self, files: list[dict], prompt_template: str) -> dict`:
    - Placeholder for Wave 2 production processing (implemented in Plan 04)
    - Raise NotImplementedError for now with message "Wave 2 production processing implemented in Plan 04"

Important implementation notes:
- The orchestrator must handle the case where the Mistral SDK does NOT support per-request temperature override. In that case, create a new client instance per strategy lane (each with its own temperature). Check the mistralai SDK -- temperature is passed per-call in `chat.complete_async()`, not at client level. So it's fine.
- Save wave1 results to database IMMEDIATELY after each file+strategy (not in batch). This ensures checkpoint resume has accurate progress.
  </action>
  <verify>
```bash
# Verify checkpoint manager
python -c "
import tempfile, os, json
from pathlib import Path
from objlib.extraction.checkpoint import CheckpointManager

tmpdir = Path(tempfile.mkdtemp())
cp = CheckpointManager(tmpdir)
assert not cp.exists

# Save checkpoint
state = {'wave': 'wave1', 'lanes': {'minimalist': {'completed': ['f1.txt'], 'failed': [], 'tokens': 100}}, 'next_file_index': 1, 'timestamp': '2026-02-16T12:00:00'}
cp.save(state)
assert cp.exists

# Load checkpoint
loaded = cp.load()
assert loaded['wave'] == 'wave1'
assert loaded['lanes']['minimalist']['completed'] == ['f1.txt']

# Clear
cp.clear()
assert not cp.exists
print('Checkpoint manager OK')
"

# Verify orchestrator imports and config
python -c "
from objlib.extraction.orchestrator import ExtractionOrchestrator, ExtractionConfig
config = ExtractionConfig()
assert config.max_concurrent == 3
assert config.rate_limit_rpm == 60
print('Orchestrator imports OK')
"

# Verify credit exhaustion handler
python -c "
from objlib.extraction.checkpoint import CreditExhaustionHandler
handler = CreditExhaustionHandler()
print('Credit exhaustion handler OK')
"
```
  </verify>
  <done>
ExtractionOrchestrator processes files through 3 competitive strategy lanes with asyncio semaphore (3 concurrent) and aiolimiter (60 req/min). Results saved atomically per-file per-strategy to wave1_results table. CheckpointManager handles atomic save/load for credit exhaustion pause/resume. CreditExhaustionHandler displays Rich notification panel.
  </done>
</task>

</tasks>

<verification>
```bash
# Integration test: all Wave 1 infrastructure modules work together
python -c "
from objlib.extraction.schemas import ExtractedMetadata, CONTROLLED_VOCABULARY
from objlib.extraction.client import MistralClient, CreditExhaustedException
from objlib.extraction.parser import parse_magistral_response
from objlib.extraction.prompts import build_system_prompt, build_user_prompt, get_schema_for_prompt
from objlib.extraction.strategies import WAVE1_STRATEGIES, StrategyLane
from objlib.extraction.checkpoint import CheckpointManager, CreditExhaustionHandler
from objlib.extraction.orchestrator import ExtractionOrchestrator, ExtractionConfig
from objlib.extraction.sampler import select_test_files

# Verify all 3 strategies produce valid prompts
for name, config in WAVE1_STRATEGIES.items():
    sp = build_system_prompt(config.system_prompt_strategy)
    schema = get_schema_for_prompt()
    assert 'epistemology' in schema
    assert 'course_transcript' in schema

print('All Wave 1 infrastructure modules verified')
"
```
</verification>

<success_criteria>
- 3 prompt strategies produce distinct system prompts (zero-shot / one-shot / chain-of-thought)
- Stratified sampler selects 20 files balanced by size bucket and podcast/non-podcast
- Orchestrator enforces 3-concurrent + 60-rpm rate limits via asyncio
- Checkpoint manager saves/loads state atomically
- Credit exhaustion (HTTP 402) triggers clean pause with Rich notification
- Resume from checkpoint skips completed file+strategy pairs
- Wave 1 results saved to database per-file per-strategy
</success_criteria>

<output>
After completion, create `.planning/phases/06-ai-powered-metadata/06-02-SUMMARY.md`
</output>
