# CLARIFICATIONS-ANSWERED.md

## Phase 16.2: Metadata Completeness Invariant Enforcement — Decisions

**Generated:** 2026-02-24
**Mode:** YOLO (balanced strategy — all consensus/recommended options selected)
**Source:** Auto-generated by meta-gsd:discuss-phase-ai --yolo

---

## Decision Summary

**Total questions:** 6
**Tier 1 (Blocking):** 4 answered
**Tier 2 (Important):** 2 answered

---

## Tier 1: Blocking Decisions

### Q1: Authoritative source for "primary_topics populated"

**YOLO DECISION:** **Option A — `file_primary_topics` junction table**

**Rationale:**
- Confidence: ✅ Consensus across all 3 providers
- "Populated" = `EXISTS (SELECT 1 FROM file_primary_topics WHERE file_path = f.file_path)`
- Catches the 21 approved .txt books that have `file_metadata_ai` rows but no topic rows
- Aligns with how search uses topics (via join table, not JSON blob)
- Stronger invariant than metadata_json check (detects insertion failures)

**Implementation note:** Audit query for violations:
```sql
SELECT f.file_path, f.filename
FROM files f
WHERE f.ai_metadata_status = 'approved'
  AND f.is_deleted = 0
  AND NOT EXISTS (
    SELECT 1 FROM file_primary_topics pt WHERE pt.file_path = f.file_path
  )
```
Current violations: **21 files** (all approved .txt book exports, must be remediated before audit exits 0)

---

### Q2: Scope of the audit — all 1885 files

**YOLO DECISION:** **Option A — all 1885 DB-tracked files**

**Rationale:**
- Confidence: ✅ Consensus across all 3 providers
- Every file in the DB must satisfy exactly one of: AI-enriched, explicitly skipped with reason, or pending-with-reason
- Leaving .pdf/.docx silently pending perpetuates the silent bypass problem the phase is designed to eliminate
- The audit reports a breakdown by extension to make the scope clear

**Audit invariant (all four conditions must hold for exit 0):**
1. Zero approved files without `file_primary_topics` entries
2. Zero skipped files with `error_message IS NULL OR error_message = ''`
3. Zero pending files with extensions NOT IN (.txt, .md) — all non-enrichable formats must be classified
4. Phase 16.3 readiness: MOTM and Other-stem categories at 100% primary_topics coverage

---

### Q3: Remediation path for 21 approved .txt books without primary_topics

**YOLO DECISION:** **Option A first (backfill from metadata_json), then Option B (re-extract) for any file where A finds no topics**

**Rationale:**
- Confidence: ✅ Recommended by Gemini and Perplexity; aligns with sacred metadata constraint
- Step 1: For each of the 21 files, check `json_extract(m.metadata_json, '$.primary_topics')`
- Step 2: If non-empty array found in JSON → INSERT rows into `file_primary_topics` (no API call)
- Step 3: If JSON has no primary_topics → reset to `pending`, include in next `batch-extract`
- Respects sacred metadata rule: we're reading existing data, not replacing or deleting it

**Implementation note for 16.2-01:** This is a one-time backfill script / migration step. It runs as part of the remediation sequence before the final audit verification. Expected outcome: all 21 files either get their topics backfilled from JSON, or are re-queued for extraction.

---

### Q4: MOTM and Other-stem identification for Phase 16.3 readiness row

**YOLO DECISION:** **Option A — file path pattern matching**

**Rationale:**
- Confidence: ✅ Recommended by OpenAI and Perplexity; DB evidence rules out Option B
- `MOTM` = files where `file_path LIKE '%/MOTM/%'` — must confirm exact folder name during 16.2-01 implementation by running `SELECT DISTINCT` on file_path patterns
- `Other-stem` = files NOT in MOTM where `json_extract(m.metadata_json, '$.topic')` approximately equals filename stem — use the Phase 16.1 triage characterization (440 files) as reference denominator
- Readiness gate for Phase 16.3: both categories at 100% primary_topics coverage

**Sub-decision — Other-stem identification SQL:**
```sql
-- Other-stem: topic matches the filename-without-extension pattern
-- (exact logic to be validated during implementation against Phase 16.1's 440-file count)
SELECT COUNT(*) FROM files f
JOIN file_metadata_ai m ON f.file_path = m.file_path AND m.is_current = 1
WHERE f.file_path NOT LIKE '%/MOTM/%'
  AND f.ai_metadata_status = 'approved'
  AND json_extract(m.metadata_json, '$.topic') IS NOT NULL
  -- topic == stem means the scanner couldn't find discriminating content
  -- specific comparison to be calibrated against the known 440-file count
```

---

## Tier 2: Important Decisions

### Q5: Single backfill for all non-enrichable formats

**YOLO DECISION:** **Single backfill pass covering all non-enrichable formats (epub + pdf + docx + other)**

**Rationale:**
- Confidence: ⚠️ Clear consensus from requirements
- One `objlib metadata mark-unsupported` (or `backfill-skipped`) command handles:
  - Update 26 skipped epubs: set `error_message = 'epub format: text extraction not supported in v2.0'`
  - Mark 59 pending pdfs as skipped with `error_message = 'pdf format: text extraction not supported in v2.0'`
  - Mark 51 pending docx/other files as skipped with `error_message = 'unsupported format: text extraction not supported in v2.0'`
- The Bernstein .md file is the ONLY non-.txt file that gets batch-extracted, not skipped
- This reduces 111 pending files to ~1 (the .md file), which batch-extract handles after `_get_pending_files()` fix

---

### Q6: Audit output format — Rich text only for Phase 16.2

**YOLO DECISION:** **Rich text only (no --format json for Phase 16.2)**

**Rationale:**
- Confidence: ⚠️ Practical decision given phase scope
- Phase 16.2 gate is verified manually by running audit and reading output
- Phase 16.3 gating uses `check_stability.py`, not `metadata audit`
- JSON output can be added in Phase 16.3 if automation requires it
- Keeping it simple reduces implementation scope

---

### Q7: MOTM discriminating subject — metadata quality check + Mistral re-extraction (REVISED — 2026-02-24)

**DECISION REVISED:** ~~Option A (slug backfill)~~ → **Option C — structural metadata quality check triggers Mistral batch re-extraction**

**Governing principle (from MEMORY.md):** All enrichable non-book files receive metadata exclusively through `objlib metadata batch-extract` (Mistral Batch API). Heuristic fallbacks (filename slug injection, manual field-writes) are not authorized metadata sources — they produce a two-tier provenance invisible to downstream consumers.

**Correct diagnosis:** MOTM files have `approved` status, but the extraction produced low-quality output: `topic` field is NULL in all 469 files, and `primary_topics` are exclusively generic controlled-vocabulary terms with no file-specific content. This is a **Mistral extraction quality failure**, not a new data-entry problem. The fix is re-extraction, not a workaround.

**Decision:**
1. **Structural metadata quality check** — Phase 16.2 defines and implements a quality gate that distinguishes "fields are structurally populated" from "fields contain file-specific AI-extracted content." Quality failure signals (deterministic, no API calls):
   - `metadata_json->>'topic'` is NULL or empty AND file is `.txt` or `.md` (enrichable)
   - `primary_topics` are present but drawn exclusively from the top-N most frequent corpus-wide terms (all entries match a "generic boilerplate" set — to be calibrated against corpus frequency data)
   - Either condition alone is sufficient to flag as quality-failure
2. **Re-extraction via Mistral batch-extract** — any file failing the quality check is reset to `ai_metadata_status='pending'` and included in the next `batch-extract` run, identical to how any unextracted file is handled. MOTM files are not special-cased; they go through the same pipeline as all other `.txt` files.
3. **Books follow established skip path** — epub/pdf/docx are marked `skipped` with named reason, unchanged.
4. **Phase 16.3 readiness gate** — audit readiness row checks that all MOTM and Other-stem files have `metadata_json->>'topic'` populated (sourced from Mistral extraction, not heuristics). Phase 16.3 cannot proceed until all quality-failed files have been re-extracted and re-approved.

**Rationale:**
- Respects the extraction-provenance invariant: Mistral is the sole authorized source for `topic`, `primary_topics`, and all other AI metadata fields
- Produces genuinely discriminating metadata (Mistral will extract the actual session topic from transcript content, not the filename)
- Generalizes correctly: the quality check applies to ALL approved files, not just MOTM — any file with low-quality extraction is caught
- The sacred metadata constraint applies to *deleting* existing metadata; resetting to `pending` for re-extraction of poor-quality fields is permitted (we are not wiping `metadata_json`, we are re-running extraction and merging results)

**Implementation note:** Before resetting any file to `pending`, verify that `metadata_json` has at least a skeleton entry (not NULL) — the re-extraction will update it in-place via the existing `_save_extracted_metadata()` path which does a merge, not a replace.

---

## Implementation Sequence (informs 16.2-01 plan)

Based on all decisions above, the recommended implementation order:

**16.2-01:**
1. Confirm MOTM folder name via `SELECT DISTINCT` on file_path patterns (expected: `/MOTM/`)
2. Implement `objlib metadata mark-unsupported` command — marks pdf/docx/other as skipped with named reason; also updates 26 epub skip reasons (error_message was NULL)
3. Fix `_get_pending_files()` in `batch_orchestrator.py` to include `LIKE '%.md'`
4. **Define and implement structural metadata quality check** — query DB for: (a) approved .txt/.md files with NULL `metadata_json->>'topic'`, (b) approved files with file_primary_topics entries that are exclusively from a boilerplate-generic set (top-N corpus frequency calibration). Produce a report: which files fail, by how many and which criteria.
5. **Reset quality-failed files to `pending`** — all files identified in step 4 get `ai_metadata_status='pending'` for re-extraction. Expected: all 469 MOTM files + any other quality-failed files. Also reset the 21 approved .txt books without `file_primary_topics` rows.
6. Run `batch-extract` on all newly-pending enrichable files (Bernstein .md + quality-failed .txt files including all MOTM). This is a Mistral Batch API call — same path as all other files.
7. Implement `objlib metadata audit` command with all invariant checks + Phase 16.3 readiness row (MOTM topic coverage, Other-stem primary_topics coverage)

**16.2-02:**
1. Run `metadata audit` and verify exit 0
2. Confirm Bernstein .md has primary_topics and topic field populated (from Mistral extraction)
3. Confirm no silent-pending files remain
4. Confirm Phase 16.3 readiness row shows 100% for: MOTM `topic` field populated (from Mistral), MOTM primary_topics, Other-stem primary_topics

---

## YOLO Confidence Summary

All 7 decisions made at ✅/⚠️ confidence level. Q7 was revised (2026-02-24): slug-backfill rejected in favor of structural quality check + Mistral re-extraction, enforcing the extraction-provenance invariant. The main implementation-time task is calibrating the "generic boilerplate" primary_topics set for the quality check — to be derived from corpus frequency analysis in 16.2-01.

---

*Auto-generated by meta-gsd:discuss-phase-ai --yolo (balanced strategy)*
*Human review recommended before final implementation*
*Generated: 2026-02-24; Q7 appended 2026-02-24 (MOTM topic backfill concern)*
