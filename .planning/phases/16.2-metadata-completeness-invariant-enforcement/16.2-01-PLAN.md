---
phase: 16.2-metadata-completeness-invariant-enforcement
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/objlib/cli.py
  - src/objlib/extraction/batch_orchestrator.py
autonomous: true

must_haves:
  truths:
    - "All 26 epub files have ai_metadata_status='skipped' with non-NULL error_message"
    - "All 59 pdf files have ai_metadata_status='skipped' with named reason"
    - "All 42 html and 9 docx files have ai_metadata_status='skipped' with named reason"
    - "_get_pending_files() returns .md files alongside .txt files"
    - "21 approved .txt books that had primary_topics in metadata_json now have file_primary_topics rows"
    - "All 468 MOTM approved .txt files are reset to pending for re-extraction"
    - "All files failing Signal B quality check (all-boilerplate primary_topics) are reset to pending"
    - "batch-extract completes on all newly-pending enrichable files"
    - "objlib metadata audit command exists, reports per-category breakdown, and exits non-zero when violations exist"
    - "objlib metadata mark-unsupported command exists and marks non-enrichable extensions"
  artifacts:
    - path: "src/objlib/cli.py"
      provides: "metadata mark-unsupported command, metadata audit command"
      contains: "metadata_app.command.*mark-unsupported"
    - path: "src/objlib/cli.py"
      provides: "metadata audit command with Phase 16.3 readiness row"
      contains: "metadata_app.command.*audit"
    - path: "src/objlib/extraction/batch_orchestrator.py"
      provides: "Fixed _get_pending_files including .md extension"
      contains: "LIKE '%.md'"
  key_links:
    - from: "mark-unsupported command"
      to: "files table"
      via: "UPDATE files SET ai_metadata_status='skipped', error_message=..."
      pattern: "ai_metadata_status.*=.*skipped"
    - from: "audit command"
      to: "file_primary_topics junction table"
      via: "EXISTS subquery on file_primary_topics"
      pattern: "EXISTS.*file_primary_topics"
    - from: "_get_pending_files()"
      to: "files table"
      via: "SQL WHERE clause"
      pattern: "LIKE '%.md'"
---

<objective>
Enforce the metadata completeness invariant across all 1,885 DB-tracked files by implementing the `mark-unsupported` and `audit` CLI commands, fixing the `.md` extension filter, backfilling 21 approved books missing primary_topics rows, detecting and resetting quality-failed files (Signal B: all-boilerplate), and running batch-extract on all newly-pending enrichable files.

Purpose: Every file must either have `primary_topics` populated or `ai_metadata_status='skipped'` with a named reason. No file silently bypasses enrichment. This also produces the Phase 16.3 readiness data (MOTM and Other-stem primary_topics coverage).

Output: Two new CLI commands (`metadata mark-unsupported`, `metadata audit`), one batch_orchestrator fix, backfilled junction rows, re-extracted MOTM metadata via Mistral Batch API, and audit reporting per-category breakdown with Phase 16.3 readiness.
</objective>

<execution_context>
@/Users/david/.claude/get-shit-done/workflows/execute-plan.md
@/Users/david/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/16.2-metadata-completeness-invariant-enforcement/16.2-CONTEXT.md
@.planning/phases/16.2-metadata-completeness-invariant-enforcement/16.2-RESEARCH.md
@src/objlib/cli.py
@src/objlib/extraction/batch_orchestrator.py
@src/objlib/extraction/schemas.py
@src/objlib/database.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement mark-unsupported command, fix .md filter, backfill 21 books, define quality check, reset quality-failed files to pending</name>
  <files>src/objlib/cli.py, src/objlib/extraction/batch_orchestrator.py</files>
  <action>
**Step 1: Confirm MOTM folder name.**
Run against live DB to verify the exact folder path pattern:
```sql
SELECT DISTINCT
  CASE WHEN file_path LIKE '%/MOTM/%' THEN 'MOTM' ELSE 'other' END as category,
  COUNT(*)
FROM files
GROUP BY category;
```
Expected: 469 MOTM files. This confirms the `LIKE '%/MOTM/%'` pattern from CONTEXT.md Q4.

**Step 2: Implement `objlib metadata mark-unsupported` command in `src/objlib/cli.py`.**
Add as `@metadata_app.command("mark-unsupported")` following the existing command pattern (see `batch-extract` at line ~2882 for the pattern: `db_path` parameter with `--db/-d` default `Path("data/library.db")`).

The command performs a single backfill pass:
1. Mark `.pdf` files as skipped: `UPDATE files SET ai_metadata_status = 'skipped', error_message = 'pdf requires OCR text extraction -- deferred' WHERE file_path LIKE '%.pdf' AND ai_metadata_status != 'skipped'`
2. Mark `.html` files as skipped: `UPDATE files SET ai_metadata_status = 'skipped', error_message = 'html requires text extraction -- deferred' WHERE file_path LIKE '%.html' AND ai_metadata_status != 'skipped'`
3. Mark `.docx` files as skipped: `UPDATE files SET ai_metadata_status = 'skipped', error_message = 'docx requires text extraction -- deferred' WHERE file_path LIKE '%.docx' AND ai_metadata_status != 'skipped'`
4. Fix 26 epub files that are already skipped but have NULL error_message: `UPDATE files SET error_message = 'epub requires text extraction -- deferred' WHERE file_path LIKE '%.epub' AND ai_metadata_status = 'skipped' AND (error_message IS NULL OR error_message = '')`

For each UPDATE, capture `cursor.rowcount` and print a Rich summary: "[green]{N} {ext} files marked as skipped[/green]" or "[dim]{ext}: 0 files to update[/dim]".

Print a final Rich Panel with total counts.

Use `with Database(db_path) as db:` and `db.conn.execute()` for all SQL. Import `Database` from `objlib.database`. Use `from rich.panel import Panel` and `from rich.table import Table` for output.

**Step 3: Fix `_get_pending_files()` in `src/objlib/extraction/batch_orchestrator.py` (line ~361).**
Change:
```python
AND file_path LIKE '%.txt'
```
To:
```python
AND (file_path LIKE '%.txt' OR file_path LIKE '%.md')
```
This is a 1-line SQL fix. The Bernstein Heroes `.md` file will now be picked up by batch-extract.

**Step 4: Backfill 21 approved .txt books missing file_primary_topics rows.**
Add this logic as a helper function `_backfill_approved_books(db)` called from the `mark-unsupported` command AFTER the skip-marking logic (so the command does all data fixes in one pass).

Per CONTEXT.md Q3:
1. Query: `SELECT f.file_path, fma.metadata_json FROM files f JOIN file_metadata_ai fma ON f.file_path = fma.file_path AND fma.is_current = 1 WHERE f.ai_metadata_status = 'approved' AND NOT EXISTS (SELECT 1 FROM file_primary_topics pt WHERE pt.file_path = f.file_path)`
2. For each result, parse `json.loads(metadata_json)` and extract `primary_topics` list.
3. Filter through `CONTROLLED_VOCABULARY` (import from `objlib.extraction.schemas`).
4. If valid topics exist: `INSERT OR IGNORE INTO file_primary_topics (file_path, topic_tag) VALUES (?, ?)` for each topic. Print the file path and topic count.
5. If NO valid topics in JSON: `UPDATE files SET ai_metadata_status = 'pending' WHERE file_path = ?` to reset for batch-extract. Print "[yellow]Reset to pending: {filename}[/yellow]".
6. Print summary: "[green]{N} files backfilled from existing JSON, {M} reset to pending[/green]".

**Step 5: Define and implement structural quality check (Signal B: all-boilerplate detection).**
Add as a helper function `_detect_boilerplate_files(db)` called from `mark-unsupported` command AFTER backfill.

Signal B algorithm:
1. Compute corpus-wide topic frequency: `SELECT topic_tag, COUNT(*) as freq FROM file_primary_topics GROUP BY topic_tag ORDER BY freq DESC`
2. Total files with topics: `SELECT COUNT(DISTINCT file_path) FROM file_primary_topics`
3. Define boilerplate threshold: topics appearing in >40% of files are "generic boilerplate" (use 40% not 50% for conservatism — MOTM files all share the same 5-core-branch set)
4. Build `boilerplate_set` = {topic_tag for topic_tag, freq in results if freq / total_with_topics > 0.40}
5. Print the boilerplate set for transparency: "[dim]Boilerplate topics (>40% frequency): {', '.join(sorted(boilerplate_set))}[/dim]"
6. Find files where ALL primary_topics are boilerplate:
```sql
SELECT fp.file_path, COUNT(*) as total_topics,
       SUM(CASE WHEN fp.topic_tag IN ({placeholders}) THEN 1 ELSE 0 END) as boilerplate_count
FROM file_primary_topics fp
JOIN files f ON f.file_path = fp.file_path
WHERE f.ai_metadata_status = 'approved'
  AND (f.file_path LIKE '%.txt' OR f.file_path LIKE '%.md')
GROUP BY fp.file_path
HAVING total_topics = boilerplate_count
```
7. Return the list of quality-failed file_paths.

**Step 6: Reset quality-failed files to pending.**
After `_detect_boilerplate_files()` returns the list:
1. Print count: "[yellow]{N} files have all-boilerplate primary_topics (quality failure)[/yellow]"
2. Show breakdown by folder pattern:
   - MOTM: `SUM(CASE WHEN file_path LIKE '%/MOTM/%' THEN 1 ELSE 0 END)`
   - Other: remaining
3. For each quality-failed file:
   - `DELETE FROM file_primary_topics WHERE file_path = ?` (clear stale boilerplate topics)
   - `UPDATE files SET ai_metadata_status = 'pending' WHERE file_path = ?`
4. Print "[green]{N} files reset to pending for re-extraction[/green]"

Do NOT delete from `file_metadata_ai` — only clear file_primary_topics and reset status. The _save_extracted_metadata in batch_orchestrator already handles DELETE + re-INSERT of file_primary_topics on extraction (lines 447-461).

**Important constraints:**
- Import `CONTROLLED_VOCABULARY` from `objlib.extraction.schemas` at the top of the command function (not at module level — follow the existing pattern of lazy imports within commands, see batch-extract at line ~2944).
- Use `with Database(db_path) as db:` context manager.
- All SQL through `db.conn.execute()`.
- Rich output only (no plain print). Use `console` from the module-level import.
  </action>
  <verify>
1. `python -m objlib metadata mark-unsupported --db data/library.db` completes without error
2. Verify skip-marking: `sqlite3 data/library.db "SELECT ai_metadata_status, COUNT(*), CASE WHEN error_message IS NULL OR error_message = '' THEN 'MISSING' ELSE 'HAS' END as has_reason FROM files WHERE ai_metadata_status = 'skipped' GROUP BY ai_metadata_status, has_reason"` — all skipped files should have reason
3. Verify .md fix: `python -c "from objlib.extraction.batch_orchestrator import BatchExtractionOrchestrator; from objlib.database import Database; db = Database('data/library.db'); o = BatchExtractionOrchestrator(db, None, 'test'); print([f['file_path'] for f in o._get_pending_files(10) if f['file_path'].endswith('.md')]); db.conn.close()"` — should show the Bernstein .md file
4. Verify backfill: `sqlite3 data/library.db "SELECT COUNT(*) FROM files f WHERE f.ai_metadata_status = 'approved' AND NOT EXISTS (SELECT 1 FROM file_primary_topics pt WHERE pt.file_path = f.file_path)"` — should return 0
5. Verify quality reset: `sqlite3 data/library.db "SELECT COUNT(*) FROM files WHERE ai_metadata_status = 'pending' AND (file_path LIKE '%.txt' OR file_path LIKE '%.md')"` — should be >= 468 (MOTM) + other quality-failed
  </verify>
  <done>
- mark-unsupported command runs and marks all pdf/html/docx as skipped with named reasons; all 26 epub have error_message populated
- _get_pending_files() includes .md extension
- 21 approved books either have file_primary_topics rows backfilled from JSON or are reset to pending
- All files with all-boilerplate primary_topics (Signal B) are reset to pending with their stale topics cleared
- Zero approved files lack file_primary_topics rows (Condition 1 = 0)
- Zero skipped files lack error_message (Condition 2 = 0)
- Zero pending files have non-enrichable extensions (Condition 3 = 0)
  </done>
</task>

<task type="auto">
  <name>Task 2: Run batch-extract on all newly-pending files and implement metadata audit command</name>
  <files>src/objlib/cli.py</files>
  <action>
**Step 1: Run batch-extract on all newly-pending enrichable files.**
Execute: `python -m objlib metadata batch-extract --db data/library.db`

This will pick up ALL pending .txt and .md files (the 468+ MOTM files reset by quality check, any Other-stem files reset, the Bernstein .md, and any books reset to pending from backfill).

Wait for the batch job to complete (poll interval 30s, typically 20-60 minutes for ~500 files). The command runs `asyncio.run()` and polls automatically.

After completion, verify:
- `sqlite3 data/library.db "SELECT ai_metadata_status, COUNT(*) FROM files WHERE file_path LIKE '%.txt' OR file_path LIKE '%.md' GROUP BY ai_metadata_status"` — expect all enrichable files are either 'approved' or 'extracted' (batch-extract sets 'extracted' then auto-approval happens separately)
- If any files remain 'extracted', run: `python -m objlib metadata approve --db data/library.db` to approve them (existing command at cli.py line ~2757)

**Step 2: Implement `objlib metadata audit` command in `src/objlib/cli.py`.**
Add as `@metadata_app.command("audit")` after the existing commands.

Parameters: `db_path: Annotated[Path, typer.Option("--db", "-d", help="Path to SQLite database")] = Path("data/library.db")`

The audit command checks 4 invariant conditions and a Phase 16.3 readiness condition. Use Rich Table and Panel for output.

**Condition 1: Approved files without primary_topics.**
```sql
SELECT COUNT(*) FROM files f
WHERE f.ai_metadata_status = 'approved'
  AND NOT EXISTS (SELECT 1 FROM file_primary_topics pt WHERE pt.file_path = f.file_path)
```
PASS if count = 0. Display: "Condition 1: Approved without primary_topics — {count}" in green/red.

**Condition 2: Skipped files without reason.**
```sql
SELECT COUNT(*) FROM files f
WHERE f.ai_metadata_status = 'skipped'
  AND (f.error_message IS NULL OR f.error_message = '')
```
PASS if count = 0.

**Condition 3: Pending files with non-enrichable extensions.**
```sql
SELECT COUNT(*) FROM files f
WHERE f.ai_metadata_status = 'pending'
  AND f.file_path NOT LIKE '%.txt'
  AND f.file_path NOT LIKE '%.md'
```
PASS if count = 0.

**Condition 4: Phase 16.3 readiness — MOTM and Other-stem at 100% primary_topics.**

MOTM coverage:
```sql
SELECT
  COUNT(*) as total,
  SUM(CASE WHEN EXISTS (SELECT 1 FROM file_primary_topics pt WHERE pt.file_path = f.file_path) THEN 1 ELSE 0 END) as with_topics
FROM files f
WHERE f.file_path LIKE '%/MOTM/%'
  AND f.ai_metadata_status = 'approved'
  AND f.file_path LIKE '%.txt'
```
PASS if total = with_topics.

Other-stem coverage (files where scanner `metadata_json->>'topic'` equals the filename stem — i.e., the topic was just derived from the filename, not a real semantic topic):
```sql
SELECT
  COUNT(*) as total,
  SUM(CASE WHEN EXISTS (SELECT 1 FROM file_primary_topics pt WHERE pt.file_path = f.file_path) THEN 1 ELSE 0 END) as with_topics
FROM files f
WHERE f.ai_metadata_status = 'approved'
  AND f.file_path LIKE '%.txt'
  AND f.file_path NOT LIKE '%/MOTM/%'
  AND json_extract(f.metadata_json, '$.topic') IS NOT NULL
  AND json_extract(f.metadata_json, '$.topic') = REPLACE(REPLACE(f.filename, '.txt', ''), '_', ' ')
```
Note: The "Other-stem" definition from research is files where the scanner-extracted topic equals the filename stem. The exact SQL for stem comparison may need tuning — use the `filename` column (just the filename, not full path) stripped of `.txt` extension and with underscores replaced by spaces. If this doesn't match exactly, try:
```sql
AND LOWER(json_extract(f.metadata_json, '$.topic')) = LOWER(REPLACE(REPLACE(f.filename, '.txt', ''), '_', ' '))
```
If the stem comparison is tricky, an alternative approach: run `SELECT json_extract(f.metadata_json, '$.topic'), f.filename FROM files f WHERE ...` on a few samples first to understand the exact format, then calibrate the SQL.

PASS if both MOTM and Other-stem are at 100%.

**Output format:**
Use a Rich Table with columns: Condition | Status | Count | Detail.

Add a summary Panel at the bottom:
- If all 4 conditions pass: "[bold green]AUDIT PASSED[/bold green] — all invariants satisfied"
- If any fail: "[bold red]AUDIT FAILED[/bold red] — {N} condition(s) violated"

Add a Phase 16.3 Readiness section as a separate Rich Table:
| Category | Total | With Topics | Coverage | Status |
|----------|-------|-------------|----------|--------|
| MOTM (.txt approved) | 468 | 468 | 100% | READY |
| Other-stem (.txt approved) | 440 | 440 | 100% | READY |

Exit code: `raise typer.Exit(code=0)` if all pass, `raise typer.Exit(code=1)` if any condition fails.

**Important constraints:**
- Follow the existing CLI command pattern (see `batch-extract` for parameter style)
- Lazy imports within the command function body
- Rich output only via `console` (module-level import)
- The audit command MUST be idempotent — read-only, no data modifications
- Use `with Database(db_path) as db:` context manager
  </action>
  <verify>
1. batch-extract output shows all pending files processed with a success count matching expectations (~468+ MOTM + Bernstein .md + any backfill resets)
2. `sqlite3 data/library.db "SELECT ai_metadata_status, COUNT(*) FROM files GROUP BY ai_metadata_status"` — no 'pending' enrichable files remain
3. `python -m objlib metadata audit --db data/library.db` runs without error and produces a Rich table output
4. Audit shows per-condition status (may not yet exit 0 if some extracted files need approval — that's expected; the approve step handles it)
5. If audit shows condition 1 failures (extracted but not yet approved): run `python -m objlib metadata approve` then re-run audit
  </verify>
  <done>
- batch-extract has completed on all newly-pending enrichable files (MOTM re-extraction, Bernstein .md, any backfill resets)
- `objlib metadata audit` command exists with 4 invariant conditions + Phase 16.3 readiness row
- Audit reports per-category breakdown with PASS/FAIL per condition
- Audit exits with code 0 (all pass) or code 1 (any fail)
- All enrichable files are approved with primary_topics populated
  </done>
</task>

</tasks>

<verification>
After both tasks complete:
1. `python -m objlib metadata audit --db data/library.db` exits 0
2. `sqlite3 data/library.db "SELECT COUNT(*) FROM files f WHERE f.ai_metadata_status = 'approved' AND NOT EXISTS (SELECT 1 FROM file_primary_topics pt WHERE pt.file_path = f.file_path)"` returns 0
3. `sqlite3 data/library.db "SELECT COUNT(*) FROM files WHERE ai_metadata_status = 'skipped' AND (error_message IS NULL OR error_message = '')"` returns 0
4. `sqlite3 data/library.db "SELECT COUNT(*) FROM files WHERE ai_metadata_status = 'pending' AND file_path NOT LIKE '%.txt' AND file_path NOT LIKE '%.md'"` returns 0
5. The Bernstein .md file appears in file_primary_topics: `sqlite3 data/library.db "SELECT topic_tag FROM file_primary_topics WHERE file_path LIKE '%Bernstein%Heroes%'"` returns topic rows
</verification>

<success_criteria>
- mark-unsupported command exists and successfully marks all non-enrichable files as skipped with reasons
- _get_pending_files() includes .md files
- All 21 approved books without topics are backfilled or reset and re-extracted
- All MOTM files have non-generic primary_topics from fresh Mistral re-extraction
- audit command exists with 4 conditions + Phase 16.3 readiness
- audit command may or may not exit 0 yet (Plan 02 does final verification)
</success_criteria>

<output>
After completion, create `.planning/phases/16.2-metadata-completeness-invariant-enforcement/16.2-01-SUMMARY.md`
</output>
