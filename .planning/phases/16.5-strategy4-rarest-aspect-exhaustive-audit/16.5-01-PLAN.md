---
phase: 16.5-strategy4-rarest-aspect-exhaustive-audit
plan: 01
subsystem: audit, search
model_profile: quality
autonomous: true

requires:
  - phase: 16.4-03
    provides: "12 structural failures documented; all tested and retrievable with S4 queries"
  - file: .planning/phases/16.5-strategy4-rarest-aspect-exhaustive-audit/16.5-ROOT-CAUSE.md
    provides: "Root cause confirmed; S4 algorithm designed; 12 winning queries documented"
provides:
  - "S4 strategy (rarest-aspect, no preamble) implemented in scripts/retrievability_audit.py"
  - "Corpus frequency map built at audit start"
  - "S4a (top-3 rarest aspects) and S4b (rarest aspect + course_dir) as fallbacks after S1/S2"
  - "All 12 known structural failures validated with S4 in production store"
affects: [16.5-02, 16.5-03, 16.5-04]

goal: |
  Add Strategy 4 (S4) to scripts/retrievability_audit.py and validate it recovers
  all 12 known structural failures. S4 uses corpus-rarity-ranked aspects as the
  entire query (no stem preamble). This is the root-cause fix: the query mechanism
  change that allows retrieval of semantically homogeneous files.

tech-stack:
  added: []
  patterns:
    - "Corpus frequency map: O(n) DB query at script start; O(1) per-file aspect ranking"
    - "S4a: top-3 rarest aspects concatenated raw (markdown stripped)"
    - "S4b: rarest aspect + course_dir_name (disambiguation fallback)"
---

# Phase 16.5 Plan 01: Implement S4 Query Strategy

## Context

Root cause investigation (2026-02-25) proved all 12 structural failures are retrievable
via targeted aspect-based queries. The fix is Strategy 4: query using the rarest aspects
from each file's topic_aspects list, with no generic preamble.

See: `.planning/phases/16.5-strategy4-rarest-aspect-exhaustive-audit/16.5-ROOT-CAUSE.md`

## Locked Decisions (DO NOT DEVIATE)

1. **S4 corpus frequency map is built ONCE at script start** (all 1,749 files' aspects)
2. **S4a query = top-3 rarest aspects concatenated, markdown stripped, no preamble**
3. **S4b fallback = rarest aspect + course_dir_name** (for files with generic aspects)
4. **Fallback order for per-file audit: S1 → S4a → S4b** (S2 removed from chain — S4 supersedes it)
5. **TOP_K threshold stays at 5** (same as Phase 16.4-03 audit)
6. **The 12 known failures from 16.4-03 must ALL pass S4 validation before committing**

## Tasks

### Task 1: Add S4 strategy to retrievability_audit.py

Modify `scripts/retrievability_audit.py`:

1. **Add corpus frequency map builder function:**
```python
def build_corpus_freq_map(db_path: str) -> dict[str, int]:
    """Build aspect corpus frequency map from all files. O(n) query."""
    conn = sqlite3.connect(db_path)
    freq: dict[str, int] = {}
    rows = conn.execute(
        "SELECT metadata_json FROM file_metadata_ai WHERE is_current = 1"
    ).fetchall()
    conn.close()
    for (mj,) in rows:
        if not mj:
            continue
        try:
            for aspect in json.loads(mj).get("topic_aspects", []):
                freq[aspect] = freq.get(aspect, 0) + 1
        except (json.JSONDecodeError, TypeError):
            pass
    return freq
```

2. **Add S4 query builder to build_query():**
```python
elif strategy == 4:
    # S4a: top-3 rarest aspects (by corpus frequency), no preamble, markdown stripped
    ai_row = conn.execute(
        "SELECT metadata_json FROM file_metadata_ai WHERE file_path = ? AND is_current = 1",
        (file_path,),
    ).fetchone()
    aspects: list[str] = []
    if ai_row and ai_row[0]:
        try:
            aspects = json.loads(ai_row[0]).get("topic_aspects", []) or []
        except Exception:
            pass
    # Sort by corpus frequency ascending (rarest first); strip markdown
    sorted_aspects = sorted(
        aspects,
        key=lambda a: self.corpus_freq.get(a, 0)
    )
    cleaned = [re.sub(r"[*_`]", "", a) for a in sorted_aspects[:3]]
    return " ".join(cleaned) if cleaned else f"What is '{PurePosixPath(filename).stem}' about?"

elif strategy == 5:
    # S4b: rarest aspect + course dir name (disambiguation fallback)
    ai_row = conn.execute(
        "SELECT metadata_json FROM file_metadata_ai WHERE file_path = ? AND is_current = 1",
        (file_path,),
    ).fetchone()
    aspects: list[str] = []
    if ai_row and ai_row[0]:
        try:
            aspects = json.loads(ai_row[0]).get("topic_aspects", []) or []
        except Exception:
            pass
    sorted_aspects = sorted(aspects, key=lambda a: self.corpus_freq.get(a, 0))
    if sorted_aspects:
        rarest = re.sub(r"[*_`]", "", sorted_aspects[0])
        course = PurePosixPath(file_path).parent.name
        return f"{rarest} {course}"
    return f"What is '{PurePosixPath(filename).stem}' about?"
```

3. **Add `self.corpus_freq` initialization in `__init__`:**
```python
self.corpus_freq: dict[str, int] = {}
```

4. **Build corpus_freq in `run()` before processing begins:**
```python
print("Building corpus aspect frequency map...")
self.corpus_freq = build_corpus_freq_map(self.db_path)
print(f"  Built frequency map for {len(self.corpus_freq)} unique aspects")
```

5. **Add `import re` at top of script (if not already present)**

6. **Update strategy choices in argparse** to include "4", "5", and "1-2-4-5" for full chain

7. **Update the "all" strategy to run S1 → S4a → S4b** (replace S2, S3 in the chain):
   The `--strategy all` mode should run strategies [1, 4, 5] in sequence, treating a miss
   at strategy N as a trigger for trying strategy N+1.

   OR: keep strategies [1, 2, 3, 4, 5] but add S4/S5 as new strategies that the analysis
   section can compare. This allows the 16.5-02 audit to compare all strategies.

   **Decision (locked):** Keep existing strategy system but add strategies 4 and 5.
   The 16.5-02 exhaustive audit will run strategies [1, 4, 5] (S1, S4a, S4b).

### Task 2: Validate S4 on the 12 known structural failures

Run `retrievability_audit.py` with `--strategy 4` on ONLY the 12 known failures:
```bash
python scripts/retrievability_audit.py \
  --store objectivism-library \
  --db data/library.db \
  --strategy 4 \
  --verbose
```

But since the script doesn't have a per-file filter, create a temporary override or test
the 12 specific files by adding a `--file-list` option, OR simply run with strategy 4
against the full corpus and check the results for the 12 known failures.

**Alternative (simpler):** Run a validation script that tests S4a and S4b for the 12
specific known failures and confirms all 12 are found. This is faster than re-running
the full 1,749-file audit.

Write a validation script `scripts/validate_s4.py` that:
1. Loads the corpus frequency map
2. For each of the 12 known failures: builds S4a and S4b queries, runs them, checks rank ≤5
3. Reports PASS/FAIL for each file

All 12 must PASS before committing.

## Validation Gates

- [ ] `scripts/retrievability_audit.py` has strategies 4 and 5 implemented
- [ ] `scripts/validate_s4.py` runs and reports 12/12 PASS (all found in top-5)
- [ ] `import re` added to retrievability_audit.py if not present
- [ ] SEARCH_MODEL stays as "gemini-2.5-flash"
- [ ] No changes to S1, S2, S3 logic

## Commit

Commit when validate_s4.py shows 12/12 PASS:
```
feat(audit): add Strategy 4 (rarest-aspect) query to retrievability audit
```
