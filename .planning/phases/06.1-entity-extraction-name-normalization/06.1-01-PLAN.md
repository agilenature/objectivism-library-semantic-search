---
phase: 06.1-entity-extraction-name-normalization
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - src/objlib/database.py
  - src/objlib/entities/__init__.py
  - src/objlib/entities/registry.py
  - src/objlib/entities/extractor.py
  - src/objlib/entities/models.py
  - pyproject.toml
  - tests/test_entity_extraction.py
autonomous: true

must_haves:
  truths:
    - "Person registry contains all 15 canonical names with human-readable slugs"
    - "Aliases map partial names, title variants, and nicknames to canonical persons"
    - "Blocked aliases (Smith, Aaron, Tara, Ben, Mike, Harry, Greg, Keith, Don) are rejected unless disambiguated"
    - "High-uniqueness surnames (Peikoff, Ghate, Binswanger, etc.) match on surname alone"
    - "Fuzzy matching with RapidFuzz accepts at >=92, flags 80-91 for LLM fallback, rejects <80"
    - "Entity extraction produces validated TranscriptEntityOutput with person_id, mention_count, confidence"
    - "Possessives (Rand's, Peikoff's) are correctly matched"
  artifacts:
    - path: "src/objlib/database.py"
      provides: "Schema v4 migration with person, person_alias, transcript_entity tables"
      contains: "MIGRATION_V4_SQL"
    - path: "src/objlib/entities/registry.py"
      provides: "PersonRegistry class loading canonical names and aliases from SQLite"
      contains: "class PersonRegistry"
    - path: "src/objlib/entities/extractor.py"
      provides: "EntityExtractor with deterministic-first pipeline and LLM fallback"
      contains: "class EntityExtractor"
    - path: "src/objlib/entities/models.py"
      provides: "Pydantic models for entity extraction validation"
      contains: "class TranscriptEntityOutput"
    - path: "tests/test_entity_extraction.py"
      provides: "TDD tests for matching logic, disambiguation, and blocked aliases"
      min_lines: 100
  key_links:
    - from: "src/objlib/entities/extractor.py"
      to: "src/objlib/entities/registry.py"
      via: "PersonRegistry dependency injection"
      pattern: "PersonRegistry"
    - from: "src/objlib/entities/extractor.py"
      to: "src/objlib/database.py"
      via: "transcript_entity table writes"
      pattern: "transcript_entity"
    - from: "src/objlib/database.py"
      to: "person table"
      via: "MIGRATION_V4_SQL seed data"
      pattern: "INSERT INTO person"
---

<objective>
Create the entity extraction foundation: database schema v4 with person registry tables, seed data for 15 canonical Objectivist philosophers/instructors with aliases, Pydantic validation models, and the deterministic-first extraction engine with RapidFuzz fuzzy matching and LLM fallback.

Purpose: Enable structured extraction of person mentions from transcripts, transforming raw text references into normalized, searchable entity metadata.
Output: Working extraction engine that can identify and normalize mentions of 15 canonical persons in transcript text, with comprehensive test coverage.
</objective>

<execution_context>
@/Users/david/.claude/get-shit-done/workflows/execute-plan.md
@/Users/david/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Phase 6 foundation (schema, extraction module patterns)
@.planning/phases/06-ai-powered-metadata/06-01-SUMMARY.md

# Locked decisions and context
@.planning/phases/06.1-entity-extraction-name-normalization/06.1-CONTEXT.md
@.planning/phases/06.1-entity-extraction-name-normalization/CLARIFICATIONS-ANSWERED.md

# Existing code to extend
@src/objlib/database.py
@src/objlib/extraction/schemas.py
@src/objlib/extraction/client.py
@pyproject.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Schema v4 migration, Pydantic models, and person registry</name>
  <files>
    src/objlib/database.py
    src/objlib/entities/__init__.py
    src/objlib/entities/models.py
    src/objlib/entities/registry.py
    pyproject.toml
  </files>
  <action>
**A. Add rapidfuzz dependency to pyproject.toml:**
```
"rapidfuzz==3.6.1",
```
Exact version pin per locked decision Q10.

**B. Create MIGRATION_V4_SQL in src/objlib/database.py:**

Add a `MIGRATION_V4_SQL` constant with these tables:

```sql
-- Canonical person registry
CREATE TABLE IF NOT EXISTS person (
    person_id TEXT PRIMARY KEY,
    canonical_name TEXT NOT NULL UNIQUE,
    type TEXT NOT NULL CHECK(type IN ('philosopher', 'ari_instructor')),
    notes TEXT,
    created_at TEXT DEFAULT (strftime('%Y-%m-%dT%H:%M:%f', 'now')),
    updated_at TEXT DEFAULT (strftime('%Y-%m-%dT%H:%M:%f', 'now'))
);

-- Alias lookup table
CREATE TABLE IF NOT EXISTS person_alias (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    alias_text TEXT NOT NULL,
    person_id TEXT NOT NULL,
    alias_type TEXT CHECK(alias_type IN ('nickname', 'misspelling', 'partial', 'initials', 'title_variant', 'full_name')),
    is_blocked BOOLEAN DEFAULT 0,
    created_at TEXT DEFAULT (strftime('%Y-%m-%dT%H:%M:%f', 'now')),
    FOREIGN KEY (person_id) REFERENCES person(person_id)
);

CREATE INDEX IF NOT EXISTS idx_person_alias_text ON person_alias(alias_text COLLATE NOCASE);

-- Transcript-level entity summary
CREATE TABLE IF NOT EXISTS transcript_entity (
    transcript_id TEXT NOT NULL,
    person_id TEXT NOT NULL,
    mention_count INTEGER NOT NULL CHECK(mention_count >= 1),
    first_seen_char INTEGER,
    max_confidence REAL CHECK(max_confidence >= 0.0 AND max_confidence <= 1.0),
    evidence_sample TEXT,
    extraction_version TEXT NOT NULL,
    created_at TEXT DEFAULT (strftime('%Y-%m-%dT%H:%M:%f', 'now')),
    PRIMARY KEY (transcript_id, person_id),
    FOREIGN KEY (person_id) REFERENCES person(person_id)
);

CREATE INDEX IF NOT EXISTS idx_transcript_entity_person ON transcript_entity(person_id);
```

Note: `transcript_id` uses TEXT (file_path) as FK to files table, matching existing database patterns. Do NOT add formal FK to `files` table since the column name differs from `files.file_path` but semantically references it.

**C. Seed data for 15 canonical persons + aliases:**

Include all 15 persons from the locked decision list in the migration SQL. Use deterministic slugs as person_id.

Seed aliases (CRITICAL -- match exactly what appears in transcripts):
- Full names registered as alias_type='full_name' for each person
- Partial surnames for high-uniqueness names: Peikoff, Ghate, Binswanger, Mayhew, Salmieri, Mazza, Liege (no accent), Lockitch, Moroney, Brook, Watkins, Bayer
- Title variants: "Dr. Peikoff", "Professor Salmieri", "Dr. Ghate", "Dr. Binswanger", "Dr. Smith" (BLOCKED)
- Nickname partials: "Rand" (for Ayn Rand -- high uniqueness), "Onkar", "Tristan", "Yaron"
- Register blocked aliases with `is_blocked=1`: "Smith", "Aaron", "Tara", "Ben", "Mike", "Harry", "Greg", "Keith", "Don"
  - These resolve to NO person unless the full name appears

**D. Update _setup_schema() in Database class:**

Add v4 migration block after the existing v3 migration:
```python
if version < 4:
    self.conn.executescript(MIGRATION_V4_SQL)
    # Add entity extraction columns to files table
    for alter_sql in [
        "ALTER TABLE files ADD COLUMN entity_extraction_version TEXT",
        "ALTER TABLE files ADD COLUMN entity_extraction_status TEXT DEFAULT 'pending'",
    ]:
        try:
            self.conn.execute(alter_sql)
        except sqlite3.OperationalError:
            pass

self.conn.execute("PRAGMA user_version = 4")
```

**E. Create src/objlib/entities/__init__.py:**
Empty init file to establish the entities package.

**F. Create src/objlib/entities/models.py:**

Pydantic models per locked decision Q9:

```python
from pydantic import BaseModel, Field

class TranscriptEntityOutput(BaseModel):
    person_id: str
    canonical_name: str
    mention_count: int = Field(ge=1)
    max_confidence: float = Field(ge=0.0, le=1.0)
    evidence_sample: str = Field(max_length=200)
    first_seen_char: int | None = None

class EntityExtractionResult(BaseModel):
    file_path: str
    entities: list[TranscriptEntityOutput]
    extraction_version: str = "6.1.0"
    status: str = "entities_done"  # entities_done | error | blocked_entity_extraction

class PersonRecord(BaseModel):
    person_id: str
    canonical_name: str
    type: str  # philosopher | ari_instructor

class AliasRecord(BaseModel):
    alias_text: str
    person_id: str
    alias_type: str
    is_blocked: bool = False
```

**G. Create src/objlib/entities/registry.py:**

`PersonRegistry` class that loads persons and aliases from SQLite:

```python
class PersonRegistry:
    def __init__(self, db: Database):
        self._persons: dict[str, PersonRecord] = {}
        self._aliases: dict[str, list[AliasRecord]] = {}  # alias_text_lower -> records
        self._blocked: set[str] = set()
        self._load(db)

    def _load(self, db: Database):
        # Load all persons from person table
        # Load all aliases from person_alias table
        # Build case-insensitive lookup: alias_text.casefold() -> list of matching records
        # Build blocked set: alias_text.casefold() for is_blocked=1

    def get_person(self, person_id: str) -> PersonRecord | None: ...
    def lookup_alias(self, text: str) -> list[AliasRecord]: ...
    def is_blocked(self, text: str) -> bool: ...
    def all_persons(self) -> list[PersonRecord]: ...
    def all_aliases(self) -> list[AliasRecord]: ...
    def get_canonical_name(self, person_id: str) -> str | None: ...
```

The registry is loaded once per extraction session and cached in memory. The canonical list is small (15 people, ~50 aliases) so in-memory lookup is instant.
  </action>
  <verify>
Run `python -c "from objlib.entities.models import TranscriptEntityOutput, EntityExtractionResult; print('Models OK')"` to verify imports.

Open a Python REPL and verify schema v4 migration creates the tables:
```python
from objlib.database import Database
db = Database(":memory:")
# Verify tables exist
tables = [r[0] for r in db.conn.execute("SELECT name FROM sqlite_master WHERE type='table'").fetchall()]
assert 'person' in tables
assert 'person_alias' in tables
assert 'transcript_entity' in tables
# Verify seed data
count = db.conn.execute("SELECT COUNT(*) FROM person").fetchone()[0]
assert count == 15
alias_count = db.conn.execute("SELECT COUNT(*) FROM person_alias").fetchone()[0]
assert alias_count > 30  # At minimum: 15 full names + 15+ partials + blocked
blocked = db.conn.execute("SELECT COUNT(*) FROM person_alias WHERE is_blocked=1").fetchone()[0]
assert blocked == 9  # Smith, Aaron, Tara, Ben, Mike, Harry, Greg, Keith, Don
```

Verify PersonRegistry loads from DB:
```python
from objlib.entities.registry import PersonRegistry
reg = PersonRegistry(db)
assert reg.get_person('ayn-rand') is not None
assert reg.is_blocked('smith')
assert not reg.is_blocked('peikoff')
aliases = reg.lookup_alias('peikoff')
assert len(aliases) >= 1
assert aliases[0].person_id == 'leonard-peikoff'
```
  </verify>
  <done>
Schema v4 migration creates person, person_alias, and transcript_entity tables with all 15 canonical persons seeded, 9 blocked aliases registered, and PersonRegistry loads and provides case-insensitive lookup. Pydantic models validate entity extraction output with confidence >= 0.0 and mention_count >= 1.
  </done>
</task>

<task type="auto">
  <name>Task 2: Entity extraction engine with TDD (deterministic + LLM fallback)</name>
  <files>
    src/objlib/entities/extractor.py
    tests/test_entity_extraction.py
  </files>
  <action>
**TDD approach: Write tests first, then implement.**

**RED PHASE -- Write failing tests in tests/test_entity_extraction.py:**

Test categories to cover:

1. **Exact match tests:**
   - "Ayn Rand" -> person_id="ayn-rand", confidence=1.0
   - "Leonard Peikoff" -> person_id="leonard-peikoff", confidence=1.0
   - "Tristan de Liege" (no accent) -> person_id="tristan-de-liege", confidence=1.0

2. **Alias match tests:**
   - "Peikoff" -> person_id="leonard-peikoff", confidence=1.0
   - "Rand" -> person_id="ayn-rand", confidence=1.0
   - "Dr. Peikoff" -> person_id="leonard-peikoff", confidence=1.0
   - "Onkar" -> person_id="onkar-ghate", confidence=1.0
   - "Ghate" -> person_id="onkar-ghate", confidence=1.0
   - "Binswanger" -> person_id="harry-binswanger", confidence=1.0

3. **Blocked alias tests:**
   - "Smith" alone -> NO match (blocked)
   - "Aaron" alone -> NO match (blocked)
   - "Tara" alone -> NO match (blocked)
   - "Ben" alone -> NO match (blocked)
   - "Mike" alone -> NO match (blocked)

4. **Disambiguation tests:**
   - "Tara Smith" -> person_id="tara-smith", confidence=1.0
   - "Aaron Smith" -> person_id="aaron-smith", confidence=1.0
   - Text containing both "Tara Smith" and "Smith" -> only "Tara Smith" matched

5. **Possessive tests:**
   - "Rand's theory" -> matches Ayn Rand
   - "Peikoff's argument" -> matches Leonard Peikoff
   - "Ghate's lecture" -> matches Onkar Ghate

6. **Speaker label tests:**
   - "Leonard Peikoff: The concept of..." -> matches Leonard Peikoff
   - "Onkar Ghate: I think that..." -> matches Onkar Ghate

7. **Full transcript extraction test:**
   - A multi-paragraph text mentioning "Ayn Rand", "Peikoff", "Rand's", "Dr. Peikoff", and "Smith" (blocked)
   - Expected: 2 entities (Ayn Rand with mention_count=2, Leonard Peikoff with mention_count=2), Smith blocked

8. **Fuzzy match test:**
   - "Peikof" (minor typo) -> if score >= 92, accept as Leonard Peikoff
   - "Binwanger" (minor typo) -> if score >= 92, accept as Harry Binswanger
   - "Xyz Random Person" -> rejected (score < 80)

9. **No entities test:**
   - Text with no person mentions -> empty entity list, status="entities_done"

10. **Confidence threshold test:**
    - Entities with confidence < 0.5 are excluded from output per locked decision Q9

**GREEN PHASE -- Implement src/objlib/entities/extractor.py:**

```python
class EntityExtractor:
    """Deterministic-first entity extraction with optional LLM fallback.

    Pipeline stages:
    A. Text normalization (casefold, strip punctuation, Unicode normalize)
    B. Tokenize text into candidate spans (word n-grams: 1, 2, 3 tokens)
    C. For each candidate span:
       1. Check blocked alias list -> skip if blocked AND no full name match nearby
       2. Exact match against canonical names -> confidence 1.0
       3. Exact match against alias_text (case-insensitive) -> confidence 1.0
       4. Strip possessive 's and re-check exact/alias match -> confidence 1.0
       5. Fuzzy match via RapidFuzz token_set_ratio:
          - >= 92: accept, confidence = score/100
          - 80-91: flag for LLM fallback
          - < 80: reject
    D. Deduplicate: group by person_id, count mentions, track first_seen_char
    E. LLM fallback for flagged candidates (Stage B from locked decisions)
    F. Validate with Pydantic, reject confidence < 0.5
    """

    def __init__(self, registry: PersonRegistry, mistral_client=None):
        self.registry = registry
        self.mistral_client = mistral_client  # Optional, only for LLM fallback

    def extract(self, text: str, file_path: str) -> EntityExtractionResult:
        """Extract entities from transcript text."""
        ...

    def _normalize_text(self, text: str) -> str:
        """Casefold, Unicode normalize (NFKD), strip extra whitespace."""
        ...

    def _find_candidates(self, text: str) -> list[tuple[str, int, int]]:
        """Find candidate name spans in text.

        Returns list of (surface_text, start_char, end_char).

        Strategy: Use regex to find sequences of capitalized words (1-3 tokens)
        that could be person names. Also find possessive forms (Name's).
        Also find title+name patterns (Dr. Name, Prof. Name).
        Also find speaker labels (Name Name:).
        """
        ...

    def _match_candidate(self, surface_text: str) -> tuple[str | None, float]:
        """Match a candidate surface text against registry.

        Returns (person_id, confidence) or (None, 0.0).
        """
        ...

    def _fuzzy_match(self, text: str) -> tuple[str | None, float]:
        """Fuzzy match against all canonical names and aliases.

        Uses rapidfuzz.fuzz.token_set_ratio.
        Returns (person_id, confidence) or (None, 0.0).
        """
        ...
```

Key implementation details:

1. **Candidate finding strategy:** Use regex `r"(?:(?:Dr|Prof|Professor|Mr|Mrs|Ms)\.?\s+)?[A-Z][a-z]+(?:'s)?(?:\s+(?:de\s+)?[A-Z][a-z]+(?:'s)?){0,2}"` to find capitalized word sequences (1-3 tokens) including title prefixes and possessives. Also scan for speaker labels with pattern `r"^([A-Z][a-z]+(?:\s+[A-Z][a-z]+)+):"` at line starts.

2. **Blocked alias check:** Before matching, check if the normalized surface text is in the blocked set. If blocked, check whether a full disambiguated name appears within +-200 chars of this mention. If no full name nearby, skip.

3. **Possessive handling:** Strip trailing `'s` or `'s` before matching, but count as valid mention at original position.

4. **Deduplication:** After all matches, group by person_id. For each person: count total mentions, record first_seen_char, compute max_confidence, capture first evidence_sample (surrounding 100 chars).

5. **Evidence sample:** Extract `text[max(0, first_seen_char-50):first_seen_char+50]` as evidence_sample, truncate to 200 chars.

6. **LLM fallback:** If `self.mistral_client` is provided and there are candidates in the 80-91 fuzzy range, send context window (+-200 chars) and canonical list to Mistral with temperature=0.1. Parse JSON response `{"person_id": "slug" | "none"}`. If "none", discard. If valid slug, accept with confidence = fuzzy_score / 100. If no mistral_client, simply discard 80-91 range candidates (conservative).
  </action>
  <verify>
Run tests:
```bash
cd /Users/david/projects/objectivism-library-semantic-search && python -m pytest tests/test_entity_extraction.py -v
```

All tests must pass. Verify the key behaviors:
- Exact matches return confidence 1.0
- Blocked aliases return no match
- "Tara Smith" disambiguates correctly
- Possessives are matched
- Fuzzy typos above 92 threshold are accepted
- Empty text returns empty entity list
  </verify>
  <done>
EntityExtractor correctly identifies and normalizes mentions of all 15 canonical persons from transcript text. Blocked aliases (Smith, Aaron, Tara, Ben, Mike, Harry, Greg, Keith, Don) are rejected unless full name appears. Fuzzy matching with RapidFuzz accepts >= 92 threshold. All TDD tests pass with exact match, alias, blocked, disambiguation, possessive, speaker label, fuzzy, and empty input scenarios.
  </done>
</task>

</tasks>

<verification>
1. Schema v4 migration runs idempotently (can re-run without errors)
2. All 15 persons seeded with correct slugs and types
3. PersonRegistry loads all persons and aliases from DB
4. EntityExtractor passes all TDD test scenarios
5. `python -m pytest tests/test_entity_extraction.py -v` passes with 10+ test cases
6. Blocked aliases correctly rejected
7. Disambiguated names correctly resolved
</verification>

<success_criteria>
- Schema v4 creates person, person_alias, transcript_entity tables
- 15 canonical persons + 30+ aliases + 9 blocked aliases seeded
- EntityExtractor handles exact, alias, fuzzy, blocked, possessive, speaker label matching
- TDD test suite has 10+ test cases all passing
- Pydantic validation rejects invalid entity output
</success_criteria>

<output>
After completion, create `.planning/phases/06.1-entity-extraction-name-normalization/06.1-01-SUMMARY.md`
</output>
