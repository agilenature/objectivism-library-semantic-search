---
phase: 06.1-entity-extraction-name-normalization
plan: 02
type: execute
wave: 2
depends_on: ["06.1-01"]
files_modified:
  - src/objlib/cli.py
  - src/objlib/database.py
  - src/objlib/entities/extractor.py
autonomous: true

must_haves:
  truths:
    - "User can run 'objlib entities extract' to extract entities from pending transcripts"
    - "User can run 'objlib entities extract --backfill' to process already-uploaded files"
    - "User can run 'objlib entities extract --force' to re-extract all files"
    - "User can run 'objlib entities stats' to see entity extraction coverage and person frequency"
    - "User can run 'objlib entities report --person \"Leonard Peikoff\"' to see all transcripts mentioning a person"
    - "Entity extraction writes to transcript_entity table and updates files.entity_extraction_status"
    - "Extraction continues on failure (fail-one-continue-batch)"
  artifacts:
    - path: "src/objlib/cli.py"
      provides: "entities command group with extract, stats, report subcommands"
      contains: "entities_app"
    - path: "src/objlib/database.py"
      provides: "Database methods for entity CRUD and statistics queries"
      contains: "save_transcript_entities"
  key_links:
    - from: "src/objlib/cli.py"
      to: "src/objlib/entities/extractor.py"
      via: "EntityExtractor instantiation in extract command"
      pattern: "EntityExtractor"
    - from: "src/objlib/cli.py"
      to: "src/objlib/database.py"
      via: "Database methods for entity persistence and queries"
      pattern: "save_transcript_entities|get_entity_stats"
    - from: "src/objlib/entities/extractor.py"
      to: "src/objlib/database.py"
      via: "transcript_entity UPSERT for extraction results"
      pattern: "transcript_entity"
---

<objective>
Wire entity extraction into the CLI with extract, stats, and report commands. Add database persistence methods for saving extraction results and querying entity statistics. Enables the user to run batch entity extraction against pending/backfill/all transcripts and review results.

Purpose: Make entity extraction accessible through the CLI, with Rich progress display and reporting, matching the established patterns from Phase 6 metadata extraction commands.
Output: Working CLI commands for entity extraction, statistics, and per-person reporting.
</objective>

<execution_context>
@/Users/david/.claude/get-shit-done/workflows/execute-plan.md
@/Users/david/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Phase 6.1 Plan 01 (dependency -- schema, registry, extractor)
@.planning/phases/06.1-entity-extraction-name-normalization/06.1-01-SUMMARY.md

# Phase 6 CLI patterns to follow
@.planning/phases/06-ai-powered-metadata/06-05-SUMMARY.md

# Locked decisions and context
@.planning/phases/06.1-entity-extraction-name-normalization/CLARIFICATIONS-ANSWERED.md

# Current code to extend
@src/objlib/cli.py
@src/objlib/database.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Database persistence methods for entity extraction</name>
  <files>
    src/objlib/database.py
  </files>
  <action>
Add these methods to the Database class:

**A. save_transcript_entities(file_path, result):**
```python
def save_transcript_entities(self, file_path: str, result: EntityExtractionResult) -> None:
    """Save entity extraction results for a transcript.

    Uses UPSERT to handle re-extraction (idempotent).
    Updates files.entity_extraction_status and entity_extraction_version.

    Args:
        file_path: Primary key matching files.file_path.
        result: EntityExtractionResult from the extractor.
    """
```
Implementation:
- Within a single transaction:
  1. Delete existing transcript_entity rows for this file_path (clean slate for re-extraction)
  2. INSERT each entity from result.entities into transcript_entity
  3. UPDATE files SET entity_extraction_status = result.status, entity_extraction_version = result.extraction_version WHERE file_path = ?
- Use `with self.conn:` for transaction management

**B. get_entity_stats() -> dict:**
```python
def get_entity_stats(self) -> dict:
    """Return entity extraction statistics.

    Returns dict with:
        total_txt: total .txt files
        entities_done: files with entity_extraction_status='entities_done'
        pending: files with entity_extraction_status='pending' or NULL
        errors: files with entity_extraction_status in ('error', 'blocked_entity_extraction')
        total_mentions: sum of all mention_count in transcript_entity
        unique_persons: count of distinct person_id in transcript_entity
        person_frequency: list of (canonical_name, transcript_count, total_mentions)
            ordered by transcript_count desc
    """
```

**C. get_files_needing_entity_extraction(mode, limit) -> list:**
```python
def get_files_needing_entity_extraction(
    self, mode: str = "pending", limit: int = 500
) -> list[dict]:
    """Return files that need entity extraction.

    Args:
        mode: "pending" (default), "backfill", "force", or "upgrade"
            - pending: entity_extraction_status IS NULL or 'pending', .txt files
            - backfill: status='uploaded' AND entity_extraction_status IS NULL
            - force: all .txt files regardless of entity status
            - upgrade: entity_extraction_version != current version
        limit: Max files to return.

    Returns:
        List of dicts with file_path, filename, file_size keys.
    """
```

For "pending" mode: `WHERE filename LIKE '%.txt' AND (entity_extraction_status IS NULL OR entity_extraction_status = 'pending') AND status != 'LOCAL_DELETE'`

For "backfill" mode: `WHERE filename LIKE '%.txt' AND status = 'uploaded' AND (entity_extraction_status IS NULL OR entity_extraction_status = 'pending') AND status != 'LOCAL_DELETE'`

For "force" mode: `WHERE filename LIKE '%.txt' AND status != 'LOCAL_DELETE'`

For "upgrade" mode: `WHERE filename LIKE '%.txt' AND entity_extraction_version != '6.1.0' AND entity_extraction_status = 'entities_done' AND status != 'LOCAL_DELETE'`

**D. get_transcripts_by_person(person_id, limit) -> list:**
```python
def get_transcripts_by_person(self, person_id: str, limit: int = 50) -> list[dict]:
    """Return transcripts that mention a specific person.

    Returns list of dicts with file_path, filename, mention_count,
    max_confidence, evidence_sample keys, ordered by mention_count DESC.
    """
```

**E. get_person_by_name_or_alias(query) -> str | None:**
```python
def get_person_by_name_or_alias(self, query: str) -> str | None:
    """Look up a person_id by canonical name or alias text.

    Case-insensitive. Returns person_id or None.
    Used by CLI to resolve user input like 'Peikoff' to 'leonard-peikoff'.
    """
```
  </action>
  <verify>
Run a quick smoke test:
```python
from objlib.database import Database
from objlib.entities.models import EntityExtractionResult, TranscriptEntityOutput

db = Database(":memory:")

# Insert a test file first
db.conn.execute(
    "INSERT INTO files (file_path, content_hash, filename, file_size, status) VALUES (?, ?, ?, ?, ?)",
    ("test/file.txt", "abc123", "file.txt", 1000, "pending")
)
db.conn.commit()

# Save entity results
result = EntityExtractionResult(
    file_path="test/file.txt",
    entities=[
        TranscriptEntityOutput(
            person_id="ayn-rand",
            canonical_name="Ayn Rand",
            mention_count=5,
            max_confidence=1.0,
            evidence_sample="...Ayn Rand argued that...",
        )
    ]
)
db.save_transcript_entities("test/file.txt", result)

# Verify stats
stats = db.get_entity_stats()
assert stats["entities_done"] >= 1
assert stats["total_mentions"] == 5

# Verify person lookup
transcripts = db.get_transcripts_by_person("ayn-rand")
assert len(transcripts) == 1
assert transcripts[0]["mention_count"] == 5
```
  </verify>
  <done>
Database has save_transcript_entities (UPSERT with status update), get_entity_stats (coverage + person frequency), get_files_needing_entity_extraction (4 modes), get_transcripts_by_person (per-person report), and get_person_by_name_or_alias (CLI input resolution).
  </done>
</task>

<task type="auto">
  <name>Task 2: CLI commands for entity extraction, stats, and reporting</name>
  <files>
    src/objlib/cli.py
  </files>
  <action>
Add an `entities` command group to the CLI, following the established pattern from the `metadata` command group.

**A. Create entities_app Typer group:**
```python
entities_app = typer.Typer(help="Extract and manage person entity mentions in transcripts")
app.add_typer(entities_app, name="entities")
```

**B. `entities extract` command:**

```python
@entities_app.command("extract")
def entities_extract(
    mode: Annotated[str, typer.Option("--mode", "-m",
        help="Extraction mode: pending (default), backfill, force, upgrade")] = "pending",
    limit: Annotated[int, typer.Option("--limit", "-l",
        help="Maximum files to process")] = 500,
    db_path: Annotated[Path, typer.Option("--db", "-d",
        help="Path to SQLite database")] = Path("data/library.db"),
    library_root: Annotated[Path, typer.Option("--library-root",
        help="Path to library root directory")] = Path("/Volumes/U32 Shadow/Objectivism Library"),
    use_llm: Annotated[bool, typer.Option("--use-llm",
        help="Enable LLM fallback for 80-91 fuzzy range")] = False,
) -> None:
```

Implementation:
1. Open Database, create PersonRegistry
2. If `use_llm`: load Mistral API key from keyring, create MistralClient
3. Create EntityExtractor(registry, mistral_client=client_or_none)
4. Query files using `db.get_files_needing_entity_extraction(mode, limit)`
5. Rich progress bar: `with Progress(...) as progress:` iterating files
6. For each file:
   - Read file content from `library_root / file_path`
   - If file not found: log warning, mark entity_extraction_status='error', continue
   - Call `extractor.extract(text, file_path)`
   - Call `db.save_transcript_entities(file_path, result)`
   - Update progress bar
7. Print summary: processed, succeeded, failed, skipped counts
8. Print top-5 most mentioned persons across the batch

Use deferred imports for EntityExtractor and PersonRegistry (fast CLI startup pattern from Phase 6).

Follow fail-one-continue-batch pattern per locked decision Q4: wrap each file in try/except, log errors, continue.

**C. `entities stats` command:**

```python
@entities_app.command("stats")
def entities_stats(
    db_path: Annotated[Path, typer.Option("--db", "-d",
        help="Path to SQLite database")] = Path("data/library.db"),
) -> None:
```

Implementation:
1. Call `db.get_entity_stats()`
2. Display Rich table with:
   - Coverage: entities_done / total_txt (percentage bar)
   - Pending / errors counts
   - Total mentions across corpus
   - Person frequency table: canonical_name, # transcripts, # total mentions
     (Rich table, sorted by transcript count descending)

**D. `entities report` command:**

```python
@entities_app.command("report")
def entities_report(
    person: Annotated[str, typer.Argument(help="Person name or alias to report on")] = "",
    low_confidence: Annotated[bool, typer.Option("--low-confidence",
        help="Show entities with confidence < 0.7")] = False,
    limit: Annotated[int, typer.Option("--limit", "-l",
        help="Maximum results")] = 50,
    db_path: Annotated[Path, typer.Option("--db", "-d",
        help="Path to SQLite database")] = Path("data/library.db"),
) -> None:
```

Implementation:
1. If `person` provided:
   - Resolve to person_id via `db.get_person_by_name_or_alias(person)`
   - If not found: print error with suggestion to check `entities stats` for valid names
   - Query `db.get_transcripts_by_person(person_id, limit)`
   - Display Rich table: filename, mention_count, confidence, evidence_sample
2. If `low_confidence`:
   - Query transcript_entity WHERE max_confidence < 0.7
   - Display table: filename, person, confidence, evidence_sample
   - Purpose: review potentially incorrect matches for quality tuning
3. If neither: show usage help

Use Rich Panel header with person canonical name for person reports. Use color-coded confidence (green >= 0.9, yellow >= 0.7, red < 0.7).
  </action>
  <verify>
Run CLI help to verify commands are registered:
```bash
cd /Users/david/projects/objectivism-library-semantic-search
python -m objlib entities --help
python -m objlib entities extract --help
python -m objlib entities stats --help
python -m objlib entities report --help
```

All four help screens should display without errors.

Run stats command against the existing database (should show 0 entities extracted, all pending):
```bash
python -m objlib entities stats
```

Verify the extract command starts correctly (even if library disk is disconnected, it should gracefully report "0 files to process" or file-not-found errors rather than crash):
```bash
python -m objlib entities extract --limit 0
```
  </verify>
  <done>
CLI has `entities extract` (with --mode pending/backfill/force/upgrade, --use-llm, Rich progress), `entities stats` (coverage percentage, person frequency table), and `entities report` (per-person transcript list with evidence samples, low-confidence review). All commands follow established Phase 6 CLI patterns with deferred imports and fail-one-continue-batch error handling.
  </done>
</task>

</tasks>

<verification>
1. `python -m objlib entities --help` shows all three subcommands
2. `python -m objlib entities stats` runs without error on existing database
3. `python -m objlib entities extract --limit 5` processes files with Rich progress (if library disk connected)
4. `python -m objlib entities report --person "Peikoff"` resolves alias and shows results (after extraction)
5. Entity extraction writes to transcript_entity and updates files.entity_extraction_status
6. Fail-one-continue-batch: a bad file doesn't stop the batch
</verification>

<success_criteria>
- entities extract command processes transcripts and persists results to SQLite
- entities stats command shows coverage, person frequency, and error counts
- entities report command shows per-person transcript mentions with evidence
- Database UPSERT handles re-extraction idempotently
- Extraction uses fail-one-continue-batch error handling
- Rich progress bar shows per-file processing status
</success_criteria>

<output>
After completion, create `.planning/phases/06.1-entity-extraction-name-normalization/06.1-02-SUMMARY.md`
</output>
