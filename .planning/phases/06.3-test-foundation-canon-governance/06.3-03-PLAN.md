---
phase: 06.3-test-foundation-canon-governance
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/test_expansion.py
  - tests/test_reranker.py
  - tests/test_synthesizer.py
autonomous: true

must_haves:
  truths:
    - "Query expansion adds correct synonyms from glossary and handles unknown terms gracefully"
    - "Reranker applies AI scores to passages in correct order using mocked generate_content"
    - "Difficulty bucketing reorders results into introductory-first or advanced-first based on mode"
    - "MMR diversity filtering removes duplicate passages from same source file"
    - "Citation validation accepts exact and whitespace-normalized quotes, rejects fabricated ones"
    - "Metadata filter syntax generates correct AIP-160 filter strings"
  artifacts:
    - path: "tests/test_expansion.py"
      provides: "Query expansion tests: synonym lookup, multi-word phrases, unknown terms, boosting"
      min_lines: 60
    - path: "tests/test_reranker.py"
      provides: "Reranker tests: scoring, difficulty ordering, mocked API responses"
      min_lines: 80
    - path: "tests/test_synthesizer.py"
      provides: "Synthesis tests: MMR diversity, citation validation, whitespace normalization, metadata filters"
      min_lines: 100
  key_links:
    - from: "tests/test_reranker.py"
      to: "src/objlib/search/reranker.py"
      via: "Mocked client.models.generate_content returning RankedResults"
      pattern: "generate_content"
    - from: "tests/test_synthesizer.py"
      to: "src/objlib/search/synthesizer.py"
      via: "Pure logic functions: validate_citations, apply_mmr_diversity"
      pattern: "validate_citations|apply_mmr_diversity"
---

<objective>
Create retroactive tests for the search pipeline: query expansion engine, LLM reranker with difficulty bucketing, and synthesis pipeline including MMR diversity, citation validation, and metadata filter generation.

Purpose: The search pipeline is the core user-facing feature. Tests prove that ranking, synthesis, and expansion logic is correct independently of Gemini API quality.
Output: test_expansion.py (glossary-based expansion), test_reranker.py (AI scoring + difficulty ordering), test_synthesizer.py (MMR + citation validation + metadata filters).
</objective>

<execution_context>
@/Users/david/.claude/get-shit-done/workflows/execute-plan.md
@/Users/david/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06.3-test-foundation-canon-governance/06.3-RESEARCH.md
@src/objlib/search/expansion.py
@src/objlib/search/reranker.py
@src/objlib/search/synthesizer.py
@src/objlib/search/models.py
@src/objlib/search/__init__.py
@tests/test_search.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Query expansion and reranker tests</name>
  <files>tests/test_expansion.py, tests/test_reranker.py</files>
  <action>
**File 1: `tests/test_expansion.py`** — Query expansion engine tests.

Read `src/objlib/search/expansion.py` and `src/objlib/search/synonyms.yml` first to understand the exact API.

Tests to implement:

1. `test_expand_known_term()` — expand_query("egoism") returns expanded string containing "rational self-interest". Assert expansions list is non-empty.

2. `test_expand_unknown_term()` — expand_query("quantum physics") returns original query unchanged. Assert expansions list is empty.

3. `test_multi_word_phrase_matched()` — expand_query("concept formation") matches the multi-word phrase, not individual words "concept" and "formation" separately.

4. `test_original_term_boosted()` — The original matched term appears twice in the expanded query (per decision [04-01] boosting).

5. `test_max_synonyms_limit()` — With max_synonyms=1, only 1 synonym added per matched term.

6. `test_case_insensitive_matching()` — expand_query("EGOISM") matches the lowercase glossary entry.

7. `test_multiple_terms_expanded()` — Query containing multiple glossary terms (e.g., "egoism and altruism") expands both.

8. `test_load_glossary_returns_dict()` — load_glossary() returns a dict with >40 entries.

9. `test_longest_phrase_first()` — A query containing "rational self-interest" matches that phrase before matching "interest" alone (if "interest" were in the glossary).

**File 2: `tests/test_reranker.py`** — Reranker with mocked API tests.

Read `src/objlib/search/reranker.py` first to understand:
- The `rerank_passages()` function signature
- How it calls `client.models.generate_content()`
- How it uses the response's `.parsed` attribute (expects `RankedResults` Pydantic model)
- The `apply_difficulty_ordering()` function and its modes

Tests to implement:

1. `test_rerank_applies_scores(mock_gemini_client)` — Set up mock to return RankedResults with 3 passages at scores [0.95, 0.60, 0.80]. Call rerank function. Assert output is ordered by relevance_score descending.

2. `test_rerank_handles_empty_passages(mock_gemini_client)` — Mock returns RankedResults with empty passages list. Assert function handles gracefully (returns empty or passes through input).

3. `test_difficulty_ordering_learn_mode()` — Given citations with difficulty values ["advanced", "introductory", "intermediate"], apply_difficulty_ordering in "learn" mode. Assert introductory first, then intermediate, then advanced.

4. `test_difficulty_ordering_research_mode()` — Same input but "research" mode. Assert advanced first.

5. `test_difficulty_ordering_missing_difficulty()` — Some citations have no difficulty metadata. Assert they default to "intermediate" (per decision [04-02]) and sort correctly.

6. `test_difficulty_window_size()` — With window_size=2, only the top 2 results are reordered by difficulty; the rest stay in relevance order (per decision [04-02], window_size=20 default, but test the mechanism with smaller window).

7. `test_rerank_prompt_includes_query()` — Verify that the prompt passed to generate_content includes the original query string. Use `mock_gemini_client.models.generate_content.call_args` to inspect the prompt.

Read `src/objlib/search/models.py` for exact field names: `RankedPassage(original_index, relevance_score, difficulty)`, `RankedResults(passages)`. Use these exact names when constructing mock responses.

For reranker tests, mock at the `client.models.generate_content()` boundary. The function takes the client as a parameter. Construct mock return values using:
```python
from unittest.mock import MagicMock
from objlib.search.models import RankedPassage, RankedResults

mock_response = MagicMock()
mock_response.parsed = RankedResults(passages=[
    RankedPassage(original_index=0, relevance_score=0.95, difficulty="introductory"),
    # ...
])
mock_client.models.generate_content.return_value = mock_response
```
  </action>
  <verify>
Run `cd /Users/david/projects/objectivism-library-semantic-search && python -m pytest tests/test_expansion.py tests/test_reranker.py -v --tb=short 2>&1 | tail -30` to confirm all expansion and reranker tests pass.
  </verify>
  <done>9+ expansion tests and 7+ reranker tests covering synonym lookup, multi-word phrases, boosting, score ordering, difficulty modes, missing difficulty defaults, and window-size mechanics. All pass with mocked API boundary.</done>
</task>

<task type="auto">
  <name>Task 2: Synthesizer, citation validation, MMR, and metadata filter tests</name>
  <files>tests/test_synthesizer.py</files>
  <action>
Read `src/objlib/search/synthesizer.py` and `src/objlib/search/__init__.py` (for `build_metadata_filter` or equivalent citation/filter functions) first.

Identify the exact function signatures for:
- `validate_citations(claims, passage_texts)` — pure logic, no mock needed
- `apply_mmr_diversity(citations)` — pure logic, no mock needed
- `_normalize(text)` — internal helper for whitespace normalization
- `build_metadata_filter(filters_dict)` — generates AIP-160 filter string
- `extract_citations(grounding_metadata)` — parses Gemini grounding metadata
- `enrich_citations(citations, db)` — looks up file metadata for citations

Tests to implement:

**Citation validation (pure logic):**

1. `test_validate_citations_exact_match()` — Claim with verbatim_quote that appears exactly in the passage text. Assert validation passes.

2. `test_validate_citations_whitespace_normalization()` — Quote with extra whitespace ("multi   word   quote") matches passage containing "multi word quote". Assert validation passes (via _normalize).

3. `test_validate_citations_case_insensitive()` — Quote differs only in case from passage text. Assert validation passes.

4. `test_validate_citations_fabricated_quote()` — Quote not present in any passage. Assert validation fails (returned in errors list).

5. `test_validate_citations_empty_claims()` — Empty claims list. Assert returns empty valid and empty errors.

**MMR diversity (pure logic):**

6. `test_mmr_removes_same_file_duplicates()` — 4 citations, 2 from same file_path. Assert MMR keeps only 1 per file in first pass (per decision [04-03]: MMR first pass prefers unseen files).

7. `test_mmr_preserves_different_files()` — 4 citations from 4 different files. Assert all 4 preserved.

8. `test_mmr_prefers_unseen_courses()` — Citations from same course vs different courses. Assert different courses preferred (per decision [04-03]).

**Metadata filter syntax:**

9. `test_build_metadata_filter_single_field()` — `{"course": "OPAR"}` generates correct AIP-160 filter string.

10. `test_build_metadata_filter_multiple_fields()` — `{"course": "OPAR", "difficulty": "introductory"}` generates combined filter.

11. `test_build_metadata_filter_numeric_field()` — Filter with `year` or `week` field. Assert CAST is used for numeric comparison (per decision from STATE.md).

12. `test_build_metadata_filter_empty()` — Empty dict returns empty string or None (no filter).

**Citation extraction (needs grounding metadata mock):**

13. `test_extract_citations_from_grounding()` — Construct a mock grounding_metadata object mimicking Gemini's response structure. Assert citations extracted with correct file references.

14. `test_enrich_citations_maps_gemini_ids(in_memory_db)` — Insert files with gemini_file_id into DB. Call enrich_citations with citation objects containing Gemini IDs. Assert file metadata (course, topic, etc.) is populated on enriched citations.

15. `test_enrich_citations_fallback_to_filename(in_memory_db)` — Citation has display_name instead of Gemini ID. Assert lookup by filename works as fallback (per decision: two-pass lookup).

**Normalization:**

16. `test_normalize_collapses_whitespace()` — Multiple spaces, tabs, newlines → single space.

17. `test_normalize_lowercases()` — Mixed case → all lowercase.

Read `src/objlib/search/__init__.py` and `src/objlib/search/synthesizer.py` to find exact import paths for these functions. Some may be in `__init__.py` (build_metadata_filter, extract_citations, enrich_citations) vs `synthesizer.py` (validate_citations, apply_mmr_diversity, _normalize).
  </action>
  <verify>
Run `cd /Users/david/projects/objectivism-library-semantic-search && python -m pytest tests/test_synthesizer.py -v --tb=short 2>&1 | tail -30` to confirm all synthesis/citation tests pass.

Then run `python -m pytest tests/ -x -q --tb=short 2>&1 | tail -10` to confirm no regressions.
  </verify>
  <done>17+ tests covering citation validation (exact, normalized, fabricated), MMR diversity (same-file dedup, course diversity), metadata filter syntax (single, multiple, numeric, empty), citation extraction from grounding metadata, enrichment with DB lookup, and text normalization. All pass. No regressions.</done>
</task>

</tasks>

<verification>
- `python -m pytest tests/test_expansion.py tests/test_reranker.py tests/test_synthesizer.py -v` — all search pipeline tests pass
- `python -m pytest tests/ -x -q` — all existing tests still pass (no regressions)
- No API calls made (all mocked or pure logic)
</verification>

<success_criteria>
- test_expansion.py: 9+ tests for glossary synonym expansion
- test_reranker.py: 7+ tests for AI scoring and difficulty bucketing
- test_synthesizer.py: 17+ tests for MMR, citation validation, metadata filters, normalization
- All pure logic functions tested without mocking
- AI-dependent functions tested with mocked client.models.generate_content
- Zero regressions in existing test suite
</success_criteria>

<output>
After completion, create `.planning/phases/06.3-test-foundation-canon-governance/06.3-03-SUMMARY.md`
</output>
