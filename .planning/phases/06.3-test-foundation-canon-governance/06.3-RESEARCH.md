# Phase 6.3: Test Foundation & Canon Governance - Research

**Researched:** 2026-02-18
**Domain:** Retroactive testing (pytest, pyfakefs, unittest.mock), Canon governance skills (Claude Code Skills format)
**Confidence:** HIGH

<user_constraints>
## User Constraints (from CONTEXT.md / CLARIFICATIONS-ANSWERED.md)

### Locked Decisions

1. **Filesystem simulation: pyfakefs** (Q1 — Consensus)
   - Add `pyfakefs` as a test dependency
   - No refactoring of scanner or SyncDetector code needed
   - `pyfakefs` integrates natively with pytest via `fs` fixture
   - Correctly handles the mtime epsilon behavior documented in STATE.md `[05-04]`
   - Check `src/objlib/sync/` for any inotify/kqueue calls (confirmed: NONE — only os.stat/pathlib)

2. **API mocking: Mock at API client boundary** (Q2 — Consensus)
   - `unittest.mock.patch` at the API client boundary for unit tests
   - No HTTP mock server for this retroactive phase
   - Focus tests on the plumbing, not the intelligence
   - Mock `client.models.generate_content()` for reranker/synthesizer
   - Do NOT test that the AI returns good results

3. **Schema migration scope: Test cumulative initialization and idempotency** (Q3 — Consensus)
   - Database uses `CREATE TABLE IF NOT EXISTS` + `try/except ALTER TABLE` + `PRAGMA user_version`
   - Test V7 schema initialization from scratch and verify all tables/columns/triggers
   - Test idempotency: second initialization on existing DB has no errors, no data loss
   - Test key columns from each major schema version (V1-V7)
   - Test foreign key constraints with `PRAGMA foreign_keys = ON`

4. **Canon.json template: Single template with placeholder variables** (Q4 — Synthesis)
   - One template with `{{PLACEHOLDER}}` variables
   - Workflow-specific defaults in `rules/gsd-rules.md`, `rules/ralph-rules.md`, `rules/bmad-rules.md`
   - Add `"_canon_workflow": "gsd"` metadata field to Canon.json
   - Generate `client-interface.md` in same `canon-init` execution

5. **Workflow detection: Algorithm in SKILL.md, signals in reference files** (Q5 — Synthesis)
   - Detection priority: (1) existing Canon.json `_canon_workflow`, (2) BMAD config files, (3) GSD artifacts, (4) Ralph artifacts, (5) Generic fallback
   - Ambiguity: output warning, do NOT silently pick one
   - Detection results NOT written to Canon.json automatically

6. **canon-update hook: Integrate Layer 1 audit into /update-docs** (Q6 — Synthesis)
   - Lightweight check added to `update-docs.md`
   - Full `canon-update` available for comprehensive audit

7. **Test coverage: 80% line coverage per module** (Q7)
   - Run: `pytest --cov=src/objlib --cov-report=html tests/`
   - Exclude `cli.py` from coverage measurement
   - Branch coverage measured but not gated
   - Primary gate: functional checklist completion per plan

8. **Test fixtures: Shared `tests/conftest.py` with real Database.initialize()** (Q8)
   - `in_memory_db()` fixture with `Database.__new__()` + manual `_conn` + `initialize()`
   - `populated_db()` with canonical test files
   - `mock_gemini_client()` with deterministic MagicMock
   - `scope="function"` (default) for all fixtures

### Claude's Discretion
- Test file organization within `tests/` directory
- Specific test case selection beyond the required checklists
- Canon skill SKILL.md prompt engineering details
- Workflow reference file internal structure

### Deferred Ideas (OUT OF SCOPE)
- Contract testing with HTTP mock server
- Testing Gemini API quality / relevance of results
- Historical migration script fabrication (V1->V2->V3 discrete steps)
- MCP server implementation for Canon (Skills chosen, not MCP)
</user_constraints>

## Summary

Phase 6.3 comprises four waves across eight plans. The retroactive test suite (Wave 1, plans 01-04) covers database schema, metadata extraction, search pipeline, sync/entities/sessions -- all without disk I/O or API calls, using pyfakefs and unittest.mock. The workflow research wave (Wave 2, plan 05) investigates GSD, Ralph, and BMAD workflow detection signals. Canon skill implementation (Wave 3, plans 06-07) builds global Claude Code Skills at `~/.claude/skills/`. Wave 4 (plan 08) applies everything to this project.

The codebase already has 120+ tests across 10 test files, covering scanner, database, metadata, search citations, entity extraction, browse/filter, upload, and formatting. However, significant gaps exist: no tests for the sync pipeline (SyncDetector, disk utility), no tests for the reranker or synthesizer, no tests for SessionManager, and no tests for query expansion. The existing test infrastructure uses file-based SQLite (for WAL support) and temporary directories -- the new tests will add in-memory SQLite fixtures and pyfakefs for filesystem simulation.

The search pipeline has clean mock boundaries at `client.models.generate_content()` which is the consistent API entry point for both reranker and synthesizer. Citation extraction and enrichment operate on intermediate data models, not raw Gemini response objects, making them straightforward to mock. Entity fuzzy matching is entirely local (rapidfuzz algorithm against canonical person list) and needs no API mocking at all.

**Primary recommendation:** Start with plan 01 (database schema tests) to establish the `in_memory_db` fixture in `conftest.py`, which all subsequent plans depend on. Plans 02-04 can then run in parallel since they share fixtures but test independent modules.

## Standard Stack

### Core
| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| pytest | >=8.0 | Test framework | Already in dev dependencies; standard Python test framework |
| pyfakefs | >=5.7 | Filesystem mocking | Intercepts os/pathlib at OS level; no code refactoring needed |
| unittest.mock | stdlib | API mocking | Part of Python stdlib; standard for unit test mocking |
| pytest-cov | >=5.0 | Coverage measurement | Already in dev dependencies; wraps coverage.py for pytest |

### Supporting
| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| pytest-asyncio | >=0.24 | Async test support | Already in dev dependencies; needed if testing async methods |
| rapidfuzz | ==3.6.1 | Fuzzy string matching | Already a production dependency; used in entity matching tests |

### Alternatives Considered
| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| pyfakefs | unittest.mock.patch on individual os calls | Misses OS interaction bugs; requires knowing every call site |
| unittest.mock | pytest-httpx / responses | Adds HTTP-level complexity; overkill for API client boundary mocking |

**Installation:**
```bash
pip install pyfakefs>=5.7
```

Add to `pyproject.toml`:
```toml
[project.optional-dependencies]
dev = [
    "pytest>=8.0",
    "pytest-cov>=5.0",
    "pytest-asyncio>=0.24",
    "pyfakefs>=5.7",
]
```

## Architecture Patterns

### Recommended Test Structure
```
tests/
├── conftest.py             # Shared fixtures: in_memory_db, populated_db, mock_gemini_client
├── test_database.py        # [EXISTS] 12 tests — extend with schema V1-V7, CRUD, triggers
├── test_scanner.py         # [EXISTS] 8 tests — extend with pyfakefs-based tests
├── test_metadata.py        # [EXISTS] 10 tests — extend with edge cases
├── test_search.py          # [EXISTS] 14 tests — extend with reranker, synthesizer, expansion
├── test_entity_extraction.py  # [EXISTS] 19 tests — extend with session, sync tests
├── test_formatter.py       # [EXISTS] 16 tests — no changes needed
├── test_browse_filter.py   # [EXISTS] 17 tests — no changes needed
├── test_upload.py          # [EXISTS] 14 tests — no changes needed
├── test_integration.py     # [EXISTS] 2 tests — no changes needed
├── test_schema.py          # [NEW] Plan 01: schema migration V1-V7
├── test_sync.py            # [NEW] Plan 04: SyncDetector, disk utility
├── test_session.py         # [NEW] Plan 04: SessionManager CRUD, append-only
├── test_reranker.py        # [NEW] Plan 03: reranker with mocked generate_content
├── test_synthesizer.py     # [NEW] Plan 03: synthesis, MMR, citation validation
└── test_expansion.py       # [NEW] Plan 03: query expansion with glossary
```

### Pattern 1: In-Memory Database Fixture
**What:** Create a fresh initialized in-memory SQLite database per test function using the real `Database.initialize()` method.
**When to use:** All tests that need database state (plans 01-04).
**Example:**
```python
# tests/conftest.py
import sqlite3
import pytest
from objlib.database import Database

@pytest.fixture
def in_memory_db():
    """Fresh initialized in-memory SQLite database."""
    conn = sqlite3.connect(":memory:")
    conn.row_factory = sqlite3.Row
    conn.execute("PRAGMA foreign_keys = ON")
    db = Database.__new__(Database)  # Skip __init__ path validation
    db._conn = conn
    db.db_path = ":memory:"
    db.initialize()  # Calls real initialization — tests it works
    yield db
    conn.close()
```

**Critical implementation detail:** The existing `Database.__init__` validates that `db_path` is a real filesystem path and opens a file-based connection. Using `Database.__new__()` bypasses `__init__` entirely, allowing manual `_conn` injection. The `initialize()` method only uses `self._conn` and does not re-validate the path.

### Pattern 2: pyfakefs for Scanner/Sync Tests
**What:** Use pyfakefs `fs` fixture to intercept all `os.*` and `pathlib.Path` calls, creating an in-memory filesystem.
**When to use:** Scanner tests (plan 02) and SyncDetector/disk utility tests (plan 04).
**Example:**
```python
def test_scanner_discovers_files(fs):
    """pyfakefs injects `fs` fixture, intercepts all os/pathlib calls."""
    fs.create_file("/library/Courses/Test/Lesson01.txt", contents="x" * 200)
    fs.create_file("/library/Courses/Test/Lesson02.txt", contents="y" * 200)
    fs.create_file("/library/Courses/Test/.hidden.txt", contents="z" * 200)

    config = ScannerConfig(library_path=Path("/library"), db_path=Path(":memory:"))
    # ... scanner should find 2 files (skip hidden)
```

**pyfakefs scope:** The `fs` fixture automatically patches:
- `os.walk`, `os.stat`, `os.path.getsize`, `os.path.isdir`, `os.listdir`
- `pathlib.Path.stat()`, `pathlib.Path.exists()`, `pathlib.Path.iterdir()`
- `open()` / `builtins.open`

All of these are used by `scanner.py`, `sync/detector.py`, and `sync/disk.py`. No inotify/kqueue/watchdog calls exist in the codebase.

### Pattern 3: API Client Boundary Mocking
**What:** Mock at `client.models.generate_content()` for reranker and synthesizer tests.
**When to use:** Search pipeline tests (plan 03) that involve AI-generated responses.
**Example:**
```python
from unittest.mock import MagicMock, patch

@pytest.fixture
def mock_genai_client():
    """Mock Google GenAI client with deterministic responses."""
    mock = MagicMock()
    # Reranker expects RankedResults JSON
    mock.models.generate_content.return_value = MagicMock(
        parsed=RankedResults(passages=[
            RankedPassage(original_index=0, relevance_score=0.95, difficulty="introductory"),
            RankedPassage(original_index=2, relevance_score=0.80, difficulty="advanced"),
        ])
    )
    return mock
```

### Pattern 4: Entity Fuzzy Matching (No Mocking Needed)
**What:** Entity fuzzy matching uses `rapidfuzz.fuzz.token_set_ratio` against a local canonical person list loaded from the database.
**When to use:** Plan 04 entity tests.
**Example:**
```python
def test_fuzzy_match_threshold(in_memory_db):
    """Fuzzy match at score >= 92 auto-accepts, 80-91 needs LLM, <80 rejects."""
    registry = PersonRegistry(in_memory_db._conn)
    extractor = EntityExtractor(registry)
    # "Lenard Peikof" fuzzy matches "Leonard Peikoff" with score ~87 (MAYBE zone)
    # "Leonard Peikoff" exact matches with score 100 (ACCEPT)
```

**Threshold constants (from `src/objlib/entities/extractor.py`):**
- `FUZZY_ACCEPT = 92` — auto-accept, no LLM needed
- `FUZZY_MAYBE = 80` — LLM fallback needed for disambiguation
- `MIN_CONFIDENCE = 0.5` — minimum confidence to include in results
- Window for full-name disambiguation: +/- 200 characters

### Anti-Patterns to Avoid
- **Testing AI quality:** Never assert that a mocked Gemini response is "correct" or "relevant." Tests verify plumbing (prompt construction, response parsing, error handling), not intelligence.
- **File-based DB for unit tests:** The existing `tmp_db` fixture uses file-based SQLite for WAL support. New in-memory fixtures (`in_memory_db`) skip WAL but are faster and disposable. Use in-memory for unit tests; keep file-based only where WAL behavior is explicitly tested.
- **Sharing mutable state across tests:** All fixtures use `scope="function"` (per-test isolation). Never use `scope="session"` or `scope="module"` for database fixtures.
- **Hardcoding Gemini response formats:** The search pipeline uses Pydantic structured output models (`RankedResults`, `SynthesisOutput`). Mock at the Pydantic model level, not at the raw JSON level.

## Don't Hand-Roll

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| Filesystem mocking | Custom os.stat/pathlib patches | pyfakefs `fs` fixture | Handles all OS interactions transparently; tested by the pyfakefs project |
| API response mocking | Custom FakeGeminiClient class | `unittest.mock.MagicMock` with `.parsed` attribute | Production code accesses `response.parsed` for Pydantic models; MagicMock handles attribute access natively |
| Coverage enforcement | Manual test counting | `pytest-cov` with `fail_under = 80` | Automatically enforced, integrated with CI |
| Test database setup | Manual SQL INSERT statements for schema | Real `Database.initialize()` call on `:memory:` | Tests the actual initialization code; catches schema bugs |
| Fuzzy match testing | Synthetic fuzzy score functions | Real `rapidfuzz.fuzz.token_set_ratio` | Production dependency already installed; use real algorithm |

**Key insight:** This is a retroactive test suite. The goal is to test existing code as-is, not to refactor for testability. pyfakefs and `Database.__new__()` are the two key patterns that make existing code testable without modification.

## Common Pitfalls

### Pitfall 1: Database.__init__ Path Validation
**What goes wrong:** Calling `Database(":memory:")` fails because `__init__` validates the directory exists and opens a file connection.
**Why it happens:** The `__init__` method calls `Path(db_path).parent.mkdir(parents=True, exist_ok=True)` and passes a string path to `sqlite3.connect()`.
**How to avoid:** Use `Database.__new__(Database)` to skip `__init__`, then manually set `db._conn`, `db.db_path`, and call `db.initialize()`.
**Warning signs:** `FileNotFoundError` or `OperationalError` when creating in-memory database fixtures.

### Pitfall 2: Row Factory Not Set on In-Memory Connection
**What goes wrong:** Tests fail with `TypeError: tuple indices must be integers` when accessing query results by column name.
**Why it happens:** The `Database.__init__` sets `conn.row_factory = sqlite3.Row`, but when bypassing `__init__`, this is not set.
**How to avoid:** Always set `conn.row_factory = sqlite3.Row` on in-memory connections before calling `initialize()`.
**Warning signs:** Tests pass with integer indexing but fail when production code accesses `row["column_name"]`.

### Pitfall 3: pyfakefs Conflicts with SQLite
**What goes wrong:** pyfakefs intercepts `sqlite3.connect()` file access, causing database connection failures.
**Why it happens:** pyfakefs patches `open()` at the builtins level, which can interfere with C-level SQLite file operations.
**How to avoid:** When combining pyfakefs with SQLite:
- Use in-memory SQLite (`:memory:`) for database fixtures within pyfakefs tests
- OR pass `patcher.pause()` / `patcher.resume()` around database operations
- OR use `fs.add_real_directory()` to exclude database paths from faking
**Warning signs:** `sqlite3.OperationalError: unable to open database file` in pyfakefs tests.

### Pitfall 4: Foreign Keys Disabled by Default
**What goes wrong:** Tests insert data violating foreign key constraints without error, then fail when querying joins.
**Why it happens:** SQLite disables foreign key enforcement by default. The `Database.__init__` runs `PRAGMA foreign_keys = ON` but bypassed `__init__` skips this.
**How to avoid:** Explicitly run `conn.execute("PRAGMA foreign_keys = ON")` in the `in_memory_db` fixture before `initialize()`.
**Warning signs:** Orphaned child records, missing JOIN results, no errors on invalid foreign key inserts.

### Pitfall 5: Schema Migration Version Check
**What goes wrong:** The `initialize()` method checks `PRAGMA user_version` and conditionally runs migrations. On a fresh `:memory:` database, `user_version` is 0, so all migrations run. But if a test manually sets `user_version` to skip migrations, subsequent schema assertions fail.
**Why it happens:** The migration pattern is `if version < N: run migration N; set user_version = N`.
**How to avoid:** Let `initialize()` run all migrations naturally on fresh databases. Test idempotency by calling `initialize()` twice on the same connection.
**Warning signs:** Missing tables/columns when testing partial migration scenarios.

### Pitfall 6: SyncDetector Safety Guard
**What goes wrong:** SyncDetector raises `RuntimeError` when >50% of tracked files are "missing." This is the disk-disconnect safety guard.
**Why it happens:** In pyfakefs, if you set up DB state with 100 files but only create 10 files on the fake filesystem, the safety guard triggers.
**How to avoid:** Ensure pyfakefs filesystem state and database state are consistent. If testing the safety guard, set up the right ratio intentionally.
**Warning signs:** `RuntimeError: SAFETY ABORT: N/M files (X%) are missing from disk` in tests that aren't testing disconnect behavior.

### Pitfall 7: SessionManager Requires row_factory = sqlite3.Row
**What goes wrong:** SessionManager methods access results via column name (`row["id"]`, `row["name"]`), not positional index.
**Why it happens:** SessionManager takes a `sqlite3.Connection` directly and assumes `row_factory` is already set.
**How to avoid:** Set `conn.row_factory = sqlite3.Row` on the connection before passing to `SessionManager`.
**Warning signs:** `TypeError` or `KeyError` in session test results.

## Code Examples

### Database Schema Verification (Plan 01)
```python
# Source: src/objlib/database.py — cumulative migration pattern
def test_fresh_schema_initialization(in_memory_db):
    """All tables from V1-V7 exist after fresh initialization."""
    tables = {row[0] for row in in_memory_db._conn.execute(
        "SELECT name FROM sqlite_master WHERE type='table'"
    ).fetchall()}

    # V1 tables
    assert "files" in tables
    assert "_processing_log" in tables
    assert "_extraction_failures" in tables
    assert "_skipped_files" in tables
    assert "upload_operations" in tables
    assert "upload_batches" in tables
    assert "upload_locks" in tables

    # V3 tables
    assert "file_metadata_ai" in tables
    assert "file_primary_topics" in tables
    assert "wave1_results" in tables

    # V4 tables
    assert "person" in tables
    assert "person_alias" in tables
    assert "transcript_entity" in tables

    # V6 tables
    assert "passages" in tables
    assert "sessions" in tables
    assert "session_events" in tables

    # V7 columns on files table
    cols = {row[1] for row in in_memory_db._conn.execute(
        "PRAGMA table_info(files)"
    ).fetchall()}
    assert "mtime" in cols
    assert "orphaned_gemini_file_id" in cols
    assert "enrichment_version" in cols

    # V7 table
    assert "library_config" in tables


def test_schema_idempotency(in_memory_db):
    """Second initialization on existing DB is harmless."""
    in_memory_db.initialize()  # Second call
    # No error, schema still intact
    tables = {row[0] for row in in_memory_db._conn.execute(
        "SELECT name FROM sqlite_master WHERE type='table'"
    ).fetchall()}
    assert "files" in tables
    assert "sessions" in tables


def test_triggers_exist(in_memory_db):
    """Both triggers (timestamp update + status log) are present."""
    triggers = {row[0] for row in in_memory_db._conn.execute(
        "SELECT name FROM sqlite_master WHERE type='trigger'"
    ).fetchall()}
    assert "update_files_timestamp" in triggers
    assert "log_status_change" in triggers
```

### SyncDetector with pyfakefs (Plan 04)
```python
# Source: src/objlib/sync/detector.py — mtime optimization
def test_mtime_unchanged_skips_hash(fs, in_memory_db):
    """Files with unchanged mtime skip hash computation."""
    fs.create_file("/lib/test.txt", contents="content here " * 50)
    mtime = os.stat("/lib/test.txt").st_mtime

    # Pre-populate DB with same hash and mtime
    content_hash = FileScanner.compute_hash(Path("/lib/test.txt"))
    in_memory_db.upsert_file("/lib/test.txt", hash=content_hash, size=650)
    in_memory_db.update_file_sync_columns("/lib/test.txt", mtime=mtime)

    # SyncDetector should skip this file (mtime unchanged)
    # ... assert changeset.mtime_skipped_count == 1
```

### Disk Utility with pyfakefs (Plan 04)
```python
# Source: src/objlib/sync/disk.py — check_disk_availability
def test_disk_available(fs):
    """Disk with files reports 'available'."""
    fs.create_dir("/Volumes/U32 Shadow")
    fs.create_file("/Volumes/U32 Shadow/test.txt")
    result = check_disk_availability("/Volumes/U32 Shadow", "/Volumes/U32 Shadow/Library")
    # ... depends on exact function signature — verify before writing tests


def test_disk_unavailable(fs):
    """Missing mount point reports 'unavailable'."""
    # /Volumes/U32 Shadow does not exist in fake filesystem
    result = check_disk_availability("/Volumes/U32 Shadow", "/Volumes/U32 Shadow/Library")
    # ... should return "unavailable"
```

### Reranker with Mocked API (Plan 03)
```python
# Source: src/objlib/search/reranker.py
from unittest.mock import MagicMock
from objlib.search.models import RankedPassage, RankedResults

def test_rerank_applies_scores(mock_genai_client):
    """Reranker applies AI scores to citations in correct order."""
    mock_genai_client.models.generate_content.return_value = MagicMock(
        parsed=RankedResults(passages=[
            RankedPassage(original_index=0, relevance_score=0.95, difficulty="introductory"),
            RankedPassage(original_index=1, relevance_score=0.60, difficulty="advanced"),
        ])
    )
    # Call rerank_passages with the mock client
    # Assert citations are reordered by relevance_score descending
```

### Citation Validation (Plan 03)
```python
# Source: src/objlib/search/synthesizer.py — validate_citations is pure logic
def test_validate_citations_exact_match():
    """Exact quote matches validate successfully."""
    claims = [Claim(
        statement="Reason is man's means of survival.",
        citation=CitationRef(passage_id=0, verbatim_quote="Reason is man's basic means"),
    )]
    passage_texts = {0: "For man, reason is man's basic means of survival."}
    valid, errors = validate_citations(claims, passage_texts)
    assert len(valid) == 1
    assert len(errors) == 0


def test_validate_citations_whitespace_normalization():
    """Whitespace differences don't cause validation failure."""
    # validate_citations uses _normalize() which collapses whitespace and lowercases
    claims = [Claim(
        statement="Test claim.",
        citation=CitationRef(passage_id=0, verbatim_quote="multi   word   quote"),
    )]
    passage_texts = {0: "This is a multi word quote from the source."}
    valid, errors = validate_citations(claims, passage_texts)
    assert len(valid) == 1
```

### SessionManager (Plan 04)
```python
# Source: src/objlib/session/manager.py
def test_session_create_and_retrieve(in_memory_db):
    """Create session, retrieve by ID."""
    mgr = SessionManager(in_memory_db._conn)
    sid = mgr.create("Test Research")
    session = mgr.get_session(sid)
    assert session["name"] == "Test Research"


def test_append_only_events(in_memory_db):
    """Events can only be added, never updated or deleted individually."""
    mgr = SessionManager(in_memory_db._conn)
    sid = mgr.create("Test")
    eid = mgr.add_event(sid, "search", {"query": "free will"})
    events = mgr.get_events(sid)
    assert len(events) == 1
    assert events[0]["event_type"] == "search"
    # No update_event or delete_event methods exist on SessionManager


def test_invalid_event_type_raises(in_memory_db):
    """Invalid event type raises ValueError."""
    mgr = SessionManager(in_memory_db._conn)
    sid = mgr.create("Test")
    with pytest.raises(ValueError, match="Invalid event_type"):
        mgr.add_event(sid, "invalid_type", {})


def test_find_by_prefix_ambiguity(in_memory_db):
    """find_by_prefix returns None for ambiguous prefixes."""
    mgr = SessionManager(in_memory_db._conn)
    # Create two sessions — any single-char prefix likely matches both
    mgr.create("Session A")
    mgr.create("Session B")
    # Very short prefix should be ambiguous (matches both)
    # Exact UUID prefix should find exactly one
```

### Query Expansion (Plan 03)
```python
# Source: src/objlib/search/expansion.py — uses YAML glossary
def test_expand_query_adds_synonyms():
    """Query expansion adds glossary synonyms to search query."""
    # The expansion module loads a YAML glossary file
    # Test with a known term that has synonyms defined
    # No API mocking needed — this is local YAML lookup
```

### Coverage Configuration (pyproject.toml)
```toml
# Add to pyproject.toml
[tool.coverage.run]
omit = ["src/objlib/cli.py", "src/objlib/__pycache__/*"]

[tool.coverage.report]
fail_under = 80
```

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| File-based SQLite for all tests | In-memory SQLite for unit tests, file-based only for WAL tests | This phase | Faster test execution, no temp file cleanup |
| No filesystem mocking | pyfakefs for scanner/sync tests | This phase | Tests run without disk I/O; can test edge cases (missing files, permissions) |
| No coverage enforcement | 80% line coverage with pytest-cov | This phase | Measurable test quality gate |
| Testing only happy paths | Explicit error path testing (malformed JSON, missing files, safety guards) | This phase | Catches regression bugs in error handling |

**Deprecated/outdated:**
- `tmp_db` fixture (file-based): Still works, but new tests should use `in_memory_db` for speed. Keep `tmp_db` for existing tests that need WAL mode.
- Direct `Database(":memory:")` calls: Fails due to `__init__` path validation. Use `Database.__new__()` pattern instead.

## Open Questions

1. **pyfakefs + sqlite3 interaction**
   - What we know: pyfakefs patches `builtins.open` and `os.*` functions. SQLite uses C-level file I/O that may bypass Python's `open()`.
   - What's unclear: Whether `sqlite3.connect("file_path")` is intercepted by pyfakefs when used alongside `fs` fixture for scanner tests.
   - Recommendation: Use `:memory:` SQLite within pyfakefs tests. If file-based SQLite is needed alongside pyfakefs, use `fs.add_real_directory()` or `fs.pause()` / `fs.resume()` around SQLite operations. Test this empirically before writing many tests.

2. **Existing test compatibility with new conftest.py fixtures**
   - What we know: Existing `conftest.py` has `tmp_db`, `tmp_library`, `scanner_config`, `metadata_extractor` fixtures. New `in_memory_db`, `populated_db`, `mock_gemini_client` must coexist.
   - What's unclear: Whether any existing tests will break if `conftest.py` is extended (unlikely, since new fixtures have different names).
   - Recommendation: Add new fixtures alongside existing ones. Do not remove or modify existing fixtures. Run full existing test suite after adding new fixtures to verify no breakage.

3. **V7 migration table rebuild in-memory**
   - What we know: The V7 migration drops and recreates the `files` table (`DROP TABLE files; ALTER TABLE files_v7 RENAME TO files`). On a fresh `:memory:` database, this happens during `initialize()`.
   - What's unclear: Whether the `files_v7` intermediate table and rename works cleanly on `:memory:` (it should, since it's just SQL, but the `DROP TABLE files` references the table created by SCHEMA_SQL, and the trigger recreations may have ordering issues).
   - Recommendation: The first test in plan 01 should verify `initialize()` succeeds on fresh `:memory:` without error. If it fails, diagnose the specific migration step.

4. **Ralph and BMAD detection signals**
   - What we know: GSD detection is well-defined (`.planning/STATE.md` + `.planning/ROADMAP.md`). Ralph and BMAD signals are TBD from plan 05 research.
   - What's unclear: What files Ralph and BMAD projects use as control documents.
   - Recommendation: Plan 05 must produce concrete detection signal lists before plans 06-07 can implement the detection algorithm. This is the explicit Wave 2 -> Wave 3 dependency.

## Database Schema Audit

### Tables by Version (Total: 16 tables + 1 rebuild)

**SCHEMA_SQL (V1-V2 era):**
| Table | Primary Key | Purpose |
|-------|-------------|---------|
| `files` | `file_path TEXT` | Core file tracking (26 columns in V7) |
| `_processing_log` | `log_id INTEGER AUTOINCREMENT` | Status transition audit log |
| `_extraction_failures` | `failure_id INTEGER AUTOINCREMENT` | Pattern parsing failure tracking |
| `_skipped_files` | `skip_id INTEGER AUTOINCREMENT` | Skipped files log (too small, wrong type) |
| `upload_operations` | `operation_name TEXT` | Individual upload operation tracking |
| `upload_batches` | `batch_id INTEGER AUTOINCREMENT` | Logical batch tracking |
| `upload_locks` | `lock_id INTEGER CHECK(lock_id = 1)` | Single-writer lock (max 1 row) |

**MIGRATION_V3_SQL:**
| Table | Primary Key | Purpose |
|-------|-------------|---------|
| `file_metadata_ai` | `metadata_id INTEGER AUTOINCREMENT` | Versioned AI metadata storage (append-only) |
| `file_primary_topics` | `(file_path, topic_tag)` | Controlled vocabulary topic index |
| `wave1_results` | `result_id INTEGER AUTOINCREMENT` | Strategy comparison results |

**MIGRATION_V4_SQL:**
| Table | Primary Key | Purpose |
|-------|-------------|---------|
| `person` | `person_id TEXT` | Canonical person registry (15 seeded) |
| `person_alias` | `id INTEGER AUTOINCREMENT` | Alias lookup (full_name, partial, nickname, title_variant, blocked) |
| `transcript_entity` | `(transcript_id, person_id)` | Transcript-level entity summary |

**MIGRATION_V6_SQL:**
| Table | Primary Key | Purpose |
|-------|-------------|---------|
| `passages` | `passage_id TEXT` | Citation passage cache |
| `sessions` | `id TEXT` | Research session tracking |
| `session_events` | `id TEXT` | Append-only session event log |

**MIGRATION_V7_SQL:**
| Table | Primary Key | Purpose |
|-------|-------------|---------|
| `library_config` | `key TEXT` | Key-value configuration store |
| `files` (rebuild) | `file_path TEXT` | Expanded CHECK constraint + 5 sync columns |

### Triggers (2 total)
1. `update_files_timestamp` — AFTER UPDATE on `files`, updates `updated_at` to current timestamp
2. `log_status_change` — AFTER UPDATE OF `status` on `files` WHEN `OLD.status != NEW.status`, inserts into `_processing_log`

### Foreign Key Relationships
- `_processing_log.file_path` -> `files.file_path`
- `_extraction_failures.file_path` -> `files.file_path`
- `upload_operations.file_path` -> `files.file_path`
- `file_metadata_ai.file_path` -> `files.file_path`
- `file_primary_topics.file_path` -> `files.file_path`
- `wave1_results.file_path` -> `files.file_path`
- `person_alias.person_id` -> `person.person_id`
- `transcript_entity.person_id` -> `person.person_id`
- `session_events.session_id` -> `sessions.id`

### Migration Pattern
```python
version = conn.execute("PRAGMA user_version").fetchone()[0]
if version < 3:
    conn.executescript(MIGRATION_V3_SQL)
    conn.execute("PRAGMA user_version = 3")
if version < 4:
    conn.executescript(MIGRATION_V4_SQL)
    conn.execute("PRAGMA user_version = 4")
# ... through version 7
```

### Key CRUD Methods (~30+)
| Method | Module | Testable Without API |
|--------|--------|---------------------|
| `upsert_file()` | database.py | Yes |
| `upsert_files()` | database.py | Yes |
| `get_all_active_files()` | database.py | Yes |
| `mark_deleted()` | database.py | Yes |
| `get_status_counts()` | database.py | Yes |
| `log_skipped_file()` | database.py | Yes |
| `log_extraction_failure()` | database.py | Yes |
| `get_file_metadata_by_filenames()` | database.py | Yes |
| `get_file_metadata_by_gemini_ids()` | database.py | Yes |
| `get_pending_files()` | database.py | Yes |
| `update_file_status()` | database.py | Yes |
| `filter_files_by_metadata()` | database.py | Yes |
| `upsert_passage()` | database.py | Yes |
| `mark_stale_passages()` | database.py | Yes |
| `save_transcript_entities()` | database.py | Yes |
| `get_entity_stats()` | database.py | Yes |
| `mark_missing()` | database.py | Yes |
| `get_missing_files()` | database.py | Yes |
| `get_orphaned_files()` | database.py | Yes |
| `clear_orphan()` | database.py | Yes |
| `set_library_config()` | database.py | Yes |
| `get_library_config()` | database.py | Yes |
| `update_file_sync_columns()` | database.py | Yes |
| `get_file_with_sync_data()` | database.py | Yes |
| `get_all_active_files_with_mtime()` | database.py | Yes |

## Scanner/Sync OS Surface Audit

### scanner.py OS Calls
| Call | Location | pyfakefs Compatible |
|------|----------|-------------------|
| `os.walk(str(root), followlinks=...)` | `discover_files()` | Yes |
| `root.stat()` — `st_dev`, `st_ino` | `_get_device()` | Yes |
| `current.stat()` | symlink cycle detection | Yes |
| `os.path.getsize(str(full_path))` | file size check | Yes |
| `file_path.stat().st_size` | `compute_hash()` | Yes |
| `open(file_path, "rb")` | `compute_hash()` SHA-256 | Yes |
| `Path(...)` various | Path construction | Yes |

### sync/detector.py OS Calls
| Call | Location | pyfakefs Compatible |
|------|----------|-------------------|
| `os.stat(path_str).st_mtime` | mtime comparison | Yes |
| `os.path.getsize(path_str)` | file size for changeset | Yes |
| `file_path.stat()` — `st_size`, `st_mtime` | new file processing | Yes |

### sync/disk.py OS Calls
| Call | Location | pyfakefs Compatible |
|------|----------|-------------------|
| `os.path.isdir(mount_point)` | mount point check | Yes |
| `os.listdir(mount_point)` | directory non-empty check | Yes |
| `os.path.isdir(library_root)` | library root check | Yes |

**Verdict:** All OS calls are standard os/pathlib. No inotify, kqueue, watchdog, or platform-specific filesystem monitoring. pyfakefs handles all of these transparently.

## Search Pipeline Mock Boundaries

### Mock Points
| Module | Mock Target | What It Returns | Used By |
|--------|-------------|-----------------|---------|
| `reranker.py` | `client.models.generate_content()` | `response.parsed` -> `RankedResults` (Pydantic) | `rerank_passages()` |
| `synthesizer.py` | `client.models.generate_content()` | `response.parsed` -> `SynthesisOutput` (Pydantic) | `synthesize_answer()` |
| `client.py` | `genai.Client()` | File search response with grounding metadata | `GeminiSearchClient.query()` |

### Pure Logic Functions (No Mocking Needed)
| Function | Module | Input -> Output |
|----------|--------|-----------------|
| `build_metadata_filter()` | citations.py | `dict` -> AIP-160 filter `str` |
| `extract_citations()` | citations.py | grounding_metadata object -> `list[Citation]` |
| `enrich_citations()` | citations.py | `list[Citation]` + `Database` -> enriched `list[Citation]` |
| `apply_mmr_diversity()` | synthesizer.py | `list[Citation]` -> deduplicated `list[Citation]` |
| `validate_citations()` | synthesizer.py | claims + passage_texts -> valid + errors |
| `apply_difficulty_ordering()` | reranker.py | citations + mode -> reordered citations |
| `_normalize()` | synthesizer.py | text -> whitespace-collapsed lowercase text |

### Pydantic Structured Output Models
| Model | Module | Fields |
|-------|--------|--------|
| `RankedPassage` | search/models.py | `original_index`, `relevance_score`, `difficulty` |
| `RankedResults` | search/models.py | `passages: list[RankedPassage]` |
| `CitationRef` | search/models.py | `passage_id`, `verbatim_quote` |
| `Claim` | search/models.py | `statement`, `citation: CitationRef` |
| `SynthesisOutput` | search/models.py | `claims: list[Claim]`, `bridging_intro`, `bridging_conclusion` |

## Canon Skills Format

### SKILL.md Structure
```yaml
---
name: skill-name
description: One-line description of what the skill does
user-invocable: true
argument-hint: [arg1] [arg2]
---

# Skill Title

## Step 1: ...
## Step 2: ...
```

### Existing Skills Reference
| Skill | Location | Frontmatter |
|-------|----------|-------------|
| `safe-clear` | `~/.claude/skills/safe-clear/SKILL.md` | `name: safe-clear`, `argument-hint: []` |
| `download-video` | `~/.claude/skills/download-video/SKILL.md` | `argument-hint: [url] [output_name] [output_dir]` |
| `transcribe-video` | `~/.claude/skills/transcribe-video/SKILL.md` | `argument-hint: [video_path] [output_name] [speaker_names]` |

### Canon Skills Directory Structure
```
~/.claude/skills/
  canon-init/
    SKILL.md                        # Main prompt + frontmatter
    templates/
      Canon.json.template           # Single template with {{PLACEHOLDER}} variables
      client-interface.template.md  # Service boundary documentation template
    workflows/
      gsd.md                        # GSD detection signals + reading instructions
      ralph.md                      # Ralph detection signals (from plan 05 research)
      bmad.md                       # BMAD detection signals (from plan 05 research)
      generic.md                    # Fallback: pyproject.toml / package.json
  canon-update/
    SKILL.md
    workflows/
      gsd.md
      ralph.md
      bmad.md
      generic.md
```

### Template Variables
```
{{PROJECT_TITLE}}        — from project detection
{{PROJECT_DESCRIPTION}}  — from README or PROJECT.md
{{BRANCH}}               — from git branch
{{PUBLIC_FOLDERS}}       — from codebase analysis
{{EXCLUDE_FOLDERS}}      — from codebase analysis
{{EXCLUDE_FILES}}        — specific files to exclude
{{RULES}}                — from workflow-specific rules file
```

## Existing Test Coverage Assessment

### Tests by Module (120+ total)
| File | Tests | Module Covered | Gaps |
|------|-------|---------------|------|
| `test_database.py` | 12 | Database CRUD, WAL, triggers | Missing: V3-V7 schema, sync columns, passages, sessions tables, entity tables, library_config |
| `test_scanner.py` | 8 | File discovery, hashing, change detection | Missing: symlink edge cases, safety guard, pyfakefs-based tests |
| `test_metadata.py` | 10 | Pattern parsing, quality grading | Missing: edge case patterns, folder extraction failures |
| `test_search.py` | 14 | Citations, metadata filter | Missing: reranker, synthesizer, query expansion, client retry |
| `test_entity_extraction.py` | 19 | Fuzzy matching, blocked aliases | Good coverage; may need session/sync tests in same plan |
| `test_formatter.py` | 16 | Display formatting | Good coverage; no changes needed |
| `test_browse_filter.py` | 17 | Browse/filter operations | Good coverage; no changes needed |
| `test_upload.py` | 14 | Circuit breaker, rate limiter, state | Good coverage; no changes needed |
| `test_integration.py` | 2 | End-to-end scan lifecycle | Good coverage for integration level |
| `conftest.py` | - | Shared fixtures | Needs: in_memory_db, populated_db, mock_gemini_client |

### Coverage Gaps by Plan
| Plan | New Test Files | Key Gaps to Fill |
|------|---------------|-----------------|
| 01 | `test_schema.py` | Schema V1-V7 verification, idempotency, foreign keys, triggers, seed data |
| 02 | Extensions to `test_scanner.py`, `test_metadata.py` | pyfakefs scanner tests, metadata edge cases, change detection boundaries |
| 03 | `test_reranker.py`, `test_synthesizer.py`, `test_expansion.py` | Reranker scoring, MMR diversity, citation validation, whitespace normalization, query expansion |
| 04 | `test_sync.py`, `test_session.py` | SyncDetector mtime optimization, disk utility, safety guard, SessionManager CRUD/append-only |

## Sources

### Primary (HIGH confidence)
- **Codebase inspection** — All source files read directly: `database.py`, `scanner.py`, `sync/detector.py`, `sync/disk.py`, `search/citations.py`, `search/reranker.py`, `search/synthesizer.py`, `search/models.py`, `search/expansion.py`, `search/client.py`, `session/manager.py`, `entities/extractor.py`, `entities/registry.py`, `entities/models.py`, `config.py`, `models.py`
- **Existing test files** — All 10 test files and `conftest.py` read directly
- **Context7 `/pytest-dev/pyfakefs`** — `fs` fixture auto-patches os/pathlib, `fs.create_file()`, works with pathlib.Path, os.stat, os.walk
- **Context7 `/pytest-dev/pytest`** — conftest.py fixture sharing, scope options, function-scoped isolation

### Secondary (MEDIUM confidence)
- **CANON-CONTEXT.md** — Canon design decisions, skill directory structure, two-layer model
- **CLARIFICATIONS-ANSWERED.md** — YOLO decisions for all 8 phase questions
- **06.3-CONTEXT.md** — Gray areas and provider synthesis

### Tertiary (LOW confidence)
- **pyfakefs + sqlite3 interaction** — Not empirically verified in this codebase; based on pyfakefs documentation claiming C-level SQLite bypasses patching. Must be validated in plan 01 or 04.

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH — all libraries already in use or well-documented; pyfakefs verified via Context7
- Architecture: HIGH — patterns derived from reading actual source code and existing tests
- Pitfalls: HIGH — identified from code inspection (Database.__init__ validation, row_factory, foreign keys)
- Canon skills: MEDIUM — format confirmed from 3 existing skills; template design from CLARIFICATIONS-ANSWERED.md decisions
- pyfakefs+SQLite: LOW — theoretical risk, needs empirical validation

**Research date:** 2026-02-18
**Valid until:** 2026-03-18 (stable domain — retroactive testing, no fast-moving dependencies)
