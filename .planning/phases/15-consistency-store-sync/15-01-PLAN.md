---
phase: 15-consistency-store-sync
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - scripts/measure_searchability_lag.py
autonomous: true

must_haves:
  truths:
    - "Import-to-searchable lag is measured for 20 fresh file uploads with targeted per-file queries"
    - "Each file's lag is measured as T_searchable - T_import where T_searchable means the file appears in top-10 search results for a content-specific query"
    - "P50, P95, and empirical max (P99/max) are computed using nearest-rank method on n=20 successful measurements"
    - "Silent failures (300s timeout) are excluded from percentiles and reported separately as failure_rate"
    - "Three timestamps recorded per file: T_import, T_listed, T_searchable"
  artifacts:
    - path: "scripts/measure_searchability_lag.py"
      provides: "Standalone lag measurement script using raw genai SDK"
      min_lines: 200
  key_links:
    - from: "scripts/measure_searchability_lag.py"
      to: "Gemini File Search API"
      via: "genai.Client -> models.generate_content with FileSearch tool"
      pattern: "models\\.generate_content"
    - from: "scripts/measure_searchability_lag.py"
      to: "data/library.db"
      via: "sqlite3 for reading untracked files and recording results"
      pattern: "sqlite3\\.connect"
---

<objective>
Build and run the import-to-searchable lag measurement for Phase 15 VLID-07.

Purpose: Empirically characterize the gap between "Gemini import API returns success" and
"the file is actually retrievable via targeted semantic search query" -- the critical gray
area between Phase 11's listing lag (P99=0.253s) and real end-user searchability.

Output:
- `scripts/measure_searchability_lag.py` -- standalone measurement script
- Lag measurement results (P50/P95/P99-max, failure_rate) in SUMMARY.md
- Per-file measurement table with T_import, T_listed, T_searchable timestamps
</objective>

<execution_context>
@/Users/david/.claude/get-shit-done/workflows/execute-plan.md
@/Users/david/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/15-consistency-store-sync/15-CONTEXT.md
@.planning/phases/15-consistency-store-sync/15-RESEARCH.md
@.planning/phases/15-consistency-store-sync/CLARIFICATIONS-ANSWERED.md
@scripts/check_stability.py
@src/objlib/search/client.py
@src/objlib/upload/client.py
@spike/phase11_spike/lag_measurement.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Build measure_searchability_lag.py script</name>
  <files>scripts/measure_searchability_lag.py</files>
  <action>
Create `scripts/measure_searchability_lag.py` -- a standalone script following the
check_stability.py pattern (raw genai SDK, keyring API key, argparse CLI, no objlib import
dependency). The script:

**Architecture (function-based, not class):**

1. **File Selection** -- `select_test_files(db_path, n=20)`:
   - Query DB: `SELECT file_path, filename, content_hash, file_size, metadata_json FROM files
     WHERE gemini_state = 'untracked' AND filename LIKE '%.txt' ORDER BY RANDOM() LIMIT 20`
   - NOTE: Using 20 FRESH untracked files (not Phase 12 corpus). The Phase 12 files are
     already indexed -- you cannot measure import-to-searchable lag on files that are already
     searchable. Research recommended fresh untracked files (1834 available). This is a
     Claude's Discretion area per CONTEXT.md.
   - Return list of dicts with file_path, filename, file_size.

2. **Query Design** -- `design_query(file_path, filename)`:
   - Read the first 1000 characters of the file at file_path.
   - Extract a distinctive phrase or concept: look for proper nouns (capitalized multi-word
     sequences), specific titles in quotes, unique philosophical terminology.
   - Craft a query string: `"What does the library contain about [extracted phrase/concept]
     from [filename without extension]?"` -- this is specific enough to identify one file.
   - Return the query string.
   - If the file cannot be read (disk not mounted), raise with clear error.

3. **Upload + Import** -- `upload_one_file(client, store_name, file_path, display_name, metadata)`:
   - Uses raw genai SDK (not GeminiFileSearchClient which needs circuit breaker/rate limiter).
   - Step 1: `client.aio.files.upload(file=file_path, config={"display_name": display_name})`
   - Step 2: Poll `client.aio.files.get(name=file.name)` until state.name == "ACTIVE" (max 300s)
   - Step 3: `client.aio.file_search_stores.import_file(file_search_store_name=store_name, file_name=file.name)`
   - Step 4: Poll `client.aio.operations.get(operation)` until done=True (max 300s)
   - Record `time.perf_counter()` at the moment the import operation reports done -- this is T_import.
   - Return (file_obj, document_name_from_operation, t_import).

4. **Listing Visibility Poll** -- `poll_until_listed(client, store_name, document_name, start_time, max_wait=300)`:
   - Poll `client.aio.file_search_stores.documents.get(name=document_name)` at backoff
     intervals: 1s -> 2s -> 4s -> 8s -> 16s -> 30s (cap).
   - Return T_listed (perf_counter value when get() succeeds) or None on timeout.
   - Phase 11 proved this should be near-instant (~0.25s) so this is supplementary data.

5. **Searchability Poll** -- `poll_until_searchable(client, store_resource_name, query, target_filename, target_file_id_suffix, start_time, max_wait=300)`:
   - This is the PRIMARY measurement. Use `client.models.generate_content()` with FileSearch
     tool (same code path as end-user CLI search, same as check_stability.py Assertion 5):
     ```python
     response = client.models.generate_content(
         model="gemini-2.5-flash",
         contents=query,
         config=genai_types.GenerateContentConfig(
             tools=[genai_types.Tool(
                 file_search=genai_types.FileSearch(
                     file_search_store_names=[store_resource_name]
                 )
             )]
         ),
     )
     ```
   - Extract citations from `response.candidates[0].grounding_metadata.grounding_chunks`.
   - Check top-10 chunks: match `retrieved_context.title` against BOTH target_filename AND
     target_file_id_suffix (Phase 11 finding: Document.display_name = file resource ID, not
     submitted display_name).
   - Poll with backoff: 1s -> 2s -> 4s -> 8s -> 16s -> 30s (cap). Hard timeout: 300s.
   - Return T_searchable (perf_counter value when found) or None on timeout.
   - CRITICAL: This uses the SYNCHRONOUS client.models.generate_content (not async) -- same as
     check_stability.py. The search API is synchronous in the genai SDK.

6. **Percentile Computation** -- `compute_percentiles_nearest_rank(latencies)`:
   - Nearest-rank method: `sorted_data[math.ceil(p/100 * n) - 1]`
   - For n=20: P50 = sorted[9], P95 = sorted[18], P99/max = sorted[19] = max
   - DO NOT use `statistics.quantiles()` (it interpolates -- see Pitfall 6 in RESEARCH.md).
   - Return dict: {n, p50, p95, p99_max, min, max, mean}.

7. **DB State Update** -- After each file is measured, update the DB:
   - `UPDATE files SET gemini_state = 'indexed', gemini_file_id = ?, gemini_store_doc_id = ?,
     gemini_state_updated_at = ?, version = version + 1 WHERE file_path = ?`
   - This ensures the 20 newly uploaded files are tracked correctly in the DB for
     check_stability.py and store-sync consistency.

8. **Main Measurement Loop** -- `async def run_measurement(args)`:
   - Resolve store (list stores, find by display_name).
   - Select 20 files. Design per-file queries.
   - **Pre-validation pass**: For files that are already indexed (from a prior run, unlikely
     but possible), skip them and select replacements.
   - Sequential loop (one file at a time per locked decision):
     a. Upload + import file N -> record T_import
     b. Start polling for T_listed (documents.get) and T_searchable (search query) concurrently
     c. Record results: {filename, query, t_import, t_listed, t_searchable, timed_out}
     d. Update DB state
   - After all 20 files: compute percentiles on successful T_searchable values.
   - Report failure_rate = count(timed_out) / 20.

9. **Output**:
   - Print formatted results table (Rich-style terminal output like check_stability.py).
   - Save JSON results to `results/lag-measurement-{timestamp}.json`.
   - Print summary: P50, P95, P99/max, failure_rate, total_time.

**CLI interface (argparse, same pattern as check_stability.py):**
- `--store` (default: "objectivism-library")
- `--db` (default: "data/library.db")
- `--n` (default: 20, number of files to test)
- `--timeout` (default: 300, per-file search timeout)
- `--verbose` / `-v`
- `--dry-run` (select files and design queries but don't upload)
- `--output-dir` (default: "results")

**Key implementation notes:**
- Use `time.perf_counter()` for all timing (high-resolution monotonic clock).
- The store_resource_name (e.g. "fileSearchStores/abc123") is needed for search queries.
  Resolve from display_name using the same pattern as check_stability.py.
- Handle the disk-not-mounted case: if file_path points to /Volumes/U32 Shadow/... and the
  disk is unmounted, raise immediately with a clear error.
- The script uploads files using the raw genai SDK (not the objlib upload pipeline). This
  is intentional -- we're measuring Gemini's indexing behavior, not our pipeline's overhead.
  But we DO update the DB afterward so check_stability.py and store-sync see consistent state.
- Ensure results/ directory exists (create if not).
  </action>
  <verify>
Run `python scripts/measure_searchability_lag.py --dry-run --verbose` to verify:
- Script loads, resolves store, selects 20 untracked .txt files
- Per-file queries are designed and printed
- No uploads happen in dry-run mode
- Exit code 0

Then verify syntax: `python -c "import py_compile; py_compile.compile('scripts/measure_searchability_lag.py', doraise=True)"`
  </verify>
  <done>
`scripts/measure_searchability_lag.py` exists, passes syntax check, and `--dry-run` mode
successfully selects 20 files, designs per-file queries, and resolves the store without error.
  </done>
</task>

<task type="auto">
  <name>Task 2: Execute the full 20-file lag measurement and produce SUMMARY</name>
  <files>scripts/measure_searchability_lag.py</files>
  <action>
Run the full measurement and produce the Phase 15 Plan 01 SUMMARY.

**Step 1: Pre-validation**
Run `python scripts/measure_searchability_lag.py --dry-run --verbose` and review the 20
selected files and their queries. Verify:
- All 20 files are .txt files with gemini_state='untracked'
- Queries reference unique content from each file
- The external drive is mounted (files are accessible)

**Step 2: Execute the full measurement**
Run: `python scripts/measure_searchability_lag.py --store objectivism-library --verbose`

This will sequentially upload 20 files, measure T_import/T_listed/T_searchable for each,
and compute percentile statistics. Expected runtime: 5-30 minutes depending on Gemini
indexing speed.

Monitor for:
- 429 rate limit errors (if seen, the backoff should handle them)
- Timeouts (300s per file max)
- Query match failures (file found but not in top-10 -- may need query adjustment)

**Step 3: If any query fails pre-validation or measurement**
- Review the query and adjust: use a more specific phrase from the file content
- Re-run for just that file if needed (the script should be idempotent for already-uploaded files)

**Step 4: Run store-sync to verify no orphans created**
After the measurement completes:
```bash
python -m objlib store-sync --store objectivism-library
```
Verify the count is consistent (50 original + 20 newly uploaded = 70 indexed, 0 orphans).

**Step 5: Run check_stability.py to verify overall system health**
```bash
python scripts/check_stability.py --store objectivism-library --verbose
```
Should report STABLE with 70 indexed files (50 + 20 new).

**Step 6: Produce SUMMARY.md**
Create `.planning/phases/15-consistency-store-sync/15-01-SUMMARY.md` with:
- Raw JSON results (copy from results/lag-measurement-*.json)
- Per-file table: filename | query | T_listed (s) | T_searchable (s) | timed_out
- Percentile summary: P50, P95, P99/max (nearest-rank on successful measurements)
- Failure rate: N/20 files that timed out at 300s
- Listing gap analysis: T_listed vs T_searchable comparison
- Total files now indexed: should be 70
- check_stability.py and store-sync output (verbatim)
- Any anomalies observed during measurement

**Step 7: If the measurement reveals problems**
- If failure_rate > 0: document which files failed and any patterns (file size, content type)
- If P95 > 60s: note this as significant for the store-sync role decision in Plan 15-02
- These findings feed directly into Plan 15-02's contract decisions
  </action>
  <verify>
1. Results JSON file exists in `results/lag-measurement-*.json`
2. SUMMARY.md exists at `.planning/phases/15-consistency-store-sync/15-01-SUMMARY.md`
3. SUMMARY contains: P50, P95, P99/max values; per-file table; failure_rate; store-sync output
4. `python scripts/check_stability.py --store objectivism-library` exits 0 (STABLE)
5. DB shows 70 indexed files: `sqlite3 data/library.db "SELECT COUNT(*) FROM files WHERE gemini_state='indexed'"`
  </verify>
  <done>
20-file lag measurement complete. Percentile statistics (P50/P95/P99-max) computed with
nearest-rank method. Failure rate documented. SUMMARY.md contains verbatim results, per-file
table, and check_stability.py output confirming STABLE at T=0 after measurement.
  </done>
</task>

</tasks>

<verification>
Phase 15 Plan 01 verification checklist:
1. `scripts/measure_searchability_lag.py` exists and is executable
2. Script uses targeted per-file queries against specific file content (NOT check_stability.py default query)
3. Script uses `client.models.generate_content()` with FileSearch tool (same code path as CLI search)
4. Script matches search results by BOTH filename AND file_id suffix (Phase 11 finding)
5. Percentiles computed using nearest-rank (NOT statistics.quantiles interpolation)
6. Silent failures (300s timeout) excluded from percentiles, reported as failure_rate
7. Results JSON saved to results/ directory
8. DB updated with gemini_state='indexed' for the 20 newly uploaded files
9. check_stability.py reports STABLE after measurement
10. store-sync shows 0 orphans after measurement
</verification>

<success_criteria>
- Import-to-searchable lag characterized with P50/P95/P99-max from n=20 successful measurements
- Three timestamps per file: T_import, T_listed, T_searchable all recorded
- Failure rate (files that never became searchable within 300s) reported
- System remains STABLE (check_stability.py exit 0) after adding 20 files
- SUMMARY.md with all raw data for Plan 15-02 to consume
</success_criteria>

<output>
After completion, create `.planning/phases/15-consistency-store-sync/15-01-SUMMARY.md`
</output>
