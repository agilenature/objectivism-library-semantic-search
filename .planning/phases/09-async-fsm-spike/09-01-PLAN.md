---
phase: 09-async-fsm-spike
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - spike/phase9_spike/__init__.py
  - spike/phase9_spike/protocol.py
  - spike/phase9_spike/states.py
  - spike/phase9_spike/db.py
  - spike/phase9_spike/exceptions.py
  - spike/phase9_spike/event_log.py
  - spike/phase9_spike/adapters/__init__.py
  - spike/phase9_spike/adapters/statemachine_adapter.py
  - spike/phase9_spike/adapters/handrolled_adapter.py
  - spike/phase9_spike/tests/__init__.py
  - spike/phase9_spike/tests/conftest.py
  - spike/phase9_spike/tests/test_async_guards.py
  - spike/phase9_spike/tests/test_concurrent_transitions.py
  - spike/phase9_spike/tests/test_error_injection.py
  - spike/phase9_spike/tests/test_db_invariants.py
  - spike/phase9_spike/tests/test_leak_check.py
  - spike/phase9_spike/harness.py
autonomous: true

must_haves:
  truths:
    - "The chosen FSM approach runs concurrent async transitions inside asyncio.run() with aiosqlite DB writes in each callback, producing no event loop conflicts, no thread leakage, and no connection-sharing violations"
    - "10 concurrent transition attempts on the same file produce exactly 1 success and 9 rejections, verified by structured JSON event log and DB state"
    - "Error injection at 3 points (pre-commit, post-commit, guard) each produce the correct recovery outcome: pre-commit leaves state unchanged, post-commit marks state as failed, guard error leaves state unchanged"
    - "DB invariants hold after every test run: all gemini_state values are in the valid enum, version columns are non-negative, no illegal state edges exist"
    - "Thread and task counts return to baseline after all concurrent transitions complete (no leaked aiosqlite threads or orphaned asyncio tasks)"
    - "A structured JSON event log is emitted for every transition attempt with attempt_id, file_id, from_state, to_state, guard_result, and outcome fields"
  artifacts:
    - path: "spike/phase9_spike/protocol.py"
      provides: "FileStateMachineProtocol interface that both adapters implement"
      contains: "FileStateMachineProtocol"
    - path: "spike/phase9_spike/adapters/statemachine_adapter.py"
      provides: "python-statemachine adapter implementing FileStateMachineProtocol"
      contains: "StateMachineAdapter"
    - path: "spike/phase9_spike/db.py"
      provides: "Per-transition aiosqlite connection factory with OCC, BEGIN IMMEDIATE, and retry"
      contains: "execute_with_retry"
    - path: "spike/phase9_spike/tests/test_async_guards.py"
      provides: "Binary pass/fail test for async guards with DB query"
      min_lines: 30
    - path: "spike/phase9_spike/tests/test_concurrent_transitions.py"
      provides: "10-concurrent same-file adversarial test"
      min_lines: 50
    - path: "spike/phase9_spike/tests/test_error_injection.py"
      provides: "3 error injection scenarios with state verification"
      min_lines: 60
    - path: "spike/phase9_spike/harness.py"
      provides: "Combined adversarial test runner producing all 4 affirmative evidence artifacts"
      min_lines: 80
  key_links:
    - from: "spike/phase9_spike/adapters/statemachine_adapter.py"
      to: "spike/phase9_spike/protocol.py"
      via: "implements FileStateMachineProtocol"
      pattern: "FileStateMachineProtocol"
    - from: "spike/phase9_spike/adapters/statemachine_adapter.py"
      to: "spike/phase9_spike/db.py"
      via: "per-transition connection factory for state writes"
      pattern: "execute_with_retry"
    - from: "spike/phase9_spike/tests/test_concurrent_transitions.py"
      to: "spike/phase9_spike/event_log.py"
      via: "emits and validates JSON event log for each attempt"
      pattern: "emit_event"
    - from: "spike/phase9_spike/harness.py"
      to: "spike/phase9_spike/tests/"
      via: "combines all test suites into single adversarial run"
      pattern: "check_db_invariants"
---

<objective>
Build the complete spike infrastructure and run adversarial concurrent async tests against `python-statemachine` 2.6.0 to produce affirmative evidence of correct FSM behavior under concurrent load with aiosqlite DB writes. If python-statemachine fails the async guard binary test, pivot immediately to a hand-rolled adapter.

Purpose: Phase 9's gate is BLOCKING for Phase 10. The spike must produce positive evidence -- not absence of failure -- that the chosen FSM approach handles concurrent async transitions correctly. This plan covers the full spike implementation and all adversarial testing.

Output: Complete spike directory with Protocol, adapter(s), DB layer, event log, and 5 test suites plus a combined harness. All 4 affirmative evidence criteria (DB invariants, JSON event log, thread/task leak check, same-file adversarial test) are exercised and produce verifiable artifacts.
</objective>

<execution_context>
@/Users/david/.claude/get-shit-done/workflows/execute-plan.md
@/Users/david/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-async-fsm-spike/09-CONTEXT.md
@.planning/phases/09-async-fsm-spike/09-RESEARCH.md
@.planning/phases/09-async-fsm-spike/CLARIFICATIONS-ANSWERED.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Scaffold spike infrastructure -- Protocol, DB layer, exceptions, event log, and async guard binary test</name>
  <files>
    spike/phase9_spike/__init__.py
    spike/phase9_spike/protocol.py
    spike/phase9_spike/states.py
    spike/phase9_spike/db.py
    spike/phase9_spike/exceptions.py
    spike/phase9_spike/event_log.py
    spike/phase9_spike/adapters/__init__.py
    spike/phase9_spike/tests/__init__.py
    spike/phase9_spike/tests/conftest.py
    spike/phase9_spike/tests/test_async_guards.py
  </files>
  <action>
**CRITICAL: The async guard binary test MUST be the first thing that runs. It is the fastest disqualification check for python-statemachine. If it fails, skip all other library work and go straight to hand-rolled.**

Install python-statemachine:
```bash
pip install python-statemachine==2.6.0
```

Create the spike directory structure under the project root `spike/phase9_spike/`.

**1. `protocol.py` -- FileStateMachineProtocol (BEFORE any adapter):**
```python
from typing import Protocol, runtime_checkable

@runtime_checkable
class FileStateMachineProtocol(Protocol):
    @property
    def current_state(self) -> str: ...
    async def trigger(self, event: str, **kwargs) -> None: ...
    async def can_trigger(self, event: str, **kwargs) -> bool: ...
```

Per locked decision #8: this Protocol is defined BEFORE the library trial so that a pivot to hand-rolled does not require rewriting test harness code.

**2. `states.py` -- State and transition constants:**

Define the valid states as a string enum or frozenset:
```python
VALID_STATES = frozenset({"untracked", "uploading", "processing", "indexed", "failed"})
VALID_EDGES = frozenset({
    ("untracked", "uploading"),
    ("uploading", "processing"),
    ("processing", "indexed"),
    ("uploading", "failed"),
    ("processing", "failed"),
})
```

Also define event names mapping to transitions: `start_upload`, `complete_upload`, `complete_processing`, `fail_upload`, `fail_processing`.

**3. `exceptions.py`:**

Define three exception types:
- `StaleTransitionError(Exception)` -- OCC version conflict
- `GuardRejectedError(Exception)` -- guard returned False
- `TransitionNotAllowedError(Exception)` -- invalid event for current state

**4. `db.py` -- Per-transition connection factory + OCC:**

Implement `execute_with_retry(db_path, sql, params, max_retries=3, initial_delay=0.05, multiplier=2.0) -> int` per the RESEARCH.md pattern. Key requirements:
- Uses `async with aiosqlite.connect(db_path)` (new connection per call -- locked decision #9)
- Sets `PRAGMA journal_mode=WAL`, `PRAGMA synchronous=NORMAL`, `PRAGMA foreign_keys=ON` on every connection
- Uses `BEGIN IMMEDIATE` before every write (locked decision #7)
- Catches `sqlite3.OperationalError` with "database is locked" for retry (locked decision #10: 3 attempts, 50ms initial, 2x multiplier)
- Returns cursor.rowcount

Also implement:
- `init_spike_db(db_path) -> None` -- creates the spike schema (files table with file_path TEXT PK, gemini_state TEXT DEFAULT 'untracked', gemini_state_updated_at TEXT, version INTEGER DEFAULT 0, last_error TEXT, failure_info TEXT) + index on gemini_state. Sets WAL mode.
- `read_file_state(db_path, file_id) -> tuple[str, int]` -- reads (gemini_state, version) from DB. Returns the DB state, which is the sole source of truth (locked decision #5).

**5. `event_log.py` -- Structured JSON log emitter:**

Implement `emit_event(file_id, from_state, to_state, event, outcome, guard_result=None, error=None) -> dict` per RESEARCH.md Pattern 6. Also implement a `EventCollector` class that stores events in a list (for test assertions) instead of only printing to stdout.

**6. `tests/conftest.py` -- Spike-specific fixtures:**

- `spike_db` fixture: creates a temp DB file (use `tmp_path`), calls `init_spike_db`, yields the path, cleanup is automatic.
- `seed_file` fixture factory: inserts a file row with given file_path and initial state.
- `event_collector` fixture: returns a fresh `EventCollector` instance.

**7. `tests/test_async_guards.py` -- BINARY PASS/FAIL for python-statemachine async guards:**

This is THE critical test. It must run first and determine whether we proceed with the library or pivot.

Define a minimal python-statemachine `StateMachine` subclass with:
- States: `untracked = State("untracked", initial=True, value="untracked")`, `uploading = State("uploading", value="uploading")`
- One transition: `start_upload = untracked.to(uploading, cond="cond_not_stale")`
- One async guard: `async def cond_not_stale(self, file_id, db_path, expected_version) -> bool` that does `async with aiosqlite.connect(db_path)` and checks the version column.

Test cases:
a. `test_async_guard_is_awaited` -- Create FSM, trigger `start_upload` with correct version. Assert: transition succeeds, DB state is "uploading". This proves the library awaits the async guard.
b. `test_async_guard_rejects` -- Create FSM, trigger `start_upload` with wrong version. Assert: transition is rejected (guard returns False), DB state remains "untracked".
c. `test_start_value_string` -- Create FSM with `start_value="uploading"`. Assert: `sm.current_state_value == "uploading"`. This tests the LOW confidence `start_value` question from RESEARCH.md.

**PIVOT LOGIC (implement in the test file):**
If `test_async_guard_is_awaited` FAILS (the library calls the guard synchronously, gets a coroutine object instead of a bool, or raises RuntimeError), print a clear message: "PIVOT REQUIRED: python-statemachine does not await async guards. Switching to hand-rolled adapter." In this case, Task 2 implements the hand-rolled adapter instead of the statemachine adapter.

Run:
```bash
cd /Users/david/projects/objectivism-library-semantic-search
python -m pytest spike/phase9_spike/tests/test_async_guards.py -v --tb=long 2>&1
```

The result of this test determines Task 2's path.
  </action>
  <verify>
1. `python -m pytest spike/phase9_spike/tests/test_async_guards.py -v --tb=long` -- all 3 tests pass (library path) OR the pivot message is printed (hand-rolled path)
2. `python -c "from spike.phase9_spike.protocol import FileStateMachineProtocol; print('Protocol OK')"` -- imports successfully
3. `python -c "from spike.phase9_spike.db import init_spike_db, execute_with_retry; print('DB OK')"` -- imports successfully
4. `python -c "from spike.phase9_spike.exceptions import StaleTransitionError, GuardRejectedError; print('Exceptions OK')"` -- imports successfully
5. `python -c "from spike.phase9_spike.event_log import EventCollector; print('EventLog OK')"` -- imports successfully
  </verify>
  <done>
All spike infrastructure modules import cleanly. The async guard binary test has run and produced a definitive PASS (proceed with python-statemachine) or FAIL (pivot to hand-rolled). The Protocol is defined and ready for either adapter path. The DB layer creates spike DBs with WAL mode, BEGIN IMMEDIATE, and OCC support.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement FSM adapter (library or hand-rolled based on Task 1 result) and full adversarial test harness</name>
  <files>
    spike/phase9_spike/adapters/statemachine_adapter.py
    spike/phase9_spike/adapters/handrolled_adapter.py
    spike/phase9_spike/tests/test_concurrent_transitions.py
    spike/phase9_spike/tests/test_error_injection.py
    spike/phase9_spike/tests/test_db_invariants.py
    spike/phase9_spike/tests/test_leak_check.py
    spike/phase9_spike/harness.py
  </files>
  <action>
**Path determination:** Check the result of Task 1's `test_async_guards.py`. If all 3 tests passed, implement the `statemachine_adapter.py`. If any failed with the pivot message, implement `handrolled_adapter.py` instead. Both MUST satisfy `FileStateMachineProtocol`.

**IF python-statemachine PASSED (primary path) -- `statemachine_adapter.py`:**

Create a `StateMachineAdapter` class that wraps `python-statemachine`'s `StateMachine` and satisfies `FileStateMachineProtocol`. Implementation:

1. Define `FileLifecycleSM(StateMachine)` with:
   - States: `untracked`, `uploading`, `processing`, `indexed` (final), `failed` -- each with explicit `value="statename"` string parameters
   - Transitions: `start_upload` (untracked->uploading), `complete_upload` (uploading->processing), `complete_processing` (processing->indexed), `fail_upload` (uploading->failed), `fail_processing` (processing->failed)
   - Async guard on `start_upload`: `cond="cond_not_stale"` -- checks DB version via per-transition aiosqlite connection
   - Async `on_enter_state` callback: writes new state to DB via `execute_with_retry` using the OCC UPDATE pattern (`UPDATE files SET gemini_state=?, version=version+1, gemini_state_updated_at=? WHERE file_path=? AND gemini_state=? AND version=?`). If rowcount==0, raise `StaleTransitionError`.

2. `StateMachineAdapter` wraps `FileLifecycleSM`:
   - Constructor: `__init__(self, file_id: str, db_path: str, initial_state: str, initial_version: int, event_collector: EventCollector | None = None)`
   - `current_state` property: reads from the internal SM's `current_state_value`
   - `async trigger(event, **kwargs)`: calls `await sm.activate_initial_state()` if not yet activated, then `await sm.send(event, file_id=file_id, db_path=db_path, expected_version=initial_version, **kwargs)`. Wraps in try/except to emit event log entries for success/rejection/failure.
   - `async can_trigger(event, **kwargs)`: checks if the event is valid for current state

3. Key detail for ephemeral lifecycle (locked decision #6): Each adapter instance is created from DB state, used for ONE transition, then discarded. The adapter re-reads version from DB at creation time. This prevents stale in-memory state.

**IF python-statemachine FAILED (fallback path) -- `handrolled_adapter.py`:**

Create a `HandRolledAdapter` class that satisfies `FileStateMachineProtocol` WITHOUT any library dependency:

1. Define allowed transitions as a dict: `TRANSITIONS = {"start_upload": ("untracked", "uploading"), "complete_upload": ("uploading", "processing"), ...}`
2. Constructor: same signature as StateMachineAdapter
3. `async trigger(event, **kwargs)`:
   - Look up `(from_state, to_state)` from TRANSITIONS
   - If current_state != from_state, raise `TransitionNotAllowedError`
   - Run guard (async): read DB version, check match -> `GuardRejectedError` if mismatch
   - Execute OCC UPDATE via `execute_with_retry`
   - If rowcount==0, raise `StaleTransitionError`
   - Emit event log entry
4. `async can_trigger(event, **kwargs)`: check if transition is valid for current state

**Regardless of path, implement ALL of the following test suites:**

**`tests/test_concurrent_transitions.py`:**

Test the 10-concurrent same-file adversarial scenario (locked decision #2, adversarial same-file test):
- Seed one file as "untracked" with version=0
- Create a `FileLockManager` (per-file asyncio.Lock, locked decision #3)
- Launch 10 concurrent coroutines via `asyncio.gather`, each attempting `start_upload` on the same file
- Each coroutine: acquire per-file lock, read DB state, create ephemeral adapter, attempt trigger
- Assert: exactly 1 success outcome and 9 rejection outcomes in the event collector
- Assert: DB shows gemini_state="uploading" and version=1
- Assert: event log contains 10 entries, 1 with outcome="success" and 9 with outcome="rejected"

Also test 10 concurrent transitions on 10 DIFFERENT files (all should succeed):
- Seed 10 files as "untracked"
- Launch 10 concurrent coroutines, each transitioning a different file
- Assert: all 10 succeed, DB shows all 10 as "uploading" with version=1

**`tests/test_error_injection.py`:**

Three required scenarios (locked decision #4):

a. **Pre-commit error** -- Inject exception BEFORE `db.commit()` is reached:
   - Monkey-patch or use a callback hook that raises before the commit
   - Assert: DB state remains "untracked", version=0 (rollback semantics)
   - Assert: event log shows outcome="failed" with the error message

b. **Post-commit error** -- Inject exception AFTER `db.commit()` succeeds but during a subsequent callback:
   - Let the OCC UPDATE succeed and commit, then raise in an after-transition callback
   - Assert: DB state IS advanced (the commit happened), but failure_info or last_error is populated
   - Assert: event log shows outcome="failed" with the error, but DB state reflects the committed transition

c. **Guard error** -- Inject exception DURING guard evaluation (guard raises instead of returning bool):
   - Monkey-patch the guard to raise RuntimeError
   - Assert: DB state remains "untracked", version=0
   - Assert: event log shows outcome="failed"

For the adapter in use (library or hand-rolled), adapt the injection technique appropriately. If using python-statemachine, test what happens when `on_enter_state` raises -- does the library propagate the exception? Does it roll back internal state? Document the observed behavior.

**`tests/test_db_invariants.py`:**

Implement `check_db_invariants(db_path) -> list[str]` as a reusable function (from RESEARCH.md Example 5):
- Check all gemini_state values are in VALID_STATES
- Check all version values are non-negative
- Return list of violation strings (empty = pass)

Test cases:
- After seeding + valid transitions: invariants pass (empty violations list)
- After inserting a row with invalid state: invariants fail (1 violation)
- After the concurrent transition test: invariants pass

**`tests/test_leak_check.py`:**

Implement thread/task leak detection (locked decision #2, point 3):
- Record `threading.active_count()` and `len(asyncio.all_tasks())` before running a batch of transitions
- Run 10 concurrent transitions (mix of same-file and different-file)
- Wait 0.1s for settle
- Record counts again
- Assert: `thread_after <= thread_baseline + 1` (the +1 is tolerance for the test runner itself)
- Assert: `task_after <= task_baseline`

**`harness.py` -- Combined adversarial test runner:**

Create a standalone script that runs ALL checks in sequence and produces a combined report:
1. Initialize spike DB at `/tmp/phase9_spike.db`
2. Seed 11 test files (10 unique + 1 for same-file contention)
3. Record thread/task baseline
4. Run concurrent transitions (10 different files + 10 same-file attempts)
5. Collect JSON event log from EventCollector
6. Run DB invariant checker
7. Record thread/task post-counts
8. Print structured results:
   - Event log summary (total attempts, successes, rejections, failures)
   - DB invariant check result (PASS/FAIL + violations)
   - Thread leak check (before/after counts, PASS/FAIL)
   - Task leak check (before/after counts, PASS/FAIL)
   - Same-file contention result (1 success, 9 rejections: PASS/FAIL)
   - Overall: ALL CHECKS PASSED or FAILURES DETECTED
9. Clean up: delete `/tmp/phase9_spike.db`

The harness should be runnable as `python -m spike.phase9_spike.harness` from the project root.

Run all tests:
```bash
cd /Users/david/projects/objectivism-library-semantic-search
python -m pytest spike/phase9_spike/tests/ -v --tb=long
python -m spike.phase9_spike.harness
```
  </action>
  <verify>
1. `python -m pytest spike/phase9_spike/tests/ -v --tb=long` -- all tests pass
2. `python -m spike.phase9_spike.harness` -- prints "ALL CHECKS PASSED" (or documents specific failures with evidence)
3. Verify the JSON event log output contains entries with all required fields: attempt_id, file_id, from_state, to_state, guard_result, outcome
4. Verify the concurrent same-file test: exactly 1 success and 9 rejections in the event log
5. Verify error injection results: pre-commit leaves state unchanged, post-commit advances state, guard error leaves state unchanged
6. Verify DB invariant check: 0 violations after all test runs
7. Verify thread/task leak check: counts return to baseline (within tolerance)
8. `/tmp/phase9_spike.db` does not exist after harness completes (cleaned up)
  </verify>
  <done>
The chosen FSM adapter (python-statemachine or hand-rolled) satisfies FileStateMachineProtocol and passes all adversarial tests. The 4 affirmative evidence criteria are all demonstrated:
(1) DB invariants hold -- all states valid, versions non-negative, no illegal edges
(2) Structured JSON event log -- every attempt has attempt_id, file_id, from_state, to_state, guard_result, outcome
(3) Thread/task leak check -- counts return to baseline after concurrent transitions
(4) Same-file adversarial test -- exactly 1 success, 9 rejections under 10 concurrent attempts
The harness produces a combined report documenting all evidence.
  </done>
</task>

</tasks>

<verification>
1. `python -m pytest spike/phase9_spike/tests/test_async_guards.py -v` -- async guard binary test passes (determines library vs hand-rolled)
2. `python -m pytest spike/phase9_spike/tests/ -v --tb=long` -- ALL spike tests pass
3. `python -m spike.phase9_spike.harness` -- combined harness prints "ALL CHECKS PASSED"
4. JSON event log contains entries for all transition attempts with required fields
5. Same-file contention: exactly 1 success, 9 rejections
6. Error injection: 3 scenarios produce correct recovery outcomes
7. DB invariants: 0 violations after all tests
8. Thread/task leak: counts at or below baseline after concurrent batch
9. `FileStateMachineProtocol` is satisfied by the chosen adapter (verified by `isinstance` check)
10. Spike DB is isolated at `/tmp/phase9_spike.db` -- never touches production `data/library.db`
</verification>

<success_criteria>
- The async guard binary test produces a definitive PASS or FAIL for python-statemachine
- The chosen adapter satisfies FileStateMachineProtocol
- All 4 affirmative evidence criteria are demonstrated with verifiable artifacts
- 10 concurrent same-file attempts produce exactly 1 success and 9 rejections
- Error injection at 3 points produces correct recovery outcomes
- DB invariants hold after every test run
- Thread/task counts return to baseline
- The combined harness produces a single "ALL CHECKS PASSED" result
</success_criteria>

<output>
After completion, create `.planning/phases/09-async-fsm-spike/09-01-SUMMARY.md`
</output>
