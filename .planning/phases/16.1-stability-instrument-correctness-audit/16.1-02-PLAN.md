---
phase: 16.1-stability-instrument-correctness-audit
plan: 02
type: execute
wave: 2
depends_on: ["16.1-01"]
files_modified:
  - scripts/check_stability.py
  - src/objlib/database.py
  - src/objlib/search/citations.py
autonomous: true

must_haves:
  truths:
    - "A6 resolves all citations via SUBSTR-based store_doc_id prefix lookup -- 0 unresolved citations for files with gemini_file_id=NULL"
    - "A7 excludes Episode files from sampling and logs the exclusion count (333)"
    - "A7 query construction uses topic metadata via fallback chain: display_title -> title -> topic -> stem"
    - "A7 matching uses exact prefix comparison (== split('-')[0]), not substring 'in' operator"
    - "A7 tolerance is 0 (max_misses = 0) -- no tolerance formula"
    - "database.py has new get_file_metadata_by_store_doc_prefix() method using SUBSTR-IN query"
    - "citations.py enrich_citations() adds store_doc_prefix lookup BEFORE gemini_file_id lookup"
    - "All existing tests pass (python -m pytest tests/ -x -q)"
    - "check_stability.py exits 0 with all 7 assertions PASS on initial run"
  artifacts:
    - path: "scripts/check_stability.py"
      provides: "Fixed A6 (SUBSTR lookup) + A7 (Episode exclusion, topic query, exact matching, zero tolerance)"
      contains: "SUBSTR(gemini_store_doc_id"
    - path: "src/objlib/database.py"
      provides: "New get_file_metadata_by_store_doc_prefix() method"
      contains: "get_file_metadata_by_store_doc_prefix"
    - path: "src/objlib/search/citations.py"
      provides: "Store doc prefix lookup pass in enrich_citations()"
      contains: "store_doc_prefix"
  key_links:
    - from: "scripts/check_stability.py"
      to: "data/library.db"
      via: "A6: SUBSTR(gemini_store_doc_id, 1, INSTR(gemini_store_doc_id, '-') - 1) = ?"
      pattern: "SUBSTR.*gemini_store_doc_id.*INSTR"
    - from: "scripts/check_stability.py"
      to: "data/library.db"
      via: "A7: SELECT ... WHERE filename NOT LIKE 'Episode %' ORDER BY RANDOM()"
      pattern: "NOT LIKE 'Episode %'"
    - from: "src/objlib/search/citations.py"
      to: "src/objlib/database.py"
      via: "enrich_citations calls get_file_metadata_by_store_doc_prefix for unresolved IDs"
      pattern: "get_file_metadata_by_store_doc_prefix"
---

<objective>
Implement all fixes to check_stability.py A6 and A7, plus the production citation resolution pipeline (database.py + citations.py). Zero tolerance. Exact-match semantics. No LIKE in any new DB lookup.

Purpose: Transform the stability instrument from one that produces false negatives at full corpus scale into one that correctly verifies all 1,749 files. Also fix the production citation pipeline so TUI search never shows "[Unresolved file #N]" for the 1,075 files with NULL gemini_file_id.

Output: Three modified files. check_stability.py exits 0 on first run. All existing tests pass.
</objective>

<execution_context>
@/Users/david/.claude/get-shit-done/workflows/execute-plan.md
@/Users/david/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/16.1-stability-instrument-correctness-audit/16.1-RESEARCH.md
@.planning/phases/16.1-stability-instrument-correctness-audit/SPIKE-EVIDENCE.md
@scripts/check_stability.py
@src/objlib/database.py
@src/objlib/search/citations.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Fix check_stability.py A6 and A7</name>
  <files>scripts/check_stability.py</files>
  <action>
Read `scripts/check_stability.py` in full before making any changes. Apply all 5 fixes to the file. Reference SPIKE-EVIDENCE.md for exact line numbers confirmed in Plan 01.

**Fix 1: A6 -- SUBSTR-based store_doc_id prefix lookup (in `_check_citation_resolution`)**

Replace the current lookup query (approximately line 417-420):
```python
row = conn.execute(
    "SELECT filename FROM files WHERE gemini_store_doc_id = ? OR gemini_file_id = ?",
    (title, f"files/{title}"),
).fetchone()
```

With SUBSTR-based exact-match lookup:
```python
row = conn.execute(
    "SELECT filename FROM files "
    "WHERE SUBSTR(gemini_store_doc_id, 1, INSTR(gemini_store_doc_id, '-') - 1) = ? "
    "OR gemini_file_id = ?",
    (title, f"files/{title}"),
).fetchone()
```

This changes the store_doc_id match from full-value equality (`gemini_store_doc_id = ?`) to prefix extraction + equality (`SUBSTR(...) = ?`). The gemini_file_id fallback is preserved for the 673 files where it is non-NULL.

NO `LIKE` operator. The SUBSTR expression is an exact-match against a computed prefix.

**Fix 2: A7 sampling -- exclude Episode files (in `_check_targeted_searchability`)**

Replace the sampling query (approximately line 479-487):
```python
rows = conn.execute(
    """SELECT filename, gemini_store_doc_id, gemini_file_id, metadata_json
       FROM files
       WHERE gemini_state = 'indexed'
         AND gemini_store_doc_id IS NOT NULL
       ORDER BY RANDOM()
       LIMIT ?""",
    (sample_size,),
).fetchall()
```

With Episode-excluding query + count logging:
```python
# Count excluded Episode files for transparency
episode_count = conn.execute(
    "SELECT COUNT(*) FROM files "
    "WHERE gemini_state = 'indexed' AND filename LIKE 'Episode %'"
).fetchone()[0]
self._verbose(
    f"Assertion 7: excluding {episode_count} Episode files "
    f"(no discriminating metadata)"
)

rows = conn.execute(
    """SELECT filename, gemini_store_doc_id, gemini_file_id, metadata_json
       FROM files
       WHERE gemini_state = 'indexed'
         AND gemini_store_doc_id IS NOT NULL
         AND filename NOT LIKE 'Episode %'
       ORDER BY RANDOM()
       LIMIT ?""",
    (sample_size,),
).fetchall()
```

Note: The `LIKE 'Episode %'` is used only for the EXCLUSION filter (selecting which files to sample), NOT for ID matching. This is acceptable -- it filters by filename pattern, not by Gemini ID. The standing constraint "NO LIKE pattern matching in any DB lookup" applies to ID resolution lookups.

**Fix 3: A7 query construction -- add topic to fallback chain**

Replace the current query construction (approximately line 505-512):
```python
title = None
if metadata_json_str:
    try:
        meta = json.loads(metadata_json_str)
        title = meta.get("display_title") or meta.get("title")
    except Exception:
        pass
subject = title if title else stem
```

With topic-aware fallback chain:
```python
title = None
if metadata_json_str:
    try:
        meta = json.loads(metadata_json_str)
        title = (
            meta.get("display_title")
            or meta.get("title")
            or meta.get("topic")
        )
    except Exception:
        pass
subject = title if title else stem
```

This adds `meta.get("topic")` as the third fallback. For 994 files where topic differs from stem, this produces a more discriminating query. For 422 files where topic == stem, behavior is unchanged.

**Fix 4: A7 matching -- replace `in` with exact prefix comparison**

Replace the current matching block (approximately lines 556-567):
```python
# Primary: exact match on file resource ID
if expected_file_id and title_in_result == expected_file_id:
    found = True
    break
# Secondary: title is prefix of store_doc_id
if store_doc_id and title_in_result in store_doc_id:
    found = True
    break
# Tertiary: match by filename (if display_name changes)
if filename in title_in_result:
    found = True
    break
```

With store_doc_prefix-first exact matching:
```python
# Primary: exact match on store_doc_id prefix (covers ALL files)
store_doc_prefix = (
    store_doc_id.split('-')[0] if store_doc_id else ""
)
if store_doc_prefix and title_in_result == store_doc_prefix:
    found = True
    break
# Secondary: fallback to file resource ID (for files with known file_id)
if expected_file_id and title_in_result == expected_file_id:
    found = True
    break
# Tertiary: match by filename (unchanged safety net)
if filename in title_in_result:
    found = True
    break
```

The `store_doc_prefix` computation can be hoisted OUTSIDE the chunk loop (it depends only on `store_doc_id` which is per-file, not per-chunk). Compute it once before the `for chunk in chunks[:10]:` loop.

**Fix 5: A7 tolerance -- set to zero**

Replace (approximately line 580):
```python
max_misses = max(1, sample_size // 5)
```

With:
```python
max_misses = 0
```

Also update the pass/warn/fail logic that follows. The current code has three branches:
1. `not missed` -> PASS
2. `len(missed) <= max_misses` -> WARN + PASS (marginal)
3. `else` -> FAIL

With `max_misses = 0`, branch 2 can only fire when `len(missed) == 0`, which is already covered by branch 1. So simplify to two branches:
1. `not missed` -> PASS
2. `else` -> FAIL

Update the PASS message to note Episode exclusion:
```python
if not missed:
    self._pass(
        "Assertion 7 -- Per-file searchability",
        f"all {len(rows)}/{sample_size} sampled files retrievable "
        f"({episode_count} Episode files excluded, tolerance=0)",
    )
else:
    self._fail(
        "Assertion 7 -- Per-file searchability",
        f"{len(missed)}/{len(rows)} files not found (tolerance=0): {missed}",
    )
```

**Also update the docstring** for `_check_targeted_searchability` to reflect:
- Episode exclusion (333 files, no discriminating metadata)
- Topic metadata in query construction
- Store doc prefix matching (not file resource ID)
- Zero tolerance

**Also update the module docstring** (line 28) to note Assertion 7's updated semantics.
  </action>
  <verify>
1. Syntax check: `python -c "import py_compile; py_compile.compile('scripts/check_stability.py', doraise=True)"`
2. Verify SUBSTR in A6: `grep -n "SUBSTR.*gemini_store_doc_id" scripts/check_stability.py`
3. Verify Episode exclusion: `grep -n "NOT LIKE 'Episode'" scripts/check_stability.py`
4. Verify topic in fallback: `grep -n "meta.get.*topic" scripts/check_stability.py`
5. Verify exact prefix match: `grep -n "split.*'-'.*\[0\]" scripts/check_stability.py`
6. Verify zero tolerance: `grep -n "max_misses = 0" scripts/check_stability.py`
7. Verify no LIKE in ID lookups: `grep -n "LIKE" scripts/check_stability.py` -- only Episode exclusion pattern, not ID resolution
8. Run check_stability.py: `python scripts/check_stability.py --store objectivism-library --sample-count 20 --verbose` -- expect exit 0
9. If exit 1: examine which files failed and whether they are course files with ambiguous stems. Document.
10. Run existing tests: `python -m pytest tests/ -x -q` -- expect all pass
  </verify>
  <done>
check_stability.py A6 uses SUBSTR-based exact prefix extraction (no LIKE). A7 excludes 333 Episode files, uses topic metadata for queries, uses exact prefix comparison for matching, and enforces zero tolerance. Syntax check passes. Initial run against live store attempted (exit code documented -- if not 0, residual failures triaged in this task's output).
  </done>
</task>

<task type="auto">
  <name>Task 2: Add store_doc_prefix lookup to database.py and citations.py</name>
  <files>
    src/objlib/database.py
    src/objlib/search/citations.py
  </files>
  <action>
Read both files in full before making any changes. These changes fix the production citation pipeline so TUI search correctly resolves citations for all 1,749 files (including the 1,075 with NULL gemini_file_id).

**database.py: Add `get_file_metadata_by_store_doc_prefix()` method**

Add this method to the `Database` class, immediately after `get_file_metadata_by_gemini_ids()` (after approximately line 992):

```python
def get_file_metadata_by_store_doc_prefix(self, prefixes: list[str]) -> dict[str, dict]:
    """Return metadata for files matching store_doc_id prefix.

    When Gemini File Search returns citations, retrieved_context.title
    contains the store document's display_name, which is the 12-character
    prefix of gemini_store_doc_id (confirmed by Phase 11 spike: 13/13
    exact round-trip match).

    This lookup covers ALL indexed files (including the 1,075 with
    gemini_file_id=NULL) because gemini_store_doc_id is never NULL
    for indexed files.

    Uses SUBSTR-based exact-match extraction (no LIKE):
      SUBSTR(gemini_store_doc_id, 1, INSTR(gemini_store_doc_id, '-') - 1)

    Args:
        prefixes: List of 12-character store doc ID prefix strings.

    Returns:
        Dict mapping prefix -> {"filename": str, "file_path": str, "metadata": dict}
    """
    if not prefixes:
        return {}
    placeholders = ",".join("?" * len(prefixes))
    rows = self.conn.execute(
        f"SELECT SUBSTR(gemini_store_doc_id, 1, INSTR(gemini_store_doc_id, '-') - 1) as prefix, "
        f"filename, file_path, metadata_json FROM files "
        f"WHERE SUBSTR(gemini_store_doc_id, 1, INSTR(gemini_store_doc_id, '-') - 1) IN ({placeholders})",
        prefixes,
    ).fetchall()

    import json

    result = {}
    for row in rows:
        meta = json.loads(row["metadata_json"]) if row["metadata_json"] else {}
        result[row["prefix"]] = {
            "filename": row["filename"],
            "file_path": row["file_path"],
            "metadata": meta,
        }
    return result
```

**citations.py: Add store_doc_prefix lookup pass to `enrich_citations()`**

In the `enrich_citations()` function, add a new lookup pass BETWEEN the filename lookup (pass 1) and the gemini_file_id lookup (pass 2). The new chain is:

1. Filename lookup (existing, unchanged)
2. **Store doc prefix lookup (NEW)** -- for titles that look like 12-char alphanumeric IDs
3. Gemini file ID lookup (existing, unchanged)
4. API fallback (existing, unchanged)

Replace the current two-pass lookup section (approximately lines 165-188):

```python
titles = [c.title for c in citations if c.title]

# First pass: lookup by filename
filename_lookup = db.get_file_metadata_by_filenames(titles)

# Second pass: for unmatched titles, try Gemini ID lookup
unmatched_titles = [t for t in titles if t not in filename_lookup]
gemini_id_lookup = db.get_file_metadata_by_gemini_ids(unmatched_titles) if unmatched_titles else {}

for citation in citations:
    # Try filename lookup first
    match = filename_lookup.get(citation.title)
    if match:
        citation.file_path = match["file_path"]
        citation.metadata = match["metadata"]
    else:
        # Fall back to Gemini ID lookup
        gemini_match = gemini_id_lookup.get(citation.title)
        if gemini_match:
            # Update citation title to the actual filename
            citation.title = gemini_match["filename"]
            citation.file_path = gemini_match["file_path"]
            citation.metadata = gemini_match["metadata"]
```

With the extended chain:

```python
titles = [c.title for c in citations if c.title]

# First pass: lookup by filename
filename_lookup = db.get_file_metadata_by_filenames(titles)

# Second pass: for unmatched titles, try store doc prefix lookup
# (covers all 1,749 files including 1,075 with NULL gemini_file_id)
unmatched_after_filename = [t for t in titles if t not in filename_lookup]
store_prefix_lookup = (
    db.get_file_metadata_by_store_doc_prefix(unmatched_after_filename)
    if unmatched_after_filename
    else {}
)

# Third pass: for still-unmatched, try gemini_file_id lookup
unmatched_after_prefix = [
    t for t in unmatched_after_filename if t not in store_prefix_lookup
]
gemini_id_lookup = (
    db.get_file_metadata_by_gemini_ids(unmatched_after_prefix)
    if unmatched_after_prefix
    else {}
)

for citation in citations:
    # Try filename lookup first
    match = filename_lookup.get(citation.title)
    if match:
        citation.file_path = match["file_path"]
        citation.metadata = match["metadata"]
        continue

    # Try store doc prefix lookup
    prefix_match = store_prefix_lookup.get(citation.title)
    if prefix_match:
        citation.title = prefix_match["filename"]
        citation.file_path = prefix_match["file_path"]
        citation.metadata = prefix_match["metadata"]
        continue

    # Fall back to Gemini file ID lookup
    gemini_match = gemini_id_lookup.get(citation.title)
    if gemini_match:
        citation.title = gemini_match["filename"]
        citation.file_path = gemini_match["file_path"]
        citation.metadata = gemini_match["metadata"]
```

Also update the `enrich_citations()` docstring to document the new 4-pass chain:
1. Filename lookup
2. Store doc prefix lookup (NEW -- uses SUBSTR match against gemini_store_doc_id)
3. Gemini file ID lookup
4. API fallback (unchanged)
  </action>
  <verify>
1. Syntax check database.py: `python -c "import py_compile; py_compile.compile('src/objlib/database.py', doraise=True)"`
2. Syntax check citations.py: `python -c "import py_compile; py_compile.compile('src/objlib/search/citations.py', doraise=True)"`
3. Verify new method exists: `grep -n "get_file_metadata_by_store_doc_prefix" src/objlib/database.py`
4. Verify no LIKE in new method: `grep -A5 "get_file_metadata_by_store_doc_prefix" src/objlib/database.py | grep -c "LIKE"` returns 0
5. Verify citations.py uses new method: `grep -n "store_doc_prefix\|store_prefix_lookup" src/objlib/search/citations.py`
6. Run all tests: `python -m pytest tests/ -x -q` -- expect all pass
7. Quick integration check: `python -c "from objlib.database import Database; db = Database('data/library.db'); print(len(db.get_file_metadata_by_store_doc_prefix(['p4exrsn9zxzc'])))"`
   Expected: 1 (the file "Objectivist Logic - Class 15-02.txt" from the T+24h A6 failure)
  </verify>
  <done>
database.py has `get_file_metadata_by_store_doc_prefix()` with SUBSTR-IN query (no LIKE). citations.py `enrich_citations()` has 4-pass lookup chain with store doc prefix as pass 2. All existing tests pass. Quick integration check confirms the T+24h A6 failure citation now resolves correctly.
  </done>
</task>

</tasks>

<verification>
Plan 16.1-02 verification checklist:
1. check_stability.py A6 uses `SUBSTR(gemini_store_doc_id, 1, INSTR(gemini_store_doc_id, '-') - 1) = ?` (exact-match, no LIKE)
2. check_stability.py A7 sampling excludes Episode files with logged count
3. check_stability.py A7 query uses `display_title or title or topic` fallback chain
4. check_stability.py A7 matching uses `== store_doc_id.split('-')[0]` (exact prefix, not `in`)
5. check_stability.py A7 tolerance is `max_misses = 0`
6. database.py has `get_file_metadata_by_store_doc_prefix()` using SUBSTR-IN query
7. citations.py `enrich_citations()` calls store_doc_prefix lookup BEFORE gemini_file_id lookup
8. No LIKE in any new ID-resolution query (only Episode exclusion filter uses LIKE)
9. `python -m pytest tests/ -x -q` exits 0
10. `python scripts/check_stability.py --store objectivism-library --sample-count 20 --verbose` attempted
</verification>

<success_criteria>
- All 5 check_stability.py fixes implemented with exact-match semantics
- Production citation pipeline (database.py + citations.py) extended for store_doc_prefix lookup
- All existing tests pass (no regressions)
- check_stability.py initial run documented (exit 0 expected, residual course-file failures triaged if present)
</success_criteria>

<output>
After completion, create `.planning/phases/16.1-stability-instrument-correctness-audit/16.1-02-SUMMARY.md`
</output>
