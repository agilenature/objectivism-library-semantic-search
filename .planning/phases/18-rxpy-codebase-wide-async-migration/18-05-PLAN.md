---
phase: 18-rxpy-codebase-wide-async-migration
plan: 05
type: validate
wave: 5
depends_on: ["18-04"]
files_modified:
  - Canon.json
  - .planning/phases/18-rxpy-codebase-wide-async-migration/18-05-SUMMARY.md
autonomous: true

must_haves:
  truths:
    - "Full pytest suite passes with 0 failures across all modules"
    - "New UNTRACKED lectures (added since Phase 18 began) are uploaded through the migrated pipeline — 50 files as the validation corpus"
    - "No currently-indexed files are reset, re-uploaded, or touched during validation"
    - "New lecture uploads reach terminal state (indexed or failed) — none stuck in uploading/processing"
    - "Some FAILED states among new lectures are acceptable — RecoveryCrawler handles recovery; not a gate blocker"
    - "store-sync confirms 0 new orphaned documents after validation upload"
    - "Semantic search against the full corpus (existing + new) returns correctly-resolved citations (no [Unresolved file #N])"
    - "Phase 17 TUI behavioral invariants 1-7 still hold (TUI regression check)"
    - "Canon.json updated to index all 10 migrated modules"
    - "18-05-SUMMARY.md provides complete post-migration evidence report"
  artifacts:
    - path: "Canon.json"
      provides: "Updated Canon.json indexing all RxPY-migrated modules"
      contains: "upload/orchestrator.py, upload/client.py, upload/state.py, upload/recovery.py, extraction/batch_orchestrator.py, extraction/orchestrator.py, services/search.py, services/library.py, search/client.py, sync/orchestrator.py"
    - path: ".planning/phases/18-rxpy-codebase-wide-async-migration/18-05-SUMMARY.md"
      provides: "Complete post-migration evidence report for Phase 18"
      contains: "test results, 50-file upload, store-sync, search citations, TUI invariants, Canon update"
---

<objective>
Post-migration validation for Phase 18 — confirm zero behavior regression across the
entire codebase after migrating all async code to RxPY.

This plan is the final gate. It does not write production code. It:
1. Runs the full test suite (regression baseline)
2. Uploads new lectures (added since Phase 18 began) through the migrated pipeline — 50 files
3. Validates semantic search and citation resolution against the full corpus
4. Runs the Phase 17 TUI behavioral invariant suite (TUI regression)
5. Updates Canon.json to reflect the migrated modules
6. Produces the 18-05-SUMMARY.md as the official phase completion record

**Test corpus constraint (CRITICAL):**
The validation upload uses ONLY newly added lectures or books — files in UNTRACKED state
that were not part of the corpus before Phase 18. No currently-indexed files are reset,
re-uploaded, or modified. The existing ~1,748 indexed files stay exactly as they are.

This constraint serves two purposes:
1. It tests the real upload path (no artificial reset/re-upload cycle)
2. It protects the production corpus from unnecessary churn during a code migration

**FAILED states are acceptable in the new-lecture batch.** Gemini API transience means
some files may fail on first pass. The RecoveryCrawler and `--retry-failed` path handle
recovery. The gate is: no files stuck in UPLOADING/PROCESSING permanently, and the
pipeline itself does not crash.

**Distrust posture: SKEPTICAL** — positive evidence required for each verification step.
"No errors" is not sufficient for Steps 2, 3, and 4; specific outcomes must be confirmed.

**TUI regression context (from Phase 17):**
The Phase 17 post-UAT captured 7 behavioral invariants as the contract for TUI behavior.
This plan re-runs those invariants (or the closest available equivalent) to confirm that
migrating Tier 3 services (which the TUI calls indirectly via SearchService) did not break
any TUI behavior.

**Canon.json update:**
Canon.json indexes the "canonical interface" of each module. Migrated modules now have
observable-returning functions alongside (or replacing) coroutine-returning functions.
The Canon must reflect the new interface contracts.
</objective>

<execution_context>
@/Users/david/.claude/get-shit-done/workflows/execute-plan.md
@/Users/david/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md
@.planning/phases/18-rxpy-codebase-wide-async-migration/18-CONTEXT.md
@.planning/phases/18-rxpy-codebase-wide-async-migration/18-04-SUMMARY.md
@Canon.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Full pytest suite</name>
  <files></files>
  <action>
Run the complete pytest suite with verbose output:
```bash
python -m pytest tests/ -v --tb=short 2>&1 | tee /tmp/phase18-test-results.txt
```

Required outcome: ALL PASS. Zero failures, zero errors.

If any test fails:
1. Identify whether it's a pre-existing failure or caused by Phase 18 migration
2. If Phase 18 caused it: fix in the relevant Tier module before continuing
3. If pre-existing: document it explicitly in SUMMARY with evidence it predates Phase 18

Record:
- Total test count
- Pass/fail/skip counts
- Duration
- Any warnings (warn but do not fail on warnings)
  </action>
  <verify>
`python -m pytest tests/ -x -q` → exit code 0, 0 failures
  </verify>
  <done>
Full test suite passed. Results recorded.
  </done>
</task>

<task type="auto">
  <name>Task 2: Upload new lectures through migrated pipeline (50 files)</name>
  <files></files>
  <action>
Upload new UNTRACKED lecture/book files through the fully-migrated RxPY pipeline.
DO NOT reset or re-upload any currently-indexed files.

**Step 1: Confirm new lectures are scanned and UNTRACKED**
```bash
python -m objlib status
sqlite3 data/library.db "SELECT COUNT(*) FROM files WHERE gemini_state = 'untracked';"
```
Required: ≥ 50 UNTRACKED files. If fewer than 50, use however many are available
(document the actual count) — the gate adjusts to the available corpus.

Record the pre-upload indexed count as the baseline:
```bash
sqlite3 data/library.db "SELECT COUNT(*) FROM files WHERE gemini_state = 'indexed';"
```
This number must not decrease after the upload.

**Step 2: Run fsm-upload on new UNTRACKED files**
```bash
python -m objlib fsm-upload --limit 50
```
The FSM guard skips already-indexed files — only UNTRACKED files are processed.

Monitor for:
- RxPY observable errors (scheduler conflicts, closed subjects) — should be ZERO
- OCC conflict retries (expected at c=10 — should retry, not fail)
- 429 retries with backoff (not FAILED transitions)
- Files progressing UNTRACKED → UPLOADING → PROCESSING → INDEXED

**Acceptable outcomes for new-lecture uploads:**
- `indexed` — ideal; counts toward the gate
- `failed` — acceptable (API transience); RecoveryCrawler handles recovery; document count
- `uploading` / `processing` — NOT acceptable if still stuck after upload command exits;
  indicates a pipeline hang in the migrated code

**Step 3: Check terminal states**
```bash
sqlite3 data/library.db "SELECT gemini_state, COUNT(*) FROM files GROUP BY gemini_state;"
```
Confirm:
- UNTRACKED count decreased by ~50 (or however many were processed)
- Pre-existing INDEXED count is unchanged (compare to Step 1 baseline)
- No files stuck in UPLOADING or PROCESSING

**Step 4: Retry any FAILED new-lecture files (optional)**
If FAILED files exist from the new batch and time permits:
```bash
python -m objlib fsm-upload --retry-failed --limit 20
```
Document the before/after FAILED count. Recovery is not required for the gate —
it confirms the recovery path works in the migrated pipeline.

Record all output verbatim.
  </action>
  <verify>
1. New UNTRACKED files processed — count decreased by expected amount
2. No files stuck in UPLOADING or PROCESSING (terminal state only: indexed or failed)
3. Pre-existing indexed file count unchanged from Step 1 baseline
4. No RxPY scheduler errors in upload output
  </verify>
  <done>
New-lecture upload validated. Migrated pipeline processed UNTRACKED files to terminal state.
Pre-existing corpus untouched. RxPY errors: 0.
  </done>
</task>

<task type="auto">
  <name>Task 3: store-sync confirms 0 new orphans</name>
  <files></files>
  <action>
Run store-sync after the new-lecture upload to confirm the migrated pipeline produces
no orphaned store documents.

**Step 1: Dry run to inspect**
```bash
python -m objlib store-sync --store objectivism-library
```
This shows orphan count without deleting. Record the output.

**Expected: 0 orphaned documents.**
Fresh uploads of new files should never produce orphans — there are no prior store documents
for these files to displace. Any orphans found here would indicate a bug in the migrated
pipeline where a prior store document was created but the DB was not updated, or an import
was retried without cleaning up the first attempt's store document.

**If orphans found:**
- Identify the file names: `python -m objlib store-sync --store objectivism-library --verbose`
- Cross-check against the new-lecture batch (Task 2): are the orphans from the new files
  or from the pre-existing corpus?
- If from new files: the `import_document` observable chain has a retry bug — it's creating
  a second store document on retry without removing the first. This is a blocking issue.
- If from pre-existing corpus (pre-existing orphan count same as pre-Phase-18): document,
  but do not block the gate.

**Step 2: Clean up any orphans**
```bash
python -m objlib store-sync --store objectivism-library --no-dry-run --yes
```
Then re-run dry run to confirm 0.

Record all output verbatim.
  </action>
  <verify>
After store-sync, dry-run shows 0 orphaned documents (or only pre-Phase-18 pre-existing
orphans that were already present before this plan — document explicitly).
  </verify>
  <done>
store-sync confirmed 0 new orphaned documents from new-lecture uploads.
  </done>
</task>

<task type="auto">
  <name>Task 4: Semantic search citation validation</name>
  <files></files>
  <action>
Run 5 diverse semantic search queries and verify citation resolution.

```bash
python -m objlib --store objectivism-library search "Rand's theory of knowledge"
python -m objlib --store objectivism-library search "capitalism and individual rights"
python -m objlib --store objectivism-library search "Objectivist ethics egoism"
python -m objlib --store objectivism-library search "induction and concept formation"
python -m objlib --store objectivism-library search "art and aesthetic theory"
```

For each query, verify:
1. Results are returned (non-empty)
2. `[Unresolved file #N]` does NOT appear in any result
3. Citations show real file names (not Gemini IDs)
4. No Python exceptions or RxPY errors during search

Record 1-3 citation examples from one of the queries verbatim.

**Note:** The search/client.py RxPY migration (Plan 18-02) must not have broken the
two-pass citation lookup (Gemini ID → DB filename). This is the behavioral regression
check for the search path.
  </action>
  <verify>
1. All 5 search queries return results
2. Zero instances of `[Unresolved file #N]` in any output
3. Citations show real filenames
4. No exceptions
  </verify>
  <done>
Semantic search validated. All 5 queries return resolved citations. No [Unresolved file #N].
  </done>
</task>

<task type="auto">
  <name>Task 5: TUI behavioral invariant regression check</name>
  <files></files>
  <action>
Re-run the Phase 17 TUI behavioral invariant suite (or the closest equivalent).

The 7 invariants from Phase 17:
1. Debounce: rapid typing fires exactly 1 search after 300ms pause
2. Enter: fires search immediately, cancels debounce timer
3. Stale cancellation: search A results never appear when query B supersedes A
4. Filter trigger: changing filter re-runs search with current query
5. History navigation: Up/Down arrows cycle past queries correctly
6. Empty query: clears results immediately (no debounce)
7. Error containment: search API error shows notification, does not crash TUI or leave is_searching=True

Run these against the live TUI:
```bash
python -m objlib tui
```
(Interactive session — manually exercise each invariant)

Or if Phase 17 produced automated test scripts, run those:
```bash
python -m pytest tests/ -k "tui" -v
```

For each invariant, record: PASS or FAIL, and the specific observation.

**If any TUI invariant fails:** This is a regression from the Tier 3 service migration
(services/search.py or services/library.py). Investigate the observable chain between
TUI → SearchService → GeminiFileSearchClient and fix before proceeding.
  </action>
  <verify>
All 7 TUI behavioral invariants: PASS
  </verify>
  <done>
TUI regression check passed. All 7 Phase 17 behavioral invariants still hold.
  </done>
</task>

<task type="auto">
  <name>Task 6: Update Canon.json</name>
  <files>Canon.json</files>
  <action>
Read `Canon.json` in full.

Update the Canon to reflect the RxPY migration of all 10 modules. For each migrated module,
update its entry to reflect:
- The observable-based interface (where public functions now return or use observables internally)
- The RxPY operators used (for future developers to understand the reactive patterns)
- Remove any mention of asyncio.Semaphore, asyncio.gather, AsyncRetrying, etc. if these were
  the primary interface descriptions

New modules to add if not already present:
- `src/objlib/upload/_operators.py` — custom RxPY operators (occ_transition, upload_with_retry, shutdown_gate)

Use the `canon-update` skill format if Canon.json follows a structured schema.
Read the existing schema before making changes.

After updating:
```bash
python -c "import json; json.load(open('Canon.json')); print('Canon.json valid JSON')"
```
  </action>
  <verify>
1. Canon.json is valid JSON after update
2. All 10 migrated modules have updated entries
3. `src/objlib/upload/_operators.py` is indexed
4. `python -c "import json; json.load(open('Canon.json'))"` → no error
  </verify>
  <done>
Canon.json updated. All migrated modules indexed. JSON valid.
  </done>
</task>

<task type="auto">
  <name>Task 7: Produce 18-05-SUMMARY.md and update STATE.md</name>
  <files>.planning/phases/18-rxpy-codebase-wide-async-migration/18-05-SUMMARY.md</files>
  <action>
Create `.planning/phases/18-rxpy-codebase-wide-async-migration/18-05-SUMMARY.md` as the
official Phase 18 completion record.

**Required sections:**

## Phase 18 Completion Summary

### Verification Results
| Verification | Result | Evidence |
|---|---|---|
| Full pytest suite | PASS (N tests) | [test output summary] |
| New-lecture upload (N files) | PASS (N indexed, M failed-acceptable) | [verbatim DB state output] |
| Pre-existing corpus untouched | PASS (count unchanged) | [before/after indexed count] |
| store-sync 0 new orphans | PASS (0 new orphans) | [verbatim store-sync output] |
| Semantic search citations | PASS (5 queries, 0 unresolved) | [example citations] |
| TUI behavioral invariants (7) | PASS (7/7) | [invariant results list] |
| Canon.json updated | COMPLETE | [list of updated entries] |

### Migration Summary
| Module | Tier | Patterns Replaced | Lines Changed |
|---|---|---|---|
| services/search.py | 3 | to_thread → rx.from_callable | N |
| services/library.py | 3 | to_thread → rx.from_callable | N |
| search/client.py | 3 | @retry → retry_when | N |
| sync/orchestrator.py | 3 | light async → observable | N |
| extraction/batch_orchestrator.py | 2 | Semaphore/gather/polling → flat_map/interval | N |
| extraction/orchestrator.py | 2 | Semaphore/wave logic → flat_map/concat_map | N |
| upload/state.py | 1 | OCC retry → occ_transition | N |
| upload/client.py | 1 | AsyncRetrying → retry_when | N |
| upload/recovery.py | 1 | wait_for → ops.timeout | N |
| upload/orchestrator.py | 1 | all patterns → full RxPY pipeline | N |

### Custom Operators Created
- `occ_transition(fn, max_attempts, base_delay)` — OCC-guarded state transition
- `upload_with_retry(file_record, upload_fn, max_attempts)` — 429-aware upload retry
- `shutdown_gate(obs, shutdown$)` — take_until shutdown broadcast wrapper

### Tenacity Dependency
- Confirm whether tenacity can now be removed from requirements.txt
- List any remaining tenacity usages across src/ (if any)

### Phase 18 Gate Status
COMPLETE — all 5 verification steps passed. Codebase-wide RxPY migration complete.

---

**Also update STATE.md:**
```
Phase 18: [##########] 5/5 plans -- COMPLETE (RxPY codebase-wide async migration) -- gate PASSED [date]
```

Update "Current Position" to reflect Phase 18 completion. Update progress count.
  </action>
  <verify>
1. 18-05-SUMMARY.md exists with all required sections
2. All 6 verification rows in the Results table show PASS or COMPLETE
3. Migration summary table has all 10 modules with evidence
4. STATE.md updated to reflect Phase 18 complete
  </verify>
  <done>
Phase 18 complete. 18-05-SUMMARY.md written. STATE.md updated. Codebase-wide RxPY migration DONE.
  </done>
</task>

</tasks>

<verification>
Phase 18 Plan 05 verification checklist:
1. `python -m pytest tests/ -x -q` → exit 0, 0 failures
2. New UNTRACKED lectures uploaded through migrated pipeline — no files stuck in UPLOADING/PROCESSING
3. Pre-existing indexed file count unchanged (no regressions on current corpus)
4. `python -m objlib store-sync --store objectivism-library` → 0 new orphaned documents
5. 5 search queries return results without [Unresolved file #N]
6. All 7 Phase 17 TUI behavioral invariants still hold
7. Canon.json updated and valid JSON
8. 18-05-SUMMARY.md documents all verification steps with verbatim evidence
9. STATE.md updated to show Phase 18 COMPLETE
</verification>

<success_criteria>
- Zero behavior regression: all tests pass, all invariants hold
- New-lecture upload works through the fully-migrated observable pipeline — FAILED states acceptable, stuck states are not
- Pre-existing indexed corpus untouched: no --reset-existing, no state mutations on already-indexed files
- search citations resolve correctly: RxPY-migrated search client preserves two-pass lookup logic
- Canon reflects the new reactive interface contracts
- Phase 18 is the definitive completion of codebase-wide RxPY migration — no asyncio primitives
  remain in the migrated modules
</success_criteria>

<output>
After completion, create `.planning/phases/18-rxpy-codebase-wide-async-migration/18-05-SUMMARY.md`
and update STATE.md to reflect Phase 18 COMPLETE.
</output>
