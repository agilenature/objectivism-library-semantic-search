---
phase: 18-rxpy-codebase-wide-async-migration
plan: 04
type: execute
wave: 4
depends_on: ["18-03"]
files_modified:
  - src/objlib/upload/orchestrator.py
  - src/objlib/upload/client.py
  - src/objlib/upload/state.py
  - src/objlib/upload/recovery.py
autonomous: true

must_haves:
  truths:
    - "Semaphore+gather fan-outs in orchestrator.py replaced with flat_map(max_concurrent=N)"
    - "Staggered launches replaced with zip(rx.interval(1.0), rx.from_iterable(...)) + flat_map"
    - "In-place 429 retry loops replaced with retry_when + exponential backoff observable (operator contract from 18-01)"
    - "Batch retry pass replaced with concat(upload_obs, rx.timer(30).flat_map(retry_obs))"
    - "Dynamic semaphore resizing replaced with circuit-breaker Subject → max_concurrent (approach from 18-01 spike Pattern 3)"
    - "asyncio.Event shutdown replaced with Subject + take_until on all in-flight observables"
    - "OCC transitions in state.py replaced with occ_transition operator (from 18-01)"
    - "AsyncRetrying (tenacity) in client.py poll_operation replaced with retry_when + delay_when"
    - "asyncio.wait_for in recovery.py replaced with ops.timeout(N)"
    - "fsm-upload --limit 20 end-to-end test passes: 20 files reach gemini_state='indexed'"
    - "store-sync confirms 0 orphaned documents after 18-04 execution"
    - "All FSM state transitions confirmed in DB after test upload"
  artifacts:
    - path: "src/objlib/upload/orchestrator.py"
      provides: "Upload orchestrator with full RxPY observable pipeline replacing asyncio primitives"
      contains: "flat_map, retry_when, take_until, zip(rx.interval"
    - path: "src/objlib/upload/client.py"
      provides: "Gemini client with RxPY retry replacing tenacity AsyncRetrying"
      contains: "retry_when, delay_when"
    - path: "src/objlib/upload/state.py"
      provides: "State manager with occ_transition operator for OCC-guarded writes"
      contains: "occ_transition"
    - path: "src/objlib/upload/recovery.py"
      provides: "Recovery crawler with ops.timeout replacing asyncio.wait_for"
      contains: "ops.timeout"
  key_links:
    - from: "src/objlib/upload/orchestrator.py"
      to: "src/objlib/upload/state.py"
      via: "Observable pipeline triggers state transitions via occ_transition operator"
      pattern: "flat_map → occ_transition"
    - from: "src/objlib/upload/orchestrator.py"
      to: "src/objlib/upload/client.py"
      via: "upload_with_retry operator wraps client API calls in retry_when pipeline"
      pattern: "retry_when (429 handling)"
    - from: "src/objlib/upload/recovery.py"
      to: "src/objlib/upload/state.py"
      via: "RecoveryCrawler uses occ_transition for safe state resets with timeout guard"
      pattern: "ops.timeout + occ_transition"
---

<objective>
Migrate Tier 1 (Upload Pipeline) — the highest-complexity migration in Phase 18.

This plan touches the most critical production code: the FSM-managed upload pipeline that
Phase 16 took 6 weeks to validate. The migration principle is STRICT: zero behavior change.
Every test that passed before 18-04 must pass after.

**Distrust posture: HOSTILE** — same as Phase 9 and Phase 12 spikes. "No errors thrown"
does not pass the gate. Behavioral verification (fsm-upload --limit 20, store-sync 0 orphans,
DB state transitions confirmed) is the gate.

**Critical invariant from v2.0 (must not be broken):**
The FSM transition guards (`gemini_state` read → check → write with OCC) must still provide
atomicity. RxPY operators must preserve the OCC semantics — they wrap the transition logic
but do not bypass it.

**Migration order within this plan:**
1. `state.py` — OCC operator (foundation; other modules depend on it)
2. `client.py` — poll_operation retry (standalone; no state.py dependency)
3. `recovery.py` — timeout guard (depends on state.py occ_transition)
4. `orchestrator.py` — all other patterns (depends on state.py + client.py)

This order minimizes the chance of a partial-migration state where modules are inconsistent.

**Do NOT remove tenacity as a package dependency** until 18-05 confirms no remaining usage.
</objective>

<execution_context>
@/Users/david/.claude/get-shit-done/workflows/execute-plan.md
@/Users/david/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/18-rxpy-codebase-wide-async-migration/18-CONTEXT.md
@.planning/phases/18-rxpy-codebase-wide-async-migration/18-03-SUMMARY.md
@spike/phase18_spike/design_doc.md
@src/objlib/upload/state.py
@src/objlib/upload/client.py
@src/objlib/upload/orchestrator.py
@src/objlib/upload/recovery.py
@governance/pre-mortem-gemini-fsm.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Read and inventory upload pipeline asyncio patterns</name>
  <files>src/objlib/upload/state.py, src/objlib/upload/client.py, src/objlib/upload/orchestrator.py, src/objlib/upload/recovery.py</files>
  <action>
Read all four files in full. Produce an inventory of every asyncio primitive and their context.

For each site:
- Pattern type (Semaphore, gather, Event, sleep+loop, AsyncRetrying, wait_for, etc.)
- Line number and function name
- Parameter values (N for Semaphore, seconds for sleep, attempts for retry)
- Whether it's in the hot path (called per-file) or cold path (startup/shutdown)
- Which FSM transition it's associated with (if any)

This inventory drives the migration in Tasks 2-5 and serves as the pre-migration baseline
for the post-migration diff.

Also identify: which aiosqlite calls must remain async (they all must — do not wrap these
in observables at this level; only wrap the transition functions that call them).
  </action>
  <verify>
Inventory produced and complete. grep counts match:
`grep -rn "asyncio\.\|AsyncRetrying\|AsyncLimiter" src/objlib/upload/`
  </verify>
  <done>
Inventory complete. All patterns identified with context.
  </done>
</task>

<task type="auto">
  <name>Task 2: Migrate state.py — OCC operator</name>
  <files>src/objlib/upload/state.py</files>
  <action>
Read `src/objlib/upload/state.py` in full before making any changes.

**Step 1: Copy occ_transition operator from spike**
The operator was validated in 18-01. Copy it (or import from a shared location) into
`src/objlib/upload/state.py` or a new `src/objlib/upload/_operators.py` module.

Prefer: create `src/objlib/upload/_operators.py` as a home for custom RxPY operators.
This keeps them discoverable and testable in isolation.

**Step 2: Replace OCC retry loops**
Every `while True: try: transition(); break; except OCCConflictError: await sleep(backoff)`
pattern becomes:
```python
await occ_transition(
    lambda: self._transition_to_state(file_id, new_state, condition),
    max_attempts=5,
    base_delay=0.1
).run()
```

**Step 3: Verify aiosqlite calls are NOT wrapped**
The raw aiosqlite DB calls inside `_transition_to_state()` (or equivalent) must remain
as plain `async with aiosqlite.connect(...) as db:` — do not wrap these in observables.
The occ_transition operator wraps the entire transition function (which internally uses
aiosqlite), not the individual DB calls.

**Step 4: Run tests after each state.py change**
```bash
python -m pytest tests/ -k "state" -x -q
```
  </action>
  <verify>
1. `grep -n "while True.*OCCConflict\|sleep.*backoff" src/objlib/upload/state.py` → 0 results
2. `grep -n "occ_transition" src/objlib/upload/state.py` → results present
3. `src/objlib/upload/_operators.py` exists and contains occ_transition
4. `python -m pytest tests/ -k "state" -x -q` → passes
5. FSM guard semantics preserved: `python -c "from objlib.upload.state import AsyncUploadStateManager; print('OK')"` → OK
  </verify>
  <done>
state.py migrated. OCC retry loops replaced with occ_transition operator. Tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 3: Migrate client.py — poll_operation retry</name>
  <files>src/objlib/upload/client.py</files>
  <action>
Read `src/objlib/upload/client.py` in full before making any changes.

**Background (from MEMORY.md):**
The `poll_operation` function in client.py was fixed in Phase 16 (commit 64e2725):
the bug was `return operation` inside tenacity's `with attempt:` block exiting the
coroutine instead of retrying. Fix: `raise TryAgain` instead of `return`. The current
code uses `AsyncRetrying` + `TryAgain` correctly.

**Migration:**
Replace `AsyncRetrying` with `retry_when` using the confirmed contract from 18-01 spike
(Pattern 5). The key semantic: retry when `TryAgain` is raised (or a sentinel condition
is detected), stop when the operation is complete.

```python
# Before:
async for attempt in AsyncRetrying(stop=stop_after_attempt(MAX_POLL), wait=wait_fixed(POLL_INTERVAL)):
    with attempt:
        operation = await self._get_operation(operation_name)
        if not operation.done:
            raise TryAgain
        return operation

# After:
async def _poll_once():
    operation = await self._get_operation(operation_name)
    if not operation.done:
        raise _OperationNotDone()  # sentinel for retry_when
    return operation

result = await rx.from_callable(_poll_once).pipe(
    ops.retry_when(
        lambda errors: errors.pipe(
            ops.scan(lambda count, e: count + 1 if isinstance(e, _OperationNotDone) else count + MAX_POLL, 0),
            ops.flat_map(
                lambda n: rx.throw(TimeoutError(f"Operation did not complete after {MAX_POLL} polls"))
                if n >= MAX_POLL
                else rx.timer(POLL_INTERVAL)
            )
        )
    )
).run()
```

Define `_OperationNotDone` as a private exception class in client.py.

Also migrate `wait_for_active` if it uses AsyncRetrying.
  </action>
  <verify>
1. `grep -n "AsyncRetrying\|TryAgain\|from tenacity" src/objlib/upload/client.py` → 0 results
2. `grep -n "retry_when\|_OperationNotDone" src/objlib/upload/client.py` → results present
3. `python -m pytest tests/ -k "client" -x -q` → passes
4. `python -c "from objlib.upload.client import GeminiFileSearchClient; print('OK')"` → OK
  </verify>
  <done>
client.py migrated. AsyncRetrying replaced with retry_when. TryAgain replaced with sentinel exception. Tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 4: Migrate recovery.py — timeout operator</name>
  <files>src/objlib/upload/recovery.py</files>
  <action>
Read `src/objlib/upload/recovery.py` in full before making any changes.

**asyncio.wait_for → ops.timeout:**
```python
# Before:
result = await asyncio.wait_for(recovery_coro(), timeout=RECOVERY_TIMEOUT)

# After:
result = await rx.from_callable(recovery_coro).pipe(
    ops.timeout(RECOVERY_TIMEOUT)
).run()
```

`ops.timeout(N)` raises `rx.core.typing.Observer` error (TimeoutError in RxPY) if the
observable does not complete within N seconds. This is semantically equivalent to
`asyncio.wait_for`'s `asyncio.TimeoutError`.

**Three-phase sequential recovery → concat_map:**
If recovery has explicit Phase 1 → Phase 2 → Phase 3 sequential steps, chain them with
`concat_map` (same pattern as extraction wave logic):
```python
rx.from_callable(phase1).pipe(
    ops.concat_map(lambda r1: rx.from_callable(lambda: phase2(r1))),
    ops.concat_map(lambda r2: rx.from_callable(lambda: phase3(r2))),
)
```

Also apply `occ_transition` for any state transition calls inside recovery that use
manual OCC retry patterns.

Run tests after changes:
```bash
python -m pytest tests/ -k "recovery" -x -q
```
  </action>
  <verify>
1. `grep -n "asyncio.wait_for" src/objlib/upload/recovery.py` → 0 results
2. `grep -n "ops.timeout\|concat_map" src/objlib/upload/recovery.py` → results present
3. `python -m pytest tests/ -k "recovery" -x -q` → passes
  </verify>
  <done>
recovery.py migrated. wait_for replaced with ops.timeout. Sequential phases use concat_map.
  </done>
</task>

<task type="auto">
  <name>Task 5: Migrate orchestrator.py — all remaining patterns</name>
  <files>src/objlib/upload/orchestrator.py</files>
  <action>
Read `src/objlib/upload/orchestrator.py` in full before making any changes.

This is the most complex file. Apply patterns in this order:

**1. Semaphore+gather → flat_map(max_concurrent=N)**
Main upload fan-out: replace with flat_map as in Tier 2.

**2. Staggered launches → zip(rx.interval(1.0), source)**
```python
# Before:
for i, item in enumerate(items):
    await asyncio.sleep(i * STAGGER_DELAY)
    tasks.append(asyncio.ensure_future(upload(item)))

# After:
rx.from_iterable(enumerate(items)).pipe(
    ops.zip(rx.interval(STAGGER_DELAY)),
    ops.flat_map(lambda pair: rx.from_callable(lambda: asyncio.run(upload(pair[0][1]))))
)
```

**3. In-place 429 retry → retry_when + backoff**
Use `upload_with_retry` operator from `_operators.py` (operator contract from 18-01):
```python
upload_obs = upload_with_retry(file_record, client.upload_file, max_attempts=5)
```

**4. Batch retry pass → concat**
```python
first_pass_obs.pipe(
    ops.concat(
        rx.timer(RETRY_DELAY_SECONDS).pipe(
            ops.flat_map(lambda _: retry_pass_obs)
        )
    )
)
```

**5. Dynamic concurrency (circuit-breaker Subject)**
Use the approach confirmed in 18-01 spike Pattern 3. The exact implementation depends
on the spike result — apply whatever was validated there, not a re-invention.

**6. Shutdown asyncio.Event → Subject + take_until**
```python
shutdown$ = rx.subject.BehaviorSubject(False)

# In shutdown handler:
shutdown$.on_next(True)

# Applied to all observable chains:
obs.pipe(ops.take_until(shutdown$.pipe(ops.filter(lambda x: x))))
```

Run full test suite after all changes:
```bash
python -m pytest tests/ -x -q
```
  </action>
  <verify>
1. `grep -n "asyncio.Semaphore\|asyncio.gather\|asyncio.Event\|asyncio.sleep" src/objlib/upload/orchestrator.py` → 0 results
2. `grep -n "flat_map\|take_until\|retry_when\|BehaviorSubject" src/objlib/upload/orchestrator.py` → results present
3. `python -m pytest tests/ -x -q` → ALL PASS
  </verify>
  <done>
orchestrator.py migrated. All asyncio primitives replaced. Full test suite green.
  </done>
</task>

<task type="auto">
  <name>Task 6: fsm-upload end-to-end validation (new lectures only)</name>
  <files>src/objlib/upload/orchestrator.py, src/objlib/upload/state.py</files>
  <action>
Run the end-to-end validation of the migrated upload pipeline using newly added lectures.
DO NOT reset or touch any currently-indexed files.

**Pre-condition: new lectures must be scanned into DB as UNTRACKED**
Before running this task, the user will have copied new lecture/book files to the library
directory and run `objlib scan`. Confirm UNTRACKED files exist:
```bash
sqlite3 data/library.db "SELECT COUNT(*) FROM files WHERE gemini_state = 'untracked';"
```
If 0 UNTRACKED files: STOP. Do not proceed until new lectures are scanned in.
Minimum needed: 20 UNTRACKED files for this gate.

**Step 1: Run fsm-upload --limit 20 on UNTRACKED new files**
```bash
python -m objlib fsm-upload --limit 20
```
The FSM guard on `transition_to_uploading` skips already-indexed files automatically —
only UNTRACKED files will be picked up.

Monitor for:
- No scheduler conflicts or RxPY subscription errors
- OCC conflicts retried correctly (retry logs expected at c=10)
- 429 retries fire with backoff (not FAILED transitions)
- Files progressing through UNTRACKED → UPLOADING → PROCESSING → INDEXED

Note: some files may end in FAILED state on first pass (normal — Gemini API transience).
FAILED files will be recovered by RecoveryCrawler on the next run or via `--retry-failed`.
The pipeline itself must not crash or leave files in UPLOADING/PROCESSING permanently.

**Step 2: Verify DB state for the uploaded batch**
```bash
sqlite3 data/library.db "SELECT gemini_state, COUNT(*) FROM files WHERE gemini_state != 'indexed' OR gemini_file_id IS NOT NULL GROUP BY gemini_state ORDER BY COUNT(*) DESC LIMIT 10;"
```
Specifically check the newly-uploaded files reached indexed (or FAILED with a clean error,
not stuck in UPLOADING/PROCESSING):
```bash
sqlite3 data/library.db "SELECT gemini_state, COUNT(*) FROM files WHERE gemini_state IN ('uploading', 'processing', 'indexed', 'failed') GROUP BY gemini_state;"
```

**Step 3: Verify store sync (0 orphans from new uploads)**
```bash
python -m objlib store-sync --store objectivism-library
```
Fresh uploads of new files should produce 0 orphans (no reset was done, so no old store
documents to orphan). Any orphans found here are a bug in the migrated pipeline.

**Step 4: Verify pre-existing corpus untouched**
```bash
sqlite3 data/library.db "SELECT COUNT(*) FROM files WHERE gemini_state = 'indexed';"
```
This count must be ≥ the count before Phase 18 began (pre-existing indexed files must not
have been touched). Compare against the count recorded in 18-04-SUMMARY.md pre-migration baseline.

Record all output verbatim.
  </action>
  <verify>
1. New lecture files processed through the migrated pipeline without RxPY errors
2. No files stuck in UPLOADING or PROCESSING state (terminal: indexed or failed)
3. store-sync confirms 0 new orphaned documents
4. Pre-existing indexed file count is unchanged
  </verify>
  <done>
End-to-end validation passed. New lectures uploaded via migrated RxPY pipeline. 0 orphans. Pre-existing corpus untouched.
  </done>
</task>

<task type="auto">
  <name>Task 7: Produce SUMMARY</name>
  <files>.planning/phases/18-rxpy-codebase-wide-async-migration/18-04-SUMMARY.md</files>
  <action>
Create `.planning/phases/18-rxpy-codebase-wide-async-migration/18-04-SUMMARY.md` with:

- Files migrated: orchestrator.py, client.py, state.py, recovery.py
- Pattern replacements by file with before/after counts
- Custom operators added to _operators.py: list each with its contract
- End-to-end test results: fsm-upload --limit 20 output (verbatim)
- Pre-migration baseline: indexed file count before Phase 18 began (record this so 18-05 can confirm it's unchanged)
- New lecture test: count of UNTRACKED files processed, terminal state breakdown (indexed/failed), any retries observed
- store-sync output: 0 new orphans confirmed (verbatim)
- DB state query output (verbatim)
- Any OCC conflicts observed during test upload (evidence of retry working)
- Any FAILED files from new-lecture upload (expected — document with file names; these are recovery candidates not blocking the gate)
- Any deviations from CONTEXT.md plan with justification
- Gate status: 18-05 UNBLOCKED
- Remaining tenacity usage (if any): grep result across entire src/
  </action>
  <verify>
18-04-SUMMARY.md exists with all sections including verbatim test output.
  </verify>
  <done>
18-04 complete. Tier 1 migrated and validated. SUMMARY written. 18-05 unblocked.
  </done>
</task>

</tasks>

<verification>
Phase 18 Plan 04 verification checklist:
1. `grep -rn "asyncio.Semaphore\|asyncio.gather\|asyncio.Event" src/objlib/upload/` → 0 results
2. `grep -rn "AsyncRetrying\|TryAgain" src/objlib/upload/client.py` → 0 results
3. `grep -rn "asyncio.wait_for" src/objlib/upload/recovery.py` → 0 results
4. `grep -rn "flat_map\|retry_when\|take_until\|occ_transition" src/objlib/upload/` → results in all 4 files
5. `python -m pytest tests/ -x -q` → ALL PASS
6. New lecture files (UNTRACKED) processed via migrated pipeline — no files stuck in UPLOADING/PROCESSING
7. `python -m objlib store-sync --store objectivism-library` → 0 orphaned documents from new uploads
8. Pre-existing indexed file count unchanged (pre-existing corpus not touched)
9. 18-04-SUMMARY.md documents all changes with verbatim evidence
</verification>

<success_criteria>
- HOSTILE gate: new lecture files processed end-to-end via migrated pipeline — not just "no errors"
- Files reach terminal state (indexed or failed-with-clean-error) — none stuck in uploading/processing
- OCC transitions preserve atomicity: concurrent upload confirms no state corruption
- store-sync 0 orphans: fresh uploads of new files produce no orphaned store documents
- Pre-existing indexed corpus untouched: no --reset-existing, no state changes on already-indexed files
- All existing tests pass: zero behavior regression from Tier 1 migration
- 18-05 is unblocked
</success_criteria>

<output>
After completion, create `.planning/phases/18-rxpy-codebase-wide-async-migration/18-04-SUMMARY.md`
</output>
