---
phase: 18-rxpy-codebase-wide-async-migration
plan: 01
type: spike
wave: 1
depends_on: ["17-04"]
files_modified:
  - spike/phase18_spike/test_harness.py
  - spike/phase18_spike/design_doc.md
autonomous: true

must_haves:
  truths:
    - "Each of the 5 high-risk pattern mappings (AsyncIOScheduler+aiosqlite, OCC retry observable, dynamic concurrency, shutdown Subject, tenacity replacement) has a working test harness"
    - "design_doc.md commits to operator contracts (input/output types, retry semantics, error propagation) for all 10 pattern mappings in the CONTEXT.md table"
    - "Go/no-go gate is answered affirmatively: all patterns map cleanly to RxPY without hidden complexity"
    - "If any pattern cannot be cleanly mapped, the gate is BLOCKED and the phase is redesigned before 18-02 begins"
  artifacts:
    - path: "spike/phase18_spike/test_harness.py"
      provides: "Working async test harness validating all 5 high-risk patterns"
      contains: "AsyncIOScheduler+aiosqlite, OCC operator, dynamic concurrency, shutdown Subject, tenacity replacement"
    - path: "spike/phase18_spike/design_doc.md"
      provides: "Operator design contracts and go/no-go verdict"
      contains: "occ_transition, upload_with_retry, shutdown_gate contracts with confirmed semantics"
  key_links:
    - from: "spike/phase18_spike/test_harness.py"
      to: "src/objlib/upload/state.py"
      via: "aiosqlite calls wrapped in observable streams — validates no connection-sharing violations"
      pattern: "AsyncIOScheduler+aiosqlite co-existence"
    - from: "spike/phase18_spike/design_doc.md"
      to: ".planning/phases/18-rxpy-codebase-wide-async-migration/18-CONTEXT.md"
      via: "Commits to operator contracts; references spike evidence for each pattern"
      pattern: "go/no-go gate"
---

<objective>
Validate the 5 highest-risk RxPY operator patterns before committing to full migration.

This spike has a HOSTILE distrust posture — "no errors thrown" does not pass the gate.
Each pattern requires positive affirmative evidence of correct behavior:
1. Observable completes cleanly (no dangling subscriptions)
2. Side effects (DB writes, API calls) occur exactly as designed
3. Error propagation reaches the correct error handler
4. Cancellation/shutdown does not leave state inconsistent

The spike does NOT migrate any production code. It proves that the operators work
correctly in isolation before 18-02 begins.

The 5 patterns to validate:

**Pattern 1: AsyncIOScheduler + aiosqlite co-existence**
Phase 17 confirmed AsyncIOScheduler works with Textual. This spike must confirm it
works with aiosqlite in a plain asyncio.run() context (no Textual dependency).
Adversarial condition: concurrent observable streams, each writing to aiosqlite,
with no connection-sharing violations (each stream uses its own connection).

**Pattern 2: OCC-guarded transition as a custom retry observable**
Current: `while True: try: await state_manager.transition(); break; except OCCConflictError: await sleep(backoff)`
Target: `occ_transition(fn, max_attempts=5)` operator
Adversarial condition: concurrent transitions on the same file trigger OCCConflictError;
the operator retries with backoff and eventually succeeds (or fails after max_attempts).
Evidence required: concurrent test with 10 coroutines each calling occ_transition on
the same record — all succeed, none stuck, exactly one writes at a time.

**Pattern 3: Dynamic concurrency (circuit-breaker Subject)**
Current: Mutate `Semaphore._value` (fragile, not public API)
Target: `BehaviorSubject` emitting current N, driving flat_map concurrency
Investigation: Does RxPY's flat_map support dynamic max_concurrent changes?
If not, document the alternative (window-based, or restructured pipeline).
Evidence required: Working implementation of a pipeline where concurrency drops from
10 to 2 mid-stream (simulating 429 pressure signal) without losing in-flight items.

**Pattern 4: Shutdown Subject + take_until**
Current: `asyncio.Event` checked inside each coroutine loop
Target: `shutdown$.next()` + `obs.pipe(ops.take_until(shutdown$))` applied to all chains
Adversarial condition: shutdown fires while 5 aiosqlite writes are in-flight — all writes
complete before shutdown (no force-kill), no connections left open, no items dropped mid-write.
Evidence required: shutdown latency measured (time from shutdown$.next() to last item emitted).

**Pattern 5: Tenacity AsyncRetrying → RxPY retry_when**
Current: `async for attempt in AsyncRetrying(...): with attempt: ... raise TryAgain`
Target: `retry_when(error_obs => error_obs.pipe(ops.delay(backoff)))` or `delay_when`
Adversarial condition: simulate poll_operation behavior — first 3 calls raise TryAgain,
4th call succeeds. Observable must emit the success value, not re-raise.
Evidence required: Observable emits exactly 1 success value after 3 retries; retry count
is verified; backoff delays are measured.
</objective>

<execution_context>
@/Users/david/.claude/get-shit-done/workflows/execute-plan.md
@/Users/david/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md
@.planning/phases/18-rxpy-codebase-wide-async-migration/18-CONTEXT.md
@src/objlib/upload/state.py
@src/objlib/upload/client.py
@src/objlib/upload/orchestrator.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Scaffold spike harness and install rx dependency</name>
  <files>spike/phase18_spike/__init__.py, spike/phase18_spike/test_harness.py</files>
  <action>
Create the spike directory and scaffold the test harness.

**Step 1: Check rx/rxpy is installed**
```bash
python -c "import rx; print(rx.__version__)"
```
If not installed:
```bash
pip install rx
```

**Step 2: Create spike/phase18_spike/__init__.py** (empty)

**Step 3: Scaffold spike/phase18_spike/test_harness.py** with:
- Top-level imports: `import asyncio, rx, aiosqlite, time` and `from rx import operators as ops`
- `from rx.scheduler.eventloop import AsyncIOScheduler`
- A `main()` async function that calls each of the 5 pattern tests in sequence
- Each pattern test is a standalone async function returning `(passed: bool, evidence: str)`
- A summary at the end showing which patterns passed/failed with evidence

**Step 4: Verify imports work**
```bash
cd spike/phase18_spike && python -c "import test_harness" && echo "OK"
```
  </action>
  <verify>
1. `python -c "import rx; from rx.scheduler.eventloop import AsyncIOScheduler; print('rx OK')"` exits 0
2. `spike/phase18_spike/test_harness.py` exists and imports without error
  </verify>
  <done>
Spike harness scaffolded, rx installed, all imports verified.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement and validate Pattern 1 (AsyncIOScheduler + aiosqlite)</name>
  <files>spike/phase18_spike/test_harness.py</files>
  <action>
Add `test_pattern1_scheduler_aiosqlite()` to the harness.

The test:
1. Creates an in-memory aiosqlite DB
2. Creates `AsyncIOScheduler(asyncio.get_event_loop())`
3. Creates 10 concurrent observable streams, each:
   - Emits 3 items
   - Each item triggers an aiosqlite INSERT (own connection per stream)
   - Scheduled on `AsyncIOScheduler`
4. Uses `rx.merge(*streams).pipe(ops.to_list()).run()` to collect all results
5. Verifies: 30 rows inserted, no connection-sharing errors, no event loop conflicts

**Adversarial check:** Each stream opens its own `aiosqlite.connect()` context. The test
must confirm this pattern (own connection per stream) is safe — it's the pattern production
code must use.

**Evidence to record:**
- Row count in DB after all streams complete
- Any exceptions caught
- Time to complete (should be near-instantaneous for in-memory DB)
  </action>
  <verify>
Pattern 1 test function added; run it with `python spike/phase18_spike/test_harness.py`
and confirm "Pattern 1: PASSED" with 30 rows inserted.
  </verify>
  <done>
Pattern 1 validated: AsyncIOScheduler + aiosqlite co-exist cleanly with own-connection-per-stream.
  </done>
</task>

<task type="auto">
  <name>Task 3: Implement and validate Pattern 2 (OCC retry observable)</name>
  <files>spike/phase18_spike/test_harness.py</files>
  <action>
Add `test_pattern2_occ_transition()` and the `occ_transition` operator.

**occ_transition operator:**
```python
class OCCConflictError(Exception):
    pass

def occ_transition(fn, max_attempts=5, base_delay=0.1):
    """Retry fn() on OCCConflictError with exponential backoff + jitter."""
    import random

    def subscribe(observer, scheduler=None):
        async def run():
            for attempt in range(max_attempts):
                try:
                    result = await fn()
                    observer.on_next(result)
                    observer.on_completed()
                    return
                except OCCConflictError:
                    if attempt == max_attempts - 1:
                        observer.on_error(OCCConflictError(f"OCC conflict after {max_attempts} attempts"))
                        return
                    delay = min(base_delay * (2 ** attempt) + random.random() * 0.05, 1.0)
                    await asyncio.sleep(delay)
        asyncio.ensure_future(run())

    return rx.create(subscribe)
```

**Adversarial test:**
- Shared counter (simulating a DB row with optimistic locking)
- 10 concurrent coroutines each calling `occ_transition(lambda: increment_counter())`
- `increment_counter()` checks a version field; if version changed since read, raises OCCConflictError
- Run all 10 concurrently with `rx.merge(*streams)`
- Evidence required: final counter = 10 (each coroutine succeeded exactly once), no deadlocks
  </action>
  <verify>
Pattern 2 test produces "Pattern 2: PASSED" with counter=10 and evidence that each
coroutine succeeded exactly once after retries.
  </verify>
  <done>
Pattern 2 validated: occ_transition operator handles concurrent OCC conflicts correctly.
  </done>
</task>

<task type="auto">
  <name>Task 4: Implement and validate Patterns 3, 4, 5</name>
  <files>spike/phase18_spike/test_harness.py</files>
  <action>
Add tests for the three remaining patterns.

**Pattern 3: Dynamic concurrency**
Investigate and implement the dynamic-N `flat_map` approach.

Key question: Does `rx.from_iterable([...]).pipe(ops.flat_map(fn, max_concurrent=2))`
support changing `max_concurrent` mid-stream? (It does not — max_concurrent is fixed at
subscription time in RxPY 3.x.)

Alternative approach: Use a `BehaviorSubject` to gate item emission:
```python
concurrency_gate = BehaviorSubject(10)  # starts at 10
# When pressure signal received: concurrency_gate.on_next(2)
# Items check semaphore N from concurrency_gate before proceeding
```

Or: restart the pipeline with new N when circuit-breaker fires.
Document the chosen approach with evidence.

Test: 20 items emitted; at item 10, concurrency drops from 10 to 2; verify in-flight
items at time of drop all complete before new lower limit takes effect.

**Pattern 4: Shutdown Subject + take_until**
```python
shutdown$ = rx.subject.Subject()
# Apply to all streams: obs.pipe(ops.take_until(shutdown$))
```

Test: 5 streams each emitting 10 items with 50ms delay between items.
At t=200ms, fire shutdown$.on_next(None).
Evidence: all streams complete within 100ms of shutdown signal; no items emitted after shutdown.

**Pattern 5: retry_when replacing tenacity AsyncRetrying**
```python
def make_retrying_observable(fn, max_retries=5, base_delay=1.0):
    attempt_count = [0]

    def subscribe(observer, scheduler=None):
        async def run():
            try:
                result = await fn()
                observer.on_next(result)
                observer.on_completed()
            except Exception as e:
                observer.on_error(e)
        asyncio.ensure_future(run())

    return rx.create(subscribe).pipe(
        ops.retry_when(
            lambda errors: errors.pipe(
                ops.scan(lambda acc, e: acc + 1, 0),
                ops.flat_map(
                    lambda n: rx.throw(Exception("max retries")) if n > max_retries
                    else rx.timer(base_delay * (2 ** (n - 1)))
                )
            )
        )
    )
```

Test: fn() raises TryAgain (or a sentinel exception) 3 times, then returns "success".
Observable must emit "success" and complete. Verify retry count = 3.
  </action>
  <verify>
All three pattern tests produce PASSED verdicts when running the harness.
`python spike/phase18_spike/test_harness.py` shows:
  Pattern 3: PASSED (with documented approach for dynamic concurrency)
  Pattern 4: PASSED (shutdown latency < 100ms)
  Pattern 5: PASSED (3 retries, then success emitted)
  </verify>
  <done>
Patterns 3, 4, 5 validated with evidence. Harness complete.
  </done>
</task>

<task type="auto">
  <name>Task 5: Write design_doc.md and produce SUMMARY</name>
  <files>spike/phase18_spike/design_doc.md</files>
  <action>
Write `spike/phase18_spike/design_doc.md` with:

**Section 1: Go/No-Go Verdict**
State clearly: GO or NO-GO for proceeding to 18-02.

**Section 2: Pattern Mapping Table (confirmed)**
All 10 patterns from CONTEXT.md table, with:
- Current implementation
- Confirmed RxPY target (updated from spike results)
- Evidence from spike (pass/fail, key finding)

**Section 3: Operator Contracts**
Final contracts for the 3 custom operators:
- `occ_transition(fn, max_attempts, base_delay)` — input/output/retry/terminal
- `upload_with_retry(file_record, upload_fn, max_attempts)` — 429-specific retry
- `shutdown_gate(obs, shutdown$)` — take_until wrapper

**Section 4: Production Implementation Guidelines**
For each tier:
- Tier 3: `asyncio.to_thread` → `rx.from_callable` + `observe_on(AsyncIOScheduler())` — no custom operators needed
- Tier 2: `asyncio.Semaphore` + `gather` → `flat_map(max_concurrent=N)`, `AsyncLimiter` → `throttle_with_timeout`
- Tier 1: All custom operators from Section 3; dynamic concurrency approach (from Pattern 3 finding)

**Section 5: Risks and Mitigations**
Any patterns that required non-obvious approaches; mitigation strategy for each.

Then create `.planning/phases/18-rxpy-codebase-wide-async-migration/18-01-SUMMARY.md` with:
- Spike outcome: GO/NO-GO verdict
- Key finding for each of the 5 patterns
- Operator contracts committed (reference design_doc.md)
- Gate status: 18-02 UNBLOCKED (or BLOCKED with reason)
  </action>
  <verify>
1. `spike/phase18_spike/design_doc.md` exists and contains all 5 sections
2. `.planning/phases/18-rxpy-codebase-wide-async-migration/18-01-SUMMARY.md` exists
3. design_doc.md contains "GO" or "NO-GO" verdict
4. SUMMARY references design_doc.md path
  </verify>
  <done>
18-01 complete. Spike design doc committed. GO/NO-GO verdict documented. 18-02 gate status clear.
  </done>
</task>

</tasks>

<verification>
Phase 18 Plan 01 verification checklist:
1. `python spike/phase18_spike/test_harness.py` exits 0 with all 5 patterns PASSED
2. `spike/phase18_spike/design_doc.md` contains operator contracts for occ_transition, upload_with_retry, shutdown_gate
3. design_doc.md addresses all 10 pattern mappings from CONTEXT.md table
4. 18-01-SUMMARY.md contains GO/NO-GO verdict
5. No production code modified (spike only)
6. All existing tests still pass: `python -m pytest tests/ -x -q`
</verification>

<success_criteria>
- All 5 high-risk patterns demonstrated working in isolation with positive evidence
- Operator contracts are precise enough that 18-02 through 18-04 can implement without revisiting spike
- If any pattern is NO-GO: phase is redesigned before 18-02 begins (this is the HOSTILE gate)
- Zero production code changes in this plan
</success_criteria>

<output>
After completion, create `.planning/phases/18-rxpy-codebase-wide-async-migration/18-01-SUMMARY.md`
</output>
