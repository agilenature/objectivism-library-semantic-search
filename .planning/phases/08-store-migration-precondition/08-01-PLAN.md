---
phase: 08-store-migration-precondition
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/objlib/database.py
  - scripts/migrate_phase8.py
autonomous: true

must_haves:
  truths:
    - "The files table has 3 new columns: gemini_store_doc_id TEXT, gemini_state TEXT DEFAULT 'untracked', gemini_state_updated_at TEXT"
    - "All previously-uploaded files are reset to gemini_state='untracked' with gemini_store_doc_id=NULL and gemini_file_id=NULL"
    - "All AI metadata columns (metadata_json, entity tables) are verified untouched after the migration"
    - "A backup of the database exists at data/library.db.bak-phase8 before any changes"
    - "All reset files have gemini_state_updated_at set to the migration timestamp (IS NOT NULL, ISO 8601 with timezone)"
  artifacts:
    - path: "src/objlib/database.py"
      provides: "V9 schema migration (3 new columns via ALTER TABLE ADD COLUMN)"
      contains: "MIGRATION_V9"
    - path: "scripts/migrate_phase8.py"
      provides: "Standalone migration script for state reset (MIGR-04) with user confirmation"
      min_lines: 80
  key_links:
    - from: "src/objlib/database.py"
      to: "PRAGMA user_version = 9"
      via: "_setup_schema() auto-migration block"
      pattern: "version < 9"
    - from: "scripts/migrate_phase8.py"
      to: "data/library.db"
      via: "MIGR-04 state reset UPDATE"
      pattern: "gemini_state.*untracked"
---

<objective>
Add Gemini FSM state columns to the database schema and reset all uploaded files to `untracked` state, preparing the DB for the FSM-managed upload lifecycle.

Purpose: The DB must have the new columns before check_stability.py (08-03) can verify prerequisites, and before the store migration (08-02) makes sense. This is the foundation layer.

Output: V9 schema migration in database.py (auto-applied), standalone migration script for the destructive state reset, verified DB backup.
</objective>

<execution_context>
@/Users/david/.claude/get-shit-done/workflows/execute-plan.md
@/Users/david/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-store-migration-precondition/08-CONTEXT.md
@.planning/phases/08-store-migration-precondition/08-RESEARCH.md
@.planning/phases/08-store-migration-precondition/CLARIFICATIONS-ANSWERED.md
@src/objlib/database.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add V9 schema migration to database.py</name>
  <files>src/objlib/database.py</files>
  <action>
Add a `MIGRATION_V9_SQL` constant (comment-only, for documentation -- the actual migration uses ALTER TABLE statements). Then in `_setup_schema()`, after the existing `if version < 8:` block and before the `PRAGMA user_version = 8` line:

1. Add a new block:
```python
if version < 9:
    for alter_sql in [
        "ALTER TABLE files ADD COLUMN gemini_store_doc_id TEXT",
        "ALTER TABLE files ADD COLUMN gemini_state TEXT DEFAULT 'untracked'",
        "ALTER TABLE files ADD COLUMN gemini_state_updated_at TEXT",
    ]:
        try:
            self.conn.execute(alter_sql)
        except sqlite3.OperationalError:
            pass  # Column already exists
```

2. Change the final `PRAGMA user_version = 8` to `PRAGMA user_version = 9`.

3. Update the `_setup_schema()` docstring to include the v9 migration description:
   `- v9: gemini_store_doc_id, gemini_state, gemini_state_updated_at columns (Phase 8 FSM)`

This is the NON-DESTRUCTIVE part of the migration. It only adds columns with safe defaults. The state reset (MIGR-04) is handled by the separate migration script in Task 2.

Do NOT add a CHECK constraint on gemini_state -- the FSM in Phase 9+ will enforce valid transitions in application code. SQLite ALTER TABLE ADD COLUMN with CHECK is fragile.
  </action>
  <verify>
Run: `python -c "from objlib.database import Database; db = Database(':memory:'); cols = [r[1] for r in db.conn.execute('PRAGMA table_info(files)')]; assert 'gemini_store_doc_id' in cols; assert 'gemini_state' in cols; assert 'gemini_state_updated_at' in cols; v = db.conn.execute('PRAGMA user_version').fetchone()[0]; assert v == 9, f'Expected version 9, got {v}'; print('V9 schema OK')"`

Run existing tests: `python -m pytest tests/ -x -q` -- all tests must still pass (schema addition is backward-compatible).
  </verify>
  <done>
V9 schema migration auto-applies on DB open. Three new columns exist with correct types and defaults. PRAGMA user_version reads 9. All existing tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create scripts/migrate_phase8.py (state reset + backup)</name>
  <files>scripts/migrate_phase8.py</files>
  <action>
Create a standalone migration script at `scripts/migrate_phase8.py` with the following structure. This script handles MIGR-04 (destructive state reset) -- the part that MUST NOT be in auto-migration.

**Arguments:** `--db` (default: `data/library.db`), `--dry-run` (show what would change without executing), `--yes` (skip confirmation prompt)

**Script flow:**

1. **Check preconditions:**
   - Verify DB file exists at `--db` path
   - Open DB connection (which triggers V9 auto-migration from Task 1)
   - Run `PRAGMA user_version` -- must be >= 9 (if < 9, the auto-migration in database.py should have already run; if it hasn't, tell user to update code first)
   - Run `PRAGMA table_info(files)` -- confirm `gemini_state`, `gemini_store_doc_id`, `gemini_state_updated_at` columns exist
   - Check if migration already done: `SELECT COUNT(*) FROM files WHERE gemini_state != 'untracked' AND status = 'uploaded'` -- if 0, AND `SELECT COUNT(*) FROM files WHERE gemini_file_id IS NOT NULL AND status = 'uploaded'` is also 0, print "Migration already applied" and exit 0

2. **Backup:**
   - Run `PRAGMA wal_checkpoint(TRUNCATE)` to flush WAL to main file
   - Close the DB connection
   - `shutil.copy2('data/library.db', 'data/library.db.bak-phase8')`
   - Re-open DB connection
   - Run `PRAGMA integrity_check` -- must return "ok"

3. **Pre-migration snapshot (for verification):**
   - `pre_uploaded = SELECT COUNT(*) FROM files WHERE status='uploaded'`
   - `pre_null_metadata = SELECT COUNT(*) FROM files WHERE metadata_json IS NULL`
   - `pre_metadata_sample = SELECT file_path, LENGTH(metadata_json) FROM files WHERE metadata_json IS NOT NULL LIMIT 5`
   - `pre_entity_count = SELECT COUNT(*) FROM transcript_entity`

4. **Show summary and confirm:**
   - Print: "Files to reset: {pre_uploaded} (status='uploaded')"
   - Print: "Columns affected: gemini_state, gemini_store_doc_id, gemini_file_id, gemini_state_updated_at"
   - Print: "Columns PRESERVED: metadata_json, entity tables, all other columns"
   - If `--dry-run`: print "DRY RUN -- no changes made" and exit 0
   - If not `--yes`: prompt "Proceed? Type 'yes' to confirm: " -- only accept exact "yes"

5. **Execute MIGR-04 state reset:**
   ```python
   from datetime import datetime, timezone
   migration_ts = datetime.now(timezone.utc).isoformat()

   with conn:
       cursor = conn.execute(
           "UPDATE files SET gemini_state='untracked', gemini_store_doc_id=NULL, "
           "gemini_file_id=NULL, gemini_state_updated_at=? WHERE status='uploaded'",
           (migration_ts,)
       )
       rows_affected = cursor.rowcount
   ```

6. **Post-migration verification (CRITICAL -- verify sacred data untouched):**
   - `post_null_metadata = SELECT COUNT(*) FROM files WHERE metadata_json IS NULL` -- must equal `pre_null_metadata`
   - `post_entity_count = SELECT COUNT(*) FROM transcript_entity` -- must equal `pre_entity_count`
   - `post_metadata_sample` (same 5 files) -- LENGTH(metadata_json) must match pre values
   - `untracked_count = SELECT COUNT(*) FROM files WHERE gemini_state='untracked'` -- must be >= pre_uploaded
   - `stale_gemini_ids = SELECT COUNT(*) FROM files WHERE gemini_file_id IS NOT NULL AND status='uploaded'` -- must be 0
   - If any check fails: print "VERIFICATION FAILED" with details and exit 1

7. **Print summary:**
   - "{rows_affected} files reset to gemini_state='untracked'"
   - "gemini_file_id nulled for all uploaded files"
   - "AI metadata verified intact: {pre_entity_count} entity records, metadata_json unchanged"
   - "Migration timestamp: {migration_ts}"
   - "Backup at: data/library.db.bak-phase8"

Use `rich.console.Console` for output formatting and `rich.panel.Panel` for the summary box. Use `argparse` for CLI arguments (consistent with existing scripts/).

The script uses `if __name__ == '__main__': sys.exit(main())` pattern.

Import DB via `sys.path.insert(0, str(Path(__file__).parent.parent / "src"))` followed by `from objlib.database import Database` -- same pattern as existing `scripts/check_stability.py`.
  </action>
  <verify>
1. Run with `--dry-run` to verify it reads state correctly:
   `python scripts/migrate_phase8.py --dry-run`
   Expected: Shows file counts, prints "DRY RUN", exits 0.

2. Run for real (on the actual DB after confirming backup exists):
   `python scripts/migrate_phase8.py --yes`
   Expected: Resets uploaded files, prints verification summary, exits 0.

3. Verify backup exists:
   `ls -la data/library.db.bak-phase8`

4. Verify state reset:
   `python -c "import sqlite3; c=sqlite3.connect('data/library.db'); print(c.execute('SELECT COUNT(*) FROM files WHERE gemini_file_id IS NOT NULL AND status=\"uploaded\"').fetchone()[0])"` -- should print 0

5. Verify metadata preserved:
   `python -c "import sqlite3; c=sqlite3.connect('data/library.db'); print(c.execute('SELECT COUNT(*) FROM transcript_entity').fetchone()[0])"` -- should match pre-migration count

6. Re-run the script (idempotency check):
   `python scripts/migrate_phase8.py --yes`
   Expected: Prints "Migration already applied" and exits 0.
  </verify>
  <done>
The migration script creates a verified backup, resets all uploaded files to gemini_state='untracked' with NULL gemini_file_id and gemini_store_doc_id, confirms AI metadata is untouched, and is idempotent on re-run.
  </done>
</task>

</tasks>

<verification>
1. `PRAGMA user_version` returns 9
2. `PRAGMA table_info(files)` includes gemini_store_doc_id, gemini_state, gemini_state_updated_at
3. All files with status='uploaded' have gemini_state='untracked', gemini_file_id=NULL, gemini_store_doc_id=NULL
4. metadata_json column values are identical to pre-migration (verified by count of NULLs and sample LENGTH checks)
5. transcript_entity row count is identical to pre-migration
6. data/library.db.bak-phase8 exists
7. All existing tests pass: `python -m pytest tests/ -x -q`
8. `SELECT COUNT(*) FROM files WHERE gemini_state_updated_at IS NULL AND status='uploaded'` -- must return 0
</verification>

<success_criteria>
- V9 schema auto-migration adds 3 columns on any DB open
- Migration script resets all uploaded files and verifies metadata preservation
- Backup file exists before any destructive operation
- Script is idempotent on re-run
- All existing tests pass unchanged
</success_criteria>

<output>
After completion, create `.planning/phases/08-store-migration-precondition/08-01-SUMMARY.md`
</output>
