# Journal — 2026-02-26

## Overview

A session that began by completing the Phase 16.5 temporal gate (T+1h fresh-session
STABLE), then started Phase 16-02 (temporal stability protocol), and ended by
discovering and closing five structural enforcement gaps in the FSM upload pipeline.
The two critical gaps — identity headers never injected and AI metadata never loaded
in the production path — were dead code introduced when the FSM orchestrator was
written: it used `get_fsm_pending_files()` which never selected `ai_metadata_json`,
making the entire content-enrichment branch permanently unreachable. All five gaps
are now closed and the upload gate structurally enforces the invariants that
Phases 16.2–16.5 audit-verified.

---

## Starting Point

The session opened needing the T+1h fresh-session STABLE run for the Phase 16.5
gate. The T=0 run had completed at 2026-02-26 01:48 UTC (STABLE, 20/20 A7). This
session constituted the required fresh context. Ran `check_stability.py` immediately.

Phase 16.4 and 16.5 plans were complete; Phase 16-02 was the next blocking item.
Phase 16-02 is the full-library temporal stability protocol (T+4h, T+24h, T+36h).

---

## Root Cause Analysis

### Gaps 1+2: Identity header and AI content enrichment were dead code in the FSM path

**Observed:** A structural enforcement gap audit found that `build_identity_header()`
from `header_builder.py` was never called by `orchestrator.py`. The function exists
and was used correctly in standalone remediation scripts (`re_enrich_retrieval.py`,
`re_upload_phase164.py`). Separately, `prepare_enriched_content()` was also never
called in the FSM path.

**Expected:** Every file uploaded via `fsm-upload` should receive the identity header
(Title/Course/Class/Tags/Aspects) that Phase 16.3 introduced as the structural fix for
per-file retrieval discrimination. `prepare_enriched_content()` should prepend the
`[AI Analysis]` block to all files that have AI metadata.

**Causal chain:** The FSM upload path in `_upload_fsm_file()` checks
`file_info.get("ai_metadata_json")` before entering the content enrichment branch.
But `get_fsm_pending_files()` in `state.py` only selected 7 columns from the `files`
table — `file_path, content_hash, filename, file_size, metadata_json, version,
gemini_state` — and `ai_metadata_json` was not among them. So `file_info.get("ai_metadata_json")`
always returned `None`, the `if ai_json:` branch was never entered, and
`prepare_enriched_content()` was never called.

Separately, `build_identity_header()` was written in Phase 16.3 as the fix for class-number
file discrimination. It was wired into the Phase 16.3 standalone remediation script
(`re_enrich_retrieval.py`) but was never imported into or called from `orchestrator.py`.
The production FSM path was not modified when Phase 16.3 introduced the function.

**Why the current 1,749 files are correctly headed despite this gap:** Phase 16.3-03
executed a 7.5-hour re-upload of all 1,749 files using `re_enrich_retrieval.py`, which
explicitly called `build_identity_header()`. The production pipeline was never the
source of truth for the remediated files — the standalone script was. The gap would
have been discovered only when a new file was added to the corpus and uploaded via
`fsm-upload`, producing a file with no identity header that subsequently failed A7.

**Correct invariant:** `get_fsm_pending_files()` must JOIN `file_metadata_ai` to
populate `ai_metadata_json`. `_upload_fsm_file()` must call `build_identity_header()`
unconditionally for all approved files (not only those with AI metadata), because the
identity header's `Tags:` and `Aspects:` fields are derived from `file_primary_topics`
and `file_metadata_ai`, which are gated by the upload queue filter.

---

### Gap 3: COUNT(*) = 8 not verified at upload time

**Observed:** The upload gate SQL used `EXISTS (SELECT 1 FROM file_primary_topics WHERE ...)`
which checks for any rows, not exactly 8 rows. The `metadata audit` Condition 1 checks
"approved without any topics" but not "approved with exactly the wrong count."

**Causal chain:** The validator enforces count = 8 at extraction time. After approval,
nothing prevented DB row count manipulation from producing a file with 7 or 9 topics
that would still pass the gate and reach `indexed`.

**Correct invariant:** The upload gate SQL must use `COUNT(*) = 8` subquery rather than
`EXISTS`. This mirrors the validator's invariant at the gate level.

---

## Decisions Made

### Gap 4: topic_aspects absence treated as warning, not hard gate

**Decision:** `_upload_fsm_file()` logs a warning when `topic_aspects` is empty but
does not block the upload.

**Rejected alternative:** Hard gate in `get_fsm_pending_files()` requiring non-empty
`topic_aspects` in the JSON. Rejected because: (1) the validator already sets
`needs_review` for empty aspects, (2) manual approval can legitimately override this
for files where aspects are genuinely not extractable, (3) adding a JSON parse in
the gate SQL adds complexity without clear benefit given the soft warning already
channels such files through `needs_review`.

**Stable:** Yes — the warning ensures operators see the degraded state in logs.
A7 acts as the correctness check: if a file is uploaded without aspects and
becomes un-retrievable, A7 will catch it in the next stability run.

### Gap 5: Post-upload retrievability check treated as log reminder, not automated hook

**Decision:** `run_fsm()` logs the `check_stability.py` command after every successful
upload wave. No pre-upload blocking gate or automated post-upload execution.

**Rejected alternatives:**
- Pre-upload gate blocking `run_fsm()` if the last A7 run was UNSTABLE: rejected because
  `run_fsm()` has no access to the prior check_stability result, and adding this coupling
  would require persisting check results to the DB.
- Auto-run `check_stability` after every upload: rejected because it adds 2–3 minutes
  to every upload run and complicates the orchestrator's async structure.

**Stable:** Yes for now. If a future phase adds CI or a post-upload hook system, this
reminder log becomes the documentation of intent.

---

## Current State

| Property | Value | Cause |
|---|---|---|
| DB indexed | 1,749 | Full library uploaded via Phase 16.3-03 remediation |
| Store docs | 1,749 | store-sync confirmed clean after each phase |
| Phase 16.5 gate | PASSED | T=0 (01:48 UTC) + T+1h (01:58 UTC) both STABLE 7/7, A7 20/20, no exclusions |
| Phase 16.4 | COMPLETE | 16.4-04 superseded by Phase 16.5; gate delivered by 16.5 |
| Phase 16.5 | COMPLETE | All 4 plans done; zero-tolerance A7 confirmed with S4a fallback |
| Phase 16-02 | IN PROGRESS | T=0 re-baselined 2026-02-26 01:48 UTC; T+4h ~05:48, T+24h ~01:48 tomorrow |
| Identity header gate | ENFORCED | `build_identity_header()` now wired into `_upload_fsm_file()` |
| AI metadata content gate | ENFORCED | `get_fsm_pending_files()` now JOINs `file_metadata_ai`; `ai_metadata_json` populated |
| primary_topics count gate | COUNT = 8 | Upload SQL now uses `COUNT(*) = 8` subquery instead of `EXISTS` |
| topic_aspects gate | WARNING | Logs warning on empty aspects; upload proceeds; A7 is correctness check |
| Post-upload reminder | LOG | `run_fsm()` logs `check_stability` command after successful uploads |
| Existing 1,749 indexed files | Correctly headed | Were uploaded by Phase 16.3-03 standalone script, not the FSM path |
| New files added going forward | Will receive headers | FSM path now wired correctly |

---

## Files Changed

| File | Change |
|------|--------|
| `src/objlib/upload/state.py` | `get_fsm_pending_files()`: LEFT JOIN `file_metadata_ai` to populate `ai_metadata_json`; COUNT(*) = 8 gate replacing EXISTS gate |
| `src/objlib/upload/orchestrator.py` | Imports: added `sqlite3`, `tempfile`, `Path`, `build_identity_header`. `_upload_fsm_file()`: wired identity header injection via sync sqlite connection + second temp file; added empty-aspects warning. `run_fsm()`: added post-upload check_stability reminder log |
| `.planning/STATE.md` | Phase 16.4 COMPLETE, Phase 16.5 COMPLETE, Phase 16-02 UNBLOCKED; temporal stability log entries; plan count 36/42 |
| `.planning/phases/16-full-library-upload/16-02-SUMMARY.md` | Created; T=0 baseline recorded; T+4h/T+24h/T+36h schedule documented |
| `~/.claude/projects/.../memory/MEMORY.md` | Store name corrected from `objectivism-library-test` to `objectivism-library` |

---

## Lessons Learned

- **The FSM path and the remediation scripts are different code paths that diverge silently.** Phase 16.3 fixed retrieval by adding `build_identity_header()` to a standalone remediation script. The production FSM path was never updated. This gap would have been invisible until the next corpus addition — a new file uploaded via `fsm-upload` would have had no identity header and likely failed A7. Lesson: when a production fix requires a content format change, the production upload path must be updated at the same time the remediation script runs. The remediation script is not a substitute for fixing the pipeline.

- **`get_fsm_pending_files()` is the structural gate for all upload-path invariants.** Any column needed by `_upload_fsm_file()` must be in the SELECT. If a column is missing from the query, `file_info.get(...)` returns `None` silently, and branches that check for it are permanently dead code with no error or warning. The gap is undetectable until a structural audit or a new-file failure.

- **Audit-verified state and structurally-enforced state are not the same guarantee.** Phases 16.2–16.5 confirmed that all 1,749 files satisfied the invariants at a point in time. But the pipeline had not been updated to enforce those invariants going forward. The audit result is historical; enforcement is what makes it future-proof. Both are necessary.

- **Audit gap maps are worth running before declaring a phase series complete.** The gap map (run via Explore agent against the upload pipeline) took ~4 minutes and found two critical dead-code gaps that would have degraded all future uploads. This would not have been caught by stability checks on the existing 1,749 files — only by uploading a new file and observing the failure.
