Mistral Batch API Extraction
Database: data/library.db
Poll interval: 30s

Starting batch extraction...
DEBUG: About to call asyncio.run()
DEBUG: Loading pending files...
DEBUG: Got 124 pending files
DEBUG: Building batch requests...
DEBUG: Processing file 1/124
DEBUG: Processing file 2/124
DEBUG: Processing file 3/124
DEBUG: Processing file 4/124
DEBUG: Processing file 5/124
DEBUG: Processing file 6/124
DEBUG: Processing file 7/124
DEBUG: Processing file 8/124
DEBUG: Processing file 9/124
DEBUG: Processing file 10/124
DEBUG: Processing file 11/124
DEBUG: Processing file 12/124
DEBUG: Processing file 13/124
DEBUG: Processing file 14/124
DEBUG: Processing file 15/124
DEBUG: Processing file 16/124
DEBUG: Processing file 17/124
DEBUG: Processing file 18/124
DEBUG: Processing file 19/124
DEBUG: Processing file 20/124
DEBUG: Processing file 21/124
DEBUG: Processing file 22/124
DEBUG: Processing file 23/124
DEBUG: Processing file 24/124
DEBUG: Processing file 25/124
DEBUG: Processing file 26/124
DEBUG: Processing file 27/124
DEBUG: Processing file 28/124
DEBUG: Processing file 29/124
DEBUG: Processing file 30/124
DEBUG: Processing file 31/124
DEBUG: Processing file 32/124
DEBUG: Processing file 33/124
DEBUG: Processing file 34/124
DEBUG: Processing file 35/124
DEBUG: Processing file 36/124
DEBUG: Processing file 37/124
DEBUG: Processing file 38/124
DEBUG: Processing file 39/124
DEBUG: Processing file 40/124
DEBUG: Processing file 41/124
DEBUG: Processing file 42/124
DEBUG: Processing file 43/124
DEBUG: Processing file 44/124
DEBUG: Processing file 45/124
DEBUG: Processing file 46/124
DEBUG: Processing file 47/124
DEBUG: Processing file 48/124
DEBUG: Processing file 49/124
DEBUG: Processing file 50/124
DEBUG: Processing file 51/124
DEBUG: Processing file 52/124
DEBUG: Processing file 53/124
DEBUG: Processing file 54/124
DEBUG: Processing file 55/124
DEBUG: Processing file 56/124
DEBUG: Processing file 57/124
DEBUG: Processing file 58/124
DEBUG: Processing file 59/124
DEBUG: Processing file 60/124
DEBUG: Processing file 61/124
DEBUG: Processing file 62/124
DEBUG: Processing file 63/124
DEBUG: Processing file 64/124
DEBUG: Processing file 65/124
DEBUG: Processing file 66/124
DEBUG: Processing file 67/124
DEBUG: Processing file 68/124
DEBUG: Processing file 69/124
DEBUG: Processing file 70/124
DEBUG: Processing file 71/124
DEBUG: Processing file 72/124
DEBUG: Processing file 73/124
DEBUG: Processing file 74/124
DEBUG: Processing file 75/124
DEBUG: Processing file 76/124
DEBUG: Processing file 77/124
DEBUG: Processing file 78/124
DEBUG: Processing file 79/124
DEBUG: Processing file 80/124
DEBUG: Processing file 81/124
DEBUG: Processing file 82/124
DEBUG: Processing file 83/124
DEBUG: Processing file 84/124
DEBUG: Processing file 85/124
DEBUG: Processing file 86/124
DEBUG: Processing file 87/124
DEBUG: Processing file 88/124
DEBUG: Processing file 89/124
DEBUG: Processing file 90/124
DEBUG: Processing file 91/124
DEBUG: Processing file 92/124
DEBUG: Processing file 93/124
DEBUG: Processing file 94/124
DEBUG: Processing file 95/124
DEBUG: Processing file 96/124
DEBUG: Processing file 97/124
DEBUG: Processing file 98/124
DEBUG: Processing file 99/124
DEBUG: Processing file 100/124
DEBUG: Processing file 101/124
DEBUG: Processing file 102/124
DEBUG: Processing file 103/124
DEBUG: Processing file 104/124
DEBUG: Processing file 105/124
DEBUG: Processing file 106/124
DEBUG: Processing file 107/124
DEBUG: Processing file 108/124
DEBUG: Processing file 109/124
DEBUG: Processing file 110/124
DEBUG: Processing file 111/124
DEBUG: Processing file 112/124
DEBUG: Processing file 113/124
DEBUG: Processing file 114/124
DEBUG: Processing file 115/124
DEBUG: Processing file 116/124
DEBUG: Processing file 117/124
DEBUG: Processing file 118/124
DEBUG: Processing file 119/124
DEBUG: Processing file 120/124
DEBUG: Processing file 121/124
DEBUG: Processing file 122/124
DEBUG: Processing file 123/124
DEBUG: Processing file 124/124
DEBUG: About to submit 124 requests...
DEBUG: Batch submitted, ID: 494800e7-e49b-4231-820b-1aab129d04fe
DEBUG: Starting to poll (interval=30s)...
DEBUG: Checking status (elapsed=0s, interval=30s)...
DEBUG: Got status: RUNNING
DEBUG: Checking status (elapsed=30s, interval=45s)...
DEBUG: Got status: RUNNING
DEBUG: Checking status (elapsed=75s, interval=67s)...
DEBUG: Got status: RUNNING
DEBUG: Checking status (elapsed=142s, interval=100s)...
DEBUG: Got status: RUNNING
DEBUG: Checking status (elapsed=242s, interval=120s)...
DEBUG: Got status: RUNNING
DEBUG: Checking status (elapsed=362s, interval=120s)...
DEBUG: Got status: RUNNING
DEBUG: Checking status (elapsed=482s, interval=120s)...
DEBUG: Got status: RUNNING
DEBUG: Checking status (elapsed=602s, interval=120s)...
DEBUG: Got status: RUNNING
DEBUG: Checking status (elapsed=722s, interval=120s)...
DEBUG: Got status: RUNNING
DEBUG: Checking status (elapsed=842s, interval=120s)...
DEBUG: Got status: RUNNING
DEBUG: Checking status (elapsed=962s, interval=120s)...
DEBUG: Got status: SUCCESS
DEBUG: Polling completed, status: {'id': '494800e7-e49b-4231-820b-1aab129d04fe', 'status': 'SUCCESS', 'model': 'magistral-medium-latest', 'created_at': 1771348856, 'started_at': 1771348856, 'completed_at': 1771349724, 'total_requests': 124, 'succeeded_requests': 124, 'failed_requests': 0, 'metadata': {'strategy': 'minimalist'}}
Failed to process result for /Volumes/U32 Shadow/Objectivism Library/Courses/ITOE Advanced Topics/ITOE Advanced Topics - Class 15-01.txt: No valid JSON found in response
Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]Loading weights:   1%|          | 1/103 [00:00<00:00, 4100.00it/s, Materializing param=embeddings.LayerNorm.bias]Loading weights:   1%|          | 1/103 [00:00<00:00, 3366.22it/s, Materializing param=embeddings.LayerNorm.bias]Loading weights:   2%|â–         | 2/103 [00:00<00:00, 2226.87it/s, Materializing param=embeddings.LayerNorm.weight]Loading weights:   2%|â–         | 2/103 [00:00<00:00, 2078.96it/s, Materializing param=embeddings.LayerNorm.weight]Loading weights:   3%|â–Ž         | 3/103 [00:00<00:00, 1958.13it/s, Materializing param=embeddings.position_embeddings.weight]Loading weights:   3%|â–Ž         | 3/103 [00:00<00:00, 1915.79it/s, Materializing param=embeddings.position_embeddings.weight]Loading weights:   4%|â–         | 4/103 [00:00<00:00, 2352.72it/s, Materializing param=embeddings.token_type_embeddings.weight]Loading weights:   4%|â–         | 4/103 [00:00<00:00, 2318.58it/s, Materializing param=embeddings.token_type_embeddings.weight]Loading weights:   5%|â–         | 5/103 [00:00<00:00, 2826.35it/s, Materializing param=embeddings.word_embeddings.weight]      Loading weights:   5%|â–         | 5/103 [00:00<00:00, 2790.25it/s, Materializing param=embeddings.word_embeddings.weight]Loading weights:   6%|â–Œ         | 6/103 [00:00<00:00, 3269.56it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]Loading weights:   6%|â–Œ         | 6/103 [00:00<00:00, 3229.29it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]Loading weights:   7%|â–‹         | 7/103 [00:00<00:00, 3619.35it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]Loading weights:   7%|â–‹         | 7/103 [00:00<00:00, 3578.32it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]Loading weights:   8%|â–Š         | 8/103 [00:00<00:00, 3995.53it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]      Loading weights:   8%|â–Š         | 8/103 [00:00<00:00, 3952.23it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]Loading weights:   9%|â–Š         | 9/103 [00:00<00:00, 4349.94it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]Loading weights:   9%|â–Š         | 9/103 [00:00<00:00, 4308.23it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]Loading weights:  10%|â–‰         | 10/103 [00:00<00:00, 4688.47it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     Loading weights:  10%|â–‰         | 10/103 [00:00<00:00, 4642.28it/s, Materializing param=encoder.layer.0.attention.self.key.bias]Loading weights:  11%|â–ˆ         | 11/103 [00:00<00:00, 5008.94it/s, Materializing param=encoder.layer.0.attention.self.key.weight]Loading weights:  11%|â–ˆ         | 11/103 [00:00<00:00, 4963.67it/s, Materializing param=encoder.layer.0.attention.self.key.weight]Loading weights:  12%|â–ˆâ–        | 12/103 [00:00<00:00, 5313.73it/s, Materializing param=encoder.layer.0.attention.self.query.bias]Loading weights:  12%|â–ˆâ–        | 12/103 [00:00<00:00, 5267.57it/s, Materializing param=encoder.layer.0.attention.self.query.bias]Loading weights:  13%|â–ˆâ–Ž        | 13/103 [00:00<00:00, 5001.46it/s, Materializing param=encoder.layer.0.attention.self.query.weight]Loading weights:  13%|â–ˆâ–Ž        | 13/103 [00:00<00:00, 4922.00it/s, Materializing param=encoder.layer.0.attention.self.query.weight]Loading weights:  14%|â–ˆâ–Ž        | 14/103 [00:00<00:00, 5185.01it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  Loading weights:  14%|â–ˆâ–Ž        | 14/103 [00:00<00:00, 5133.34it/s, Materializing param=encoder.layer.0.attention.self.value.bias]Loading weights:  15%|â–ˆâ–        | 15/103 [00:00<00:00, 5358.99it/s, Materializing param=encoder.layer.0.attention.self.value.weight]Loading weights:  15%|â–ˆâ–        | 15/103 [00:00<00:00, 5298.07it/s, Materializing param=encoder.layer.0.attention.self.value.weight]Loading weights:  16%|â–ˆâ–Œ        | 16/103 [00:00<00:00, 5494.42it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]    Loading weights:  16%|â–ˆâ–Œ        | 16/103 [00:00<00:00, 5414.63it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]Loading weights:  17%|â–ˆâ–‹        | 17/103 [00:00<00:00, 5546.29it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]Loading weights:  17%|â–ˆâ–‹        | 17/103 [00:00<00:00, 5497.97it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]Loading weights:  17%|â–ˆâ–‹        | 18/103 [00:00<00:00, 5736.02it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    Loading weights:  17%|â–ˆâ–‹        | 18/103 [00:00<00:00, 5692.34it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]Loading weights:  18%|â–ˆâ–Š        | 19/103 [00:00<00:00, 5259.84it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]Loading weights:  18%|â–ˆâ–Š        | 19/103 [00:00<00:00, 5225.69it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]Loading weights:  19%|â–ˆâ–‰        | 20/103 [00:00<00:00, 4623.10it/s, Materializing param=encoder.layer.0.output.dense.bias]      Loading weights:  19%|â–ˆâ–‰        | 20/103 [00:00<00:00, 4598.51it/s, Materializing param=encoder.layer.0.output.dense.bias]Loading weights:  20%|â–ˆâ–ˆ        | 21/103 [00:00<00:00, 4782.30it/s, Materializing param=encoder.layer.0.output.dense.weight]Loading weights:  20%|â–ˆâ–ˆ        | 21/103 [00:00<00:00, 4759.56it/s, Materializing param=encoder.layer.0.output.dense.weight]Loading weights:  21%|â–ˆâ–ˆâ–       | 22/103 [00:00<00:00, 4941.61it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]Loading weights:  21%|â–ˆâ–ˆâ–       | 22/103 [00:00<00:00, 4917.12it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]Loading weights:  22%|â–ˆâ–ˆâ–       | 23/103 [00:00<00:00, 4836.75it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]Loading weights:  22%|â–ˆâ–ˆâ–       | 23/103 [00:00<00:00, 4793.49it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 24/103 [00:00<00:00, 4699.28it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]      Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 24/103 [00:00<00:00, 4673.75it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]Loading weights:  24%|â–ˆâ–ˆâ–       | 25/103 [00:00<00:00, 4669.47it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]Loading weights:  24%|â–ˆâ–ˆâ–       | 25/103 [00:00<00:00, 4645.06it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 26/103 [00:00<00:00, 4789.07it/s, Materializing param=encoder.layer.1.attention.self.key.bias]      Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 26/103 [00:00<00:00, 4767.92it/s, Materializing param=encoder.layer.1.attention.self.key.bias]Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 27/103 [00:00<00:00, 4904.56it/s, Materializing param=encoder.layer.1.attention.self.key.weight]Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 27/103 [00:00<00:00, 4885.94it/s, Materializing param=encoder.layer.1.attention.self.key.weight]Loading weights:  27%|â–ˆâ–ˆâ–‹       | 28/103 [00:00<00:00, 5011.54it/s, Materializing param=encoder.layer.1.attention.self.query.bias]Loading weights:  27%|â–ˆâ–ˆâ–‹       | 28/103 [00:00<00:00, 4993.64it/s, Materializing param=encoder.layer.1.attention.self.query.bias]Loading weights:  28%|â–ˆâ–ˆâ–Š       | 29/103 [00:00<00:00, 5135.30it/s, Materializing param=encoder.layer.1.attention.self.query.weight]Loading weights:  28%|â–ˆâ–ˆâ–Š       | 29/103 [00:00<00:00, 5115.44it/s, Materializing param=encoder.layer.1.attention.self.query.weight]Loading weights:  29%|â–ˆâ–ˆâ–‰       | 30/103 [00:00<00:00, 5250.10it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  Loading weights:  29%|â–ˆâ–ˆâ–‰       | 30/103 [00:00<00:00, 5228.28it/s, Materializing param=encoder.layer.1.attention.self.value.bias]Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 31/103 [00:00<00:00, 5345.48it/s, Materializing param=encoder.layer.1.attention.self.value.weight]Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 31/103 [00:00<00:00, 5324.46it/s, Materializing param=encoder.layer.1.attention.self.value.weight]Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 32/103 [00:00<00:00, 4887.04it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 32/103 [00:00<00:00, 4869.14it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 33/103 [00:00<00:00, 4966.17it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 33/103 [00:00<00:00, 4950.54it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 34/103 [00:00<00:00, 5070.63it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 34/103 [00:00<00:00, 5055.71it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 35/103 [00:00<00:00, 5172.13it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 35/103 [00:00<00:00, 5157.60it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 36/103 [00:00<00:00, 5276.22it/s, Materializing param=encoder.layer.1.output.dense.bias]      Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 36/103 [00:00<00:00, 5260.78it/s, Materializing param=encoder.layer.1.output.dense.bias]Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/103 [00:00<00:00, 5292.41it/s, Materializing param=encoder.layer.1.output.dense.weight]Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/103 [00:00<00:00, 5272.09it/s, Materializing param=encoder.layer.1.output.dense.weight]Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 38/103 [00:00<00:00, 4914.69it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 38/103 [00:00<00:00, 4900.64it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 39/103 [00:00<00:00, 5001.31it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 39/103 [00:00<00:00, 4988.50it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 40/103 [00:00<00:00, 5075.55it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 40/103 [00:00<00:00, 5063.14it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 41/103 [00:00<00:00, 5164.31it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 41/103 [00:00<00:00, 5152.09it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/103 [00:00<00:00, 5216.18it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/103 [00:00<00:00, 5201.85it/s, Materializing param=encoder.layer.2.attention.self.key.bias]Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/103 [00:00<00:00, 5298.64it/s, Materializing param=encoder.layer.2.attention.self.key.weight]Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/103 [00:00<00:00, 5286.37it/s, Materializing param=encoder.layer.2.attention.self.key.weight]Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 44/103 [00:00<00:00, 5384.22it/s, Materializing param=encoder.layer.2.attention.self.query.bias]Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 44/103 [00:00<00:00, 5371.05it/s, Materializing param=encoder.layer.2.attention.self.query.bias]Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 45/103 [00:00<00:00, 4909.96it/s, Materializing param=encoder.layer.2.attention.self.query.weight]Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 45/103 [00:00<00:00, 4895.44it/s, Materializing param=encoder.layer.2.attention.self.query.weight]Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/103 [00:00<00:00, 4979.43it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/103 [00:00<00:00, 4968.15it/s, Materializing param=encoder.layer.2.attention.self.value.bias]Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47/103 [00:00<00:00, 5052.60it/s, Materializing param=encoder.layer.2.attention.self.value.weight]Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47/103 [00:00<00:00, 5041.23it/s, Materializing param=encoder.layer.2.attention.self.value.weight]Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 48/103 [00:00<00:00, 5126.47it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 48/103 [00:00<00:00, 5113.97it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 49/103 [00:00<00:00, 4545.41it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 49/103 [00:00<00:00, 4533.68it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/103 [00:00<00:00, 4609.13it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/103 [00:00<00:00, 4600.63it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51/103 [00:00<00:00, 4675.82it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51/103 [00:00<00:00, 4667.76it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/103 [00:00<00:00, 4742.83it/s, Materializing param=encoder.layer.2.output.dense.bias]      Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/103 [00:00<00:00, 4734.49it/s, Materializing param=encoder.layer.2.output.dense.bias]Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/103 [00:00<00:00, 4808.53it/s, Materializing param=encoder.layer.2.output.dense.weight]Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/103 [00:00<00:00, 4800.32it/s, Materializing param=encoder.layer.2.output.dense.weight]Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/103 [00:00<00:00, 4872.80it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/103 [00:00<00:00, 4864.01it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 55/103 [00:00<00:00, 4935.00it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 55/103 [00:00<00:00, 4926.47it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/103 [00:00<00:00, 4991.42it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/103 [00:00<00:00, 4983.05it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57/103 [00:00<00:00, 5054.98it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57/103 [00:00<00:00, 5046.02it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 58/103 [00:00<00:00, 5117.26it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 58/103 [00:00<00:00, 5108.77it/s, Materializing param=encoder.layer.3.attention.self.key.bias]Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 59/103 [00:00<00:00, 5062.58it/s, Materializing param=encoder.layer.3.attention.self.key.weight]Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 59/103 [00:00<00:00, 5050.90it/s, Materializing param=encoder.layer.3.attention.self.key.weight]Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 60/103 [00:00<00:00, 5116.77it/s, Materializing param=encoder.layer.3.attention.self.query.bias]Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 60/103 [00:00<00:00, 5107.63it/s, Materializing param=encoder.layer.3.attention.self.query.bias]Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 4815.23it/s, Materializing param=encoder.layer.3.attention.self.query.weight]Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 4801.68it/s, Materializing param=encoder.layer.3.attention.self.query.weight]Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 62/103 [00:00<00:00, 4860.05it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 62/103 [00:00<00:00, 4851.35it/s, Materializing param=encoder.layer.3.attention.self.value.bias]Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/103 [00:00<00:00, 4912.28it/s, Materializing param=encoder.layer.3.attention.self.value.weight]Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/103 [00:00<00:00, 4903.80it/s, Materializing param=encoder.layer.3.attention.self.value.weight]Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/103 [00:00<00:00, 4965.42it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/103 [00:00<00:00, 4957.35it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 65/103 [00:00<00:00, 4953.48it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 65/103 [00:00<00:00, 4945.22it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/103 [00:00<00:00, 5006.77it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/103 [00:00<00:00, 4999.17it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67/103 [00:00<00:00, 5060.02it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67/103 [00:00<00:00, 5052.74it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68/103 [00:00<00:00, 5114.27it/s, Materializing param=encoder.layer.3.output.dense.bias]      Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68/103 [00:00<00:00, 5106.95it/s, Materializing param=encoder.layer.3.output.dense.bias]Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 69/103 [00:00<00:00, 5167.43it/s, Materializing param=encoder.layer.3.output.dense.weight]Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 69/103 [00:00<00:00, 5159.97it/s, Materializing param=encoder.layer.3.output.dense.weight]Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70/103 [00:00<00:00, 5220.78it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70/103 [00:00<00:00, 5213.00it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 71/103 [00:00<00:00, 5271.65it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 71/103 [00:00<00:00, 5264.29it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72/103 [00:00<00:00, 5058.63it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72/103 [00:00<00:00, 5050.08it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 73/103 [00:00<00:00, 5104.43it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 73/103 [00:00<00:00, 5096.95it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/103 [00:00<00:00, 5151.68it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/103 [00:00<00:00, 5144.17it/s, Materializing param=encoder.layer.4.attention.self.key.bias]Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 75/103 [00:00<00:00, 5199.29it/s, Materializing param=encoder.layer.4.attention.self.key.weight]Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 75/103 [00:00<00:00, 5192.08it/s, Materializing param=encoder.layer.4.attention.self.key.weight]Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 5247.20it/s, Materializing param=encoder.layer.4.attention.self.query.bias]Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 5239.86it/s, Materializing param=encoder.layer.4.attention.self.query.bias]Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/103 [00:00<00:00, 5294.97it/s, Materializing param=encoder.layer.4.attention.self.query.weight]Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/103 [00:00<00:00, 5287.00it/s, Materializing param=encoder.layer.4.attention.self.query.weight]Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 78/103 [00:00<00:00, 5340.27it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 78/103 [00:00<00:00, 5332.61it/s, Materializing param=encoder.layer.4.attention.self.value.bias]Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 79/103 [00:00<00:00, 5385.44it/s, Materializing param=encoder.layer.4.attention.self.value.weight]Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 79/103 [00:00<00:00, 5377.75it/s, Materializing param=encoder.layer.4.attention.self.value.weight]Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 80/103 [00:00<00:00, 5431.72it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 80/103 [00:00<00:00, 5423.99it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 81/103 [00:00<00:00, 5477.71it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 81/103 [00:00<00:00, 5470.74it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 82/103 [00:00<00:00, 5279.42it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 82/103 [00:00<00:00, 5271.25it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 83/103 [00:00<00:00, 5320.85it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 83/103 [00:00<00:00, 5313.30it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/103 [00:00<00:00, 5363.23it/s, Materializing param=encoder.layer.4.output.dense.bias]      Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/103 [00:00<00:00, 5356.47it/s, Materializing param=encoder.layer.4.output.dense.bias]Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 85/103 [00:00<00:00, 5406.75it/s, Materializing param=encoder.layer.4.output.dense.weight]Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 85/103 [00:00<00:00, 5400.20it/s, Materializing param=encoder.layer.4.output.dense.weight]Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 86/103 [00:00<00:00, 5450.93it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 86/103 [00:00<00:00, 5444.11it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/103 [00:00<00:00, 5490.26it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/103 [00:00<00:00, 5483.41it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 88/103 [00:00<00:00, 5531.81it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 88/103 [00:00<00:00, 5525.18it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 89/103 [00:00<00:00, 5408.32it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 89/103 [00:00<00:00, 5401.75it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90/103 [00:00<00:00, 5423.28it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90/103 [00:00<00:00, 5414.49it/s, Materializing param=encoder.layer.5.attention.self.key.bias]Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91/103 [00:00<00:00, 5459.15it/s, Materializing param=encoder.layer.5.attention.self.key.weight]Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91/103 [00:00<00:00, 5452.67it/s, Materializing param=encoder.layer.5.attention.self.key.weight]Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 92/103 [00:00<00:00, 5499.08it/s, Materializing param=encoder.layer.5.attention.self.query.bias]Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 92/103 [00:00<00:00, 5492.51it/s, Materializing param=encoder.layer.5.attention.self.query.bias]Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 93/103 [00:00<00:00, 5531.73it/s, Materializing param=encoder.layer.5.attention.self.query.weight]Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 93/103 [00:00<00:00, 5525.15it/s, Materializing param=encoder.layer.5.attention.self.query.weight]Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/103 [00:00<00:00, 5521.91it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/103 [00:00<00:00, 5515.73it/s, Materializing param=encoder.layer.5.attention.self.value.bias]Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 95/103 [00:00<00:00, 5562.35it/s, Materializing param=encoder.layer.5.attention.self.value.weight]Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 95/103 [00:00<00:00, 5556.22it/s, Materializing param=encoder.layer.5.attention.self.value.weight]Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 96/103 [00:00<00:00, 5602.52it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 96/103 [00:00<00:00, 5596.37it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/103 [00:00<00:00, 5640.48it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/103 [00:00<00:00, 5634.30it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 98/103 [00:00<00:00, 5588.15it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 98/103 [00:00<00:00, 5582.15it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 99/103 [00:00<00:00, 5626.58it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 99/103 [00:00<00:00, 5620.49it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100/103 [00:00<00:00, 5653.84it/s, Materializing param=encoder.layer.5.output.dense.bias]     Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100/103 [00:00<00:00, 5648.13it/s, Materializing param=encoder.layer.5.output.dense.bias]Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 101/103 [00:00<00:00, 5694.57it/s, Materializing param=encoder.layer.5.output.dense.weight]Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 101/103 [00:00<00:00, 5688.83it/s, Materializing param=encoder.layer.5.output.dense.weight]Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 102/103 [00:00<00:00, 5735.15it/s, Materializing param=pooler.dense.bias]                  Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 102/103 [00:00<00:00, 5729.39it/s, Materializing param=pooler.dense.bias]Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 5775.81it/s, Materializing param=pooler.dense.weight]Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 5769.95it/s, Materializing param=pooler.dense.weight]Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 5751.28it/s, Materializing param=pooler.dense.weight]
[1mBertModel LOAD REPORT[0m from: sentence-transformers/all-MiniLM-L6-v2
Key                     | Status     |  | 
------------------------+------------+--+-
embeddings.position_ids | UNEXPECTED |  | 

[3mNotes:
- UNEXPECTED[3m	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.[0m
Failed to process result for /Volumes/U32 Shadow/Objectivism Library/Courses/Objectivism Seminar - Foundations/Year1/Q2/Objectivism Seminar - Foundations - Year 1 - Q2 - Week 7 - Idealism and Arguments for the Existence of God Discussion â€“ Group B.txt: No valid JSON found in response
Hard validation failures for /Volumes/U32 Shadow/Objectivism Library/Courses/Objectivism Seminar - Foundations/Year2/Q4/Objectivism Seminar - Foundations - Year 2 - Q4 - Week 2 - Capitalism [contâ€™d]; War and foreign policy capitalism and a mixed economy.txt: ['confidence_score is missing or not a number']
Failed to process result for /Volumes/U32 Shadow/Objectivism Library/Courses/Objectivism Through Induction/Objectivism Through Induction - Lesson 01 - An Inductive Approach to Philosophy.txt: No valid JSON found in response
Mistral returned JSON array instead of object. Array length: 7. Content preview:  
["course_transcript","book_excerpt","qa_session","article","philosophy_comparison","concept_exploration","cultural_commentary"]
Failed to process result for /Volumes/U32 Shadow/Objectivism Library/Courses/Objectivism Through Induction/Objectivism Through Induction - Lesson 08 - The Evil of Initiating Physical Force.txt: Mistral returned JSON array with 7 elements instead of JSON object. This violates response_format constraint.
Hard validation failures for /Volumes/U32 Shadow/Objectivism Library/Courses/Philosophy of Education/Philosophy of Education - Lesson 02 - How to Teach Proper Thinking Methods.txt: ['confidence_score is missing or not a number']
Hard validation failures for /Volumes/U32 Shadow/Objectivism Library/Courses/Principles of Grammar/Principles of Grammar - Lesson 02 - Subordination and Coordination Part 1.txt: ['confidence_score is missing or not a number']
Mistral returned JSON array instead of object. Array length: 1. Content preview: [{ "facts": [], "sentences": [], "type": "cultural_commentary" }]
Hard validation failures for /Volumes/U32 Shadow/Objectivism Library/Courses/Rationality and Objectivity/Rationality and Objectivity - Lesson 01 - Introduction to Rationality and Objectivity.txt: ["Invalid difficulty: ''. Must be one of: ['advanced', 'intermediate', 'intro']", 'primary_topics: must be exactly 8 topics (found 0). Semantic normalization should have corrected this. Valid: []', 'confidence_score is missing or not a number']
Mistral returned JSON array instead of object. Array length: 2. Content preview: [20231028     , 20231028 ]
Failed to process result for /Volumes/U32 Shadow/Objectivism Library/Courses/The Atlas Project/The Atlas Project - Lesson 09 - Part I Chapter 9 - The Sacred and the Profane.txt: Mistral returned JSON array with 2 elements instead of JSON object. This violates response_format constraint.
Hard validation failures for /Volumes/U32 Shadow/Objectivism Library/Courses/The Atlas Project/The Atlas Project - Lesson 29 - Part III Chapter 8 - The Egoist.txt: ['confidence_score is missing or not a number']
Hard validation failures for /Volumes/U32 Shadow/Objectivism Library/Courses/Writing_ A Mini-Course/Writing_ A Mini-Course - Lesson 01 - Writing, Part 1.txt: ['confidence_score is missing or not a number']
Hard validation failures for /Volumes/U32 Shadow/Objectivism Library/MOTM/MOTM_2016-10-23_Ellen-Kenner-10.txt: ['confidence_score is missing or not a number']
Hard validation failures for /Volumes/U32 Shadow/Objectivism Library/MOTM/MOTM_2017-04-02_Sunday-Brunch-at-HBL-Political-Reactions-Labels-and-Moral-Certainty-Dealing-with-the-altruist.txt: ['confidence_score is missing or not a number']
Hard validation failures for /Volumes/U32 Shadow/Objectivism Library/MOTM/MOTM_2018-01-14_Sunday-Brunch-at-HBL-Introspection-and-the-hierarchy-of-concepts-it-involves.txt: ['confidence_score is missing or not a number']
Hard validation failures for /Volumes/U32 Shadow/Objectivism Library/MOTM/MOTM_2020-01-12_Interview-with-Raymond-Niles.txt: ['confidence_score is missing or not a number']
Hard validation failures for /Volumes/U32 Shadow/Objectivism Library/MOTM/MOTM_2021-12-19_Harry-Binswanger-Interviews-Jean-Moroney-about-Central-Purpose.txt: ['confidence_score is missing or not a number']
Hard validation failures for /Volumes/U32 Shadow/Objectivism Library/MOTM/MOTM_2022-08-14_Peter-Schwartz-Interview.txt: ['confidence_score is missing or not a number']
Hard validation failures for /Volumes/U32 Shadow/Objectivism Library/MOTM/MOTM_2023-06-25_Challenge-Putins-Rule-and-Introspection-II.txt: ['confidence_score is missing or not a number']
Hard validation failures for /Volumes/U32 Shadow/Objectivism Library/MOTM/MOTM_2024-01-28_Unusual-Hobbies.txt: ['confidence_score is missing or not a number']
Mistral returned JSON array instead of object. Array length: 1. Content preview: [20231222112801423]
Failed to process result for /Volumes/U32 Shadow/Objectivism Library/MOTM/MOTM_2025-12-21_Sneak-Preview-of-Randsday-Conference.txt: Mistral returned JSON array with 1 elements instead of JSON object. This violates response_format constraint.
Hard validation failures for /Volumes/U32 Shadow/Objectivism Library/Thinking Lab/NonFiction Writing/NonFiction 09 - 14 - Edit for Clarity 15 - Polish to Add Impact.txt: ["Invalid difficulty: ''. Must be one of: ['advanced', 'intermediate', 'intro']", 'primary_topics: must be exactly 8 topics (found 0). Semantic normalization should have corrected this. Valid: []', 'confidence_score is missing or not a number']
âœ“ Saved: ITOE - Class 17-01.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Introduction to the Objectivist Ethics - 03.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Logic_ The Cashing-In - Lesson 05 - Wrap-up and Course Q&A.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Moral Virtue - Lesson 03 - The Virtue of Independence.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Moral Virtue - Lesson 04 - Question Period, Moral Virtue.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Objective Communication - Lesson 03 - Writing_ Analyses of _The Wreckage of the Consensus_ and a Sample Essay.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Objective Communication - Lesson 07 - Arguing_ Principles and Methods of Informal Debate.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Objective Communication - Lesson 08 - Arguing_ Analyses of Student Mock Arguments on God and on Knowledge.txt (conf: 31.0%, status=needs_review)
âœ“ Saved: Objective Communication - Lesson 09 - Writing_ Analyses of Student Papers on the Primacy of Consciousness and on Man_s Rights.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Objective Thinking - Lesson 01 - Thinking Objectively.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Objective Thinking - Lesson 02 - Discussion of Objective Thinking.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Objective Thinking - Lesson 04 - Discussion of Objectivity in Science.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Objective Thinking - Lesson 06 - Being Objective About Objectivism.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Objectivism Seminar - Foundations - Year 1 - Q2 - Week 2 - Descartes Meditations on First Philosophy.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Objectivism Seminar - Foundations - Year 1 - Q3 - Week 3 - Perceptual Awareness Form and Object.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Objectivism Seminar - Foundations - Year 1 - Q4 - Week 4 - The Objectivist Theory of Concepts Measurement, Isolation and Abstraction.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Objectivism Seminar - Foundations - Year 1 - Q4 - Week 6 - The Objectivist Theory of Concepts Definitions.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Objectivism Seminar - Foundations - Year 2 - Q2 - Week 6 - The virtue of justice.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Objectivism Seminar - Foundations - Year 2 - Q3 - Week 1 - Hobbes on the philosophic foundations of government - Part 1.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Objectivism Seminar - Foundations - Year 2 - Q3 - Week 6 - Government.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Objectivism Seminar - Foundations - Year 2 - Q3 - Week 8 - Wrap up topics physical force and the good; property rights, including intellectual property and Locke on property.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Objectivism Through Induction - Lesson 10 - Values as Objective.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Objectivism_ The State of the Art - Lesson 03 - Rand_s Distinctive Conception of Objectivity.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Objectivism_ The State of the Art - Lesson 06 - Moral Principles_ Integrity and Honesty.txt (conf: 81.0%, status=needs_review)
âœ“ Saved: Objectivism_ The State of the Art - Lesson 08 - Question Period 2_ Objectivism_ The State of the Art.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Objectivist Logic - Class 05-02.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Objectivist Logic - Class 08-01.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Objectivist Logic - Class 08-02.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Objectivist Logic - Class 11-02.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Persuasion Mastery - Week 3.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Persuasion Mastery - Week 5.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Philosophy of Education - Lesson 04 - Teaching Techniques, Teacher Training and the Politics of Education.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Principles of Grammar - Lesson 03 - Subordination and Coordination Part 2.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Psycho-Epistemology II - Lesson 02 - Psycho-Epistemology II, Part 2.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Rationality and Objectivity - Lesson 04 - Objectivity_ Theory.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Self-Interest - Lesson 04 - Altruism, Principles and the Ill-gotten.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: The Art of Thinking - Lesson 02 - Hierarchy.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: The Atlas Project - Lesson 11 - Part II Chapter 1 - The Man Who Belonged on Earth.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: The Atlas Project - Lesson 21 - Part III Chapter 1 - Atlantis.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: The Atlas Project - Lesson 31 - Part III Chapter 10 - In the Name of the Best Within Us.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: The DIM Hypothesis I - Lesson 01 - Integration.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: The DIM Hypothesis I - Lesson 05 - DIM in Education.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: The Fountainhead â€” Reading Group â€” Session 07 â€” (Chapters 2-10|2-11|2-12).txt (conf: 56.0%, status=needs_review)
âœ“ Saved: The Fountainhead â€” Reading Group â€” Session 11 â€” (Chapters 4-2|4-3|4-4|4-5).txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Unity in Epistemology and Ethics - Lesson 02 - How to Unite History and Philosophy.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: Charles H. Kepner and Benjamin B. Tregoe - The New Rational Manager (1997).txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2016-06-26_Alex-Epstein-on-Fossil-Fuels-and-Industrial-Progress.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2016-07-31_Sunday-Brunch-Prox-Principle-and-Objectivism-as-Elitist-Philosophy.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2016-12-04_Sunday-Brunch-Subconscious-Causality-and-Textbook-of-Americanism.txt (conf: 81.0%, status=needs_review)
âœ“ Saved: MOTM_2017-03-26_Sunday-Brunch-at-HBL-Ryan-Care.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2017-07-09_Sunday-Brunch-The-inspiration-for-Song-of-Broken-Glass-Preventive-Law-Researching-Racial-Intelligence-the-Molyneux-problem-in-perception.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2017-09-03_Guest-Jeff-Brown-Certified-Non-Violent-Communication-Trainer.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2017-11-18_Sunday-Brunch-at-HBL-Disc-on-Tabula-Rasa-continues.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2017-12-10_Sunday-Brunch-at-HBL-Meaning-of-Christmas-Nazism-current-sexual-harassment-charges.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2017-12-24_Sunday-Brunch-at-HBL-Altered-states-of-consciousnous-incl-lucid-dreaming-hypnosis.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2018-04-22_Regulation-vs-Law-Philosophical-Distinctions.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2018-05-06_Self-Leadership-with-Jean-Moroney.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2018-07-08_Mindfulness-b.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2018-07-22_The-Proper-Attitude-Toward-Privacy.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2018-09-09_Priests-who-sin-how-faith-fosters-evil.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2018-09-16_Flourish-Fever.txt (conf: 81.0%, status=needs_review)
âœ“ Saved: MOTM_2019-01-13_What-people-never-learn-and-why.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2019-03-24_The-crow-and-the-raven.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2019-05-12_When-is-it-preventive-law.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2019-05-26_Gems-from-Foundations-of-a-Free-Society.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2019-06-16_From-unowned-to-owned-and-related-property-rights-issues.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2019-09-08_Selfishness.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2019-10-20_The-Fountain-of-Middle-Age.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2020-03-08_The-subconscious-as-an-active-integrating-mechanism-with-Peter-Schwartz.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2020-03-15_Corona-virus-update.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2020-09-27_Americas-Revolutionary-Mind-Interview-with-Bradley-Thompson.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2020-10-11_What-Killed-America-Bradley-Thompson-interview-Part-II.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2020-12-20_Interview-with-Patrick-Cox-Interview-with-Patrick-Cox-specialist-in-age-reversal-research-and-development.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2021-02-21_History-of-the-Objectivist-movement-a-personal-account-part.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2021-09-12_General-Discussion-about-Covid-Issues.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2021-10-10_Interview-of-Jonathan-Hoenig.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2022-02-06_History-of-the-Objectivist-Movement-Part.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2022-06-26_Treasured-Discoveries-III.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2022-12-04_Atlas-Shrugged-As-A-Mini-Series.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2023-01-01_Then-and-Now.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2023-03-05_A-New-View-of-the-Nature-of-Psychological-Problems.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2023-04-02_Abortion-and-Infanticide.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2023-06-04_Psycho-epistemology-and-decision-making.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2023-09-03_Interview-of-JMB-on-Achieving-Long-Range-Goals.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2023-10-01_Precision-in-Introspecting-Feelings.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2024-02-04_Pet-Day-with-Jonathan-Hoenig.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2024-07-07_Current-Events.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2024-08-18_Any-better-ways-to-spread-Objectivism.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2024-09-01_Pleasure-Principle-and-Ambitious-Goals.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2024-09-08_Treasured-Discoveries-VI.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2025-01-05_Retrospective-and-prospective.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2025-01-19_Economics.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2025-04-20_Yaron-Brook-Interview.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2025-04-27_Economics-of-Tariffs-etc.txt (conf: 81.0%, status=needs_review)
âœ“ Saved: MOTM_2025-05-25_Objectivism-contrasted-and-compared-to-Pragmatism.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2025-08-03_Reign-of-King-Donald-I-and-Philosophical-Grammar.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2025-08-10_Clarity-techniques-contd-PLUS-What-is-an-Implicit-Premise.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2025-10-19_Peter-Schwartz-on-Israel.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2025-11-16_Philosophy-and-Science-The-Relationship.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: MOTM_2025-12-28_Interview-with-Joseph-Tabenkin-Continued.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: 19 - __8 - Dealing with Threats - 9-26-2023.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: 32 - The concept of anti-values - MOTM 2-25-2024.txt (conf: 56.0%, status=needs_review)
âœ“ Saved: TL - JIT - Unit 02 - Workshop Quick & Dirty Planning .txt (conf: 56.0%, status=needs_review)

âœ“ Batch Extraction Complete
                      Batch Summary                       
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Metric          â”ƒ                                Value â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Batch ID        â”‚ 494800e7-e49b-4231-820b-1aab129d04fe â”‚
â”‚ Total Files     â”‚                                  124 â”‚
â”‚ Succeeded       â”‚                                  103 â”‚
â”‚ Failed          â”‚                                   21 â”‚
â”‚ Processing Time â”‚                       985.6s (16.4m) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âš  21 files failed:
  â€¢ ITOE Advanced Topics - Class 15-01.txt
  â€¢ Objectivism Seminar - Foundations - Year 1 - Q2 - Week 7 - Idealism and 
Arguments for the Existence of God Discussion â€“ Group B.txt
  â€¢ Objectivism Seminar - Foundations - Year 2 - Q4 - Week 2 - Capitalism ; War 
and foreign policy capitalism and a mixed economy.txt
  â€¢ Objectivism Through Induction - Lesson 01 - An Inductive Approach to 
Philosophy.txt
  â€¢ Objectivism Through Induction - Lesson 08 - The Evil of Initiating Physical 
Force.txt
  â€¢ Philosophy of Education - Lesson 02 - How to Teach Proper Thinking 
Methods.txt
  â€¢ Principles of Grammar - Lesson 02 - Subordination and Coordination Part 
1.txt
  â€¢ Rationality and Objectivity - Lesson 01 - Introduction to Rationality and 
Objectivity.txt
  â€¢ The Atlas Project - Lesson 09 - Part I Chapter 9 - The Sacred and the 
Profane.txt
  â€¢ The Atlas Project - Lesson 29 - Part III Chapter 8 - The Egoist.txt
  ... and 11 more

Failed files marked in database: ai_metadata_status='failed_validation'
Review errors and retry with objlib metadata batch-extract

Next: Run objlib metadata stats to see updated extraction progress
